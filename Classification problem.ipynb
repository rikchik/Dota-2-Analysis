{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54532a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7f56c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a943115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>hero_id</th>\n",
       "      <th>player_slot</th>\n",
       "      <th>gold</th>\n",
       "      <th>gold_spent</th>\n",
       "      <th>gold_per_min</th>\n",
       "      <th>xp_per_min</th>\n",
       "      <th>kills</th>\n",
       "      <th>deaths</th>\n",
       "      <th>...</th>\n",
       "      <th>unit_order_glyph</th>\n",
       "      <th>unit_order_eject_item_from_stash</th>\n",
       "      <th>unit_order_cast_rune</th>\n",
       "      <th>unit_order_ping_ability</th>\n",
       "      <th>unit_order_move_to_direction</th>\n",
       "      <th>unit_order_patrol</th>\n",
       "      <th>unit_order_vector_target_position</th>\n",
       "      <th>unit_order_radar</th>\n",
       "      <th>unit_order_set_item_combine_lock</th>\n",
       "      <th>unit_order_continue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>3261</td>\n",
       "      <td>10960</td>\n",
       "      <td>347</td>\n",
       "      <td>362</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2954</td>\n",
       "      <td>17760</td>\n",
       "      <td>494</td>\n",
       "      <td>659</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>12195</td>\n",
       "      <td>350</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1179</td>\n",
       "      <td>22505</td>\n",
       "      <td>599</td>\n",
       "      <td>605</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>3307</td>\n",
       "      <td>23825</td>\n",
       "      <td>613</td>\n",
       "      <td>762</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  account_id  hero_id  player_slot  gold  gold_spent  gold_per_min  \\\n",
       "0         0           0       86            0  3261       10960           347   \n",
       "1         0           1       51            1  2954       17760           494   \n",
       "2         0           0       83            2   110       12195           350   \n",
       "3         0           2       11            3  1179       22505           599   \n",
       "4         0           3       67            4  3307       23825           613   \n",
       "\n",
       "   xp_per_min  kills  deaths  ...  unit_order_glyph  \\\n",
       "0         362      9       3  ...               NaN   \n",
       "1         659     13       3  ...               NaN   \n",
       "2         385      0       4  ...               NaN   \n",
       "3         605      8       4  ...               1.0   \n",
       "4         762     20       3  ...               3.0   \n",
       "\n",
       "   unit_order_eject_item_from_stash  unit_order_cast_rune  \\\n",
       "0                               NaN                   NaN   \n",
       "1                               NaN                   NaN   \n",
       "2                               NaN                   NaN   \n",
       "3                               NaN                   NaN   \n",
       "4                               NaN                   NaN   \n",
       "\n",
       "  unit_order_ping_ability  unit_order_move_to_direction  unit_order_patrol  \\\n",
       "0                     6.0                           NaN                NaN   \n",
       "1                    14.0                           NaN                NaN   \n",
       "2                    17.0                           NaN                NaN   \n",
       "3                    13.0                           NaN                NaN   \n",
       "4                    23.0                           NaN                NaN   \n",
       "\n",
       "   unit_order_vector_target_position  unit_order_radar  \\\n",
       "0                                NaN               NaN   \n",
       "1                                NaN               NaN   \n",
       "2                                NaN               NaN   \n",
       "3                                NaN               NaN   \n",
       "4                                NaN               NaN   \n",
       "\n",
       "   unit_order_set_item_combine_lock  unit_order_continue  \n",
       "0                               NaN                  NaN  \n",
       "1                               NaN                  NaN  \n",
       "2                               NaN                  NaN  \n",
       "3                               NaN                  NaN  \n",
       "4                               NaN                  NaN  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players=pd.read_csv(r\"players.csv\")\n",
    "matches=pd.read_csv(r\"match.csv\")\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67945e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>hero_id</th>\n",
       "      <th>player_slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>49999</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>49999</td>\n",
       "      <td>9</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>49999</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>49999</td>\n",
       "      <td>73</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>49999</td>\n",
       "      <td>53</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        match_id  hero_id  player_slot\n",
       "0              0       86            0\n",
       "1              0       51            1\n",
       "2              0       83            2\n",
       "3              0       11            3\n",
       "4              0       67            4\n",
       "...          ...      ...          ...\n",
       "499995     49999      100          128\n",
       "499996     49999        9          129\n",
       "499997     49999       90          130\n",
       "499998     49999       73          131\n",
       "499999     49999       53          132\n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players=players[[\"match_id\",\"hero_id\",\"player_slot\"]]\n",
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0022c87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6606934e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match_id       int64\n",
       "hero_id        int64\n",
       "player_slot    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c077380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>hero_id</th>\n",
       "      <th>player_slot</th>\n",
       "      <th>position</th>\n",
       "      <th>radiant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  hero_id  player_slot  position  radiant\n",
       "0         0       86            0         0     True\n",
       "1         0       51            1         1     True\n",
       "2         0       83            2         2     True\n",
       "3         0       11            3         3     True\n",
       "4         0       67            4         4     True\n",
       "5         0      106          128         0    False\n",
       "6         0      102          129         1    False\n",
       "7         0       46          130         2    False\n",
       "8         0        7          131         3    False\n",
       "9         0       73          132         4    False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_position(x):\n",
    "    if x>=128:\n",
    "        x-=128\n",
    "    return x\n",
    "players[\"position\"]=players[\"player_slot\"].apply(lambda x: get_position(x))\n",
    "players[\"radiant\"]=players[\"player_slot\"].apply(lambda x: x<128)\n",
    "players.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d526ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>tower_status_radiant</th>\n",
       "      <th>tower_status_dire</th>\n",
       "      <th>barracks_status_dire</th>\n",
       "      <th>barracks_status_radiant</th>\n",
       "      <th>first_blood_time</th>\n",
       "      <th>game_mode</th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>negative_votes</th>\n",
       "      <th>positive_votes</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1446750112</td>\n",
       "      <td>2375</td>\n",
       "      <td>1982</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1446753078</td>\n",
       "      <td>2582</td>\n",
       "      <td>0</td>\n",
       "      <td>1846</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1446764586</td>\n",
       "      <td>2716</td>\n",
       "      <td>256</td>\n",
       "      <td>1972</td>\n",
       "      <td>63</td>\n",
       "      <td>48</td>\n",
       "      <td>190</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1446765723</td>\n",
       "      <td>3085</td>\n",
       "      <td>4</td>\n",
       "      <td>1924</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1446796385</td>\n",
       "      <td>1887</td>\n",
       "      <td>2047</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  start_time  duration  tower_status_radiant  tower_status_dire  \\\n",
       "0         0  1446750112      2375                  1982                  4   \n",
       "1         1  1446753078      2582                     0               1846   \n",
       "2         2  1446764586      2716                   256               1972   \n",
       "3         3  1446765723      3085                     4               1924   \n",
       "4         4  1446796385      1887                  2047                  0   \n",
       "\n",
       "   barracks_status_dire  barracks_status_radiant  first_blood_time  game_mode  \\\n",
       "0                     3                       63                 1         22   \n",
       "1                    63                        0               221         22   \n",
       "2                    63                       48               190         22   \n",
       "3                    51                        3                40         22   \n",
       "4                     0                       63                58         22   \n",
       "\n",
       "   radiant_win  negative_votes  positive_votes  cluster  \n",
       "0         True               0               1      155  \n",
       "1        False               0               2      154  \n",
       "2        False               0               0      132  \n",
       "3        False               0               0      191  \n",
       "4         True               0               0      156  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aedb20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches=matches[[\"match_id\",\"radiant_win\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2a13b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>radiant_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  radiant_win\n",
       "0         0         True\n",
       "1         1        False\n",
       "2         2        False\n",
       "3         3        False\n",
       "4         4         True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c881be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>hero_id</th>\n",
       "      <th>player_slot</th>\n",
       "      <th>position</th>\n",
       "      <th>radiant</th>\n",
       "      <th>radiant_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  hero_id  player_slot  position  radiant  radiant_win\n",
       "0         0       86            0         0     True         True\n",
       "1         0       51            1         1     True         True\n",
       "2         0       83            2         2     True         True\n",
       "3         0       11            3         3     True         True\n",
       "4         0       67            4         4     True         True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.merge(players,matches,left_on=\"match_id\",right_on=\"match_id\",how=\"left\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582a8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[[\"match_id\",\"hero_id\",\"position\",\"radiant\",\"radiant_win\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "111bb91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>hero_id</th>\n",
       "      <th>position</th>\n",
       "      <th>radiant</th>\n",
       "      <th>radiant_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  hero_id  position  radiant  radiant_win\n",
       "0         0       86         0     True         True\n",
       "1         0       51         1     True         True\n",
       "2         0       83         2     True         True\n",
       "3         0       11         3     True         True\n",
       "4         0       67         4     True         True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddff05d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>hero_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[86, 51, 83, 11, 67, 106, 102, 46, 7, 73]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[7, 82, 71, 39, 21, 73, 22, 5, 67, 106]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[51, 109, 9, 41, 27, 38, 7, 10, 12, 85]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[50, 44, 32, 26, 39, 78, 19, 31, 40, 47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[8, 39, 55, 87, 69, 101, 100, 22, 67, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id                                    hero_id\n",
       "0         0  [86, 51, 83, 11, 67, 106, 102, 46, 7, 73]\n",
       "1         1    [7, 82, 71, 39, 21, 73, 22, 5, 67, 106]\n",
       "2         2    [51, 109, 9, 41, 27, 38, 7, 10, 12, 85]\n",
       "3         3   [50, 44, 32, 26, 39, 78, 19, 31, 40, 47]\n",
       "4         4  [8, 39, 55, 87, 69, 101, 100, 22, 67, 21]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_row=data.groupby('match_id')['hero_id'].agg(list).reset_index()\n",
    "one_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03797614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radiant1</th>\n",
       "      <th>Radiant2</th>\n",
       "      <th>Radiant3</th>\n",
       "      <th>Radiant4</th>\n",
       "      <th>Radiant5</th>\n",
       "      <th>Dire1</th>\n",
       "      <th>Dire2</th>\n",
       "      <th>Dire3</th>\n",
       "      <th>Dire4</th>\n",
       "      <th>Dire5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>51</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>67</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>67</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>109</td>\n",
       "      <td>35</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>93</td>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>100</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>94</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>73</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Radiant1  Radiant2  Radiant3  Radiant4  Radiant5  Dire1  Dire2  Dire3  \\\n",
       "0            86        51        83        11        67    106    102     46   \n",
       "1             7        82        71        39        21     73     22      5   \n",
       "2            51       109         9        41        27     38      7     10   \n",
       "3            50        44        32        26        39     78     19     31   \n",
       "4             8        39        55        87        69    101    100     22   \n",
       "...         ...       ...       ...       ...       ...    ...    ...    ...   \n",
       "49995        73        86        21        20        14     32      7    109   \n",
       "49996        93        74       100        32        85     36      1    112   \n",
       "49997       100        68        75        39        44     28    102     21   \n",
       "49998        56        50         2        72        30     46      7     29   \n",
       "49999        94        19        68        35        21    100      9     90   \n",
       "\n",
       "       Dire4  Dire5  \n",
       "0          7     73  \n",
       "1         67    106  \n",
       "2         12     85  \n",
       "3         40     47  \n",
       "4         67     21  \n",
       "...      ...    ...  \n",
       "49995     35    112  \n",
       "49996     60     71  \n",
       "49997      9     23  \n",
       "49998     44      3  \n",
       "49999     73     53  \n",
       "\n",
       "[50000 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = one_row.hero_id.apply(pd.Series)\n",
    "df3.columns = ['Radiant1', 'Radiant2','Radiant3','Radiant4','Radiant5','Dire1','Dire2','Dire3','Dire4','Dire5']\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77d61102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radiant_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radiant_win\n",
       "0         True\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4         True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(subset='match_id', keep=\"first\",inplace=True)\n",
    "data=data.reset_index(drop=True)[[\"radiant_win\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0a11599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>Radiant1</th>\n",
       "      <th>Radiant2</th>\n",
       "      <th>Radiant3</th>\n",
       "      <th>Radiant4</th>\n",
       "      <th>Radiant5</th>\n",
       "      <th>Dire1</th>\n",
       "      <th>Dire2</th>\n",
       "      <th>Dire3</th>\n",
       "      <th>Dire4</th>\n",
       "      <th>Dire5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "      <td>51</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>67</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>67</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radiant_win  Radiant1  Radiant2  Radiant3  Radiant4  Radiant5  Dire1  \\\n",
       "0         True        86        51        83        11        67    106   \n",
       "1        False         7        82        71        39        21     73   \n",
       "2        False        51       109         9        41        27     38   \n",
       "3        False        50        44        32        26        39     78   \n",
       "4         True         8        39        55        87        69    101   \n",
       "\n",
       "   Dire2  Dire3  Dire4  Dire5  \n",
       "0    102     46      7     73  \n",
       "1     22      5     67    106  \n",
       "2      7     10     12     85  \n",
       "3     19     31     40     47  \n",
       "4    100     22     67     21  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([data,df3],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46f40c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"radiant_win\"]=data[\"radiant_win\"].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "852373b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>Radiant1</th>\n",
       "      <th>Radiant2</th>\n",
       "      <th>Radiant3</th>\n",
       "      <th>Radiant4</th>\n",
       "      <th>Radiant5</th>\n",
       "      <th>Dire1</th>\n",
       "      <th>Dire2</th>\n",
       "      <th>Dire3</th>\n",
       "      <th>Dire4</th>\n",
       "      <th>Dire5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>51</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>67</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>67</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radiant_win  Radiant1  Radiant2  Radiant3  Radiant4  Radiant5  Dire1  \\\n",
       "0            1        86        51        83        11        67    106   \n",
       "1            0         7        82        71        39        21     73   \n",
       "2            0        51       109         9        41        27     38   \n",
       "3            0        50        44        32        26        39     78   \n",
       "4            1         8        39        55        87        69    101   \n",
       "\n",
       "   Dire2  Dire3  Dire4  Dire5  \n",
       "0    102     46      7     73  \n",
       "1     22      5     67    106  \n",
       "2      7     10     12     85  \n",
       "3     19     31     40     47  \n",
       "4    100     22     67     21  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51280875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size=len(data[\"Radiant1\"].unique())+10\n",
    "data_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26951da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(data[\"Radiant1\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4946e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['Radiant1', 'Radiant2','Radiant3','Radiant4','Radiant5','Dire1','Dire2','Dire3','Dire4','Dire5']], data[\"radiant_win\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a7e7a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bde56f0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 71,  74,  30,  67,  53,  62,  65,  63,  60,  25],\n",
      "        [  8,  73,  37, 100,  19,  86,  88,  21,  93,   7],\n",
      "        [ 39,  69,   8,  68,  71, 110,  73,  86,  72,  50],\n",
      "        [ 71,  15,  31,  76,  12, 106,   3,   9,  46,  69],\n",
      "        [ 88,  14,  74, 104,  47,  18,  25,   9,  93,  21]])\n",
      "tensor([1, 0, 1, 1, 0])\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "data_numpy=torch.tensor(X_train[['Radiant1', 'Radiant2','Radiant3','Radiant4','Radiant5','Dire1','Dire2','Dire3','Dire4','Dire5']].to_numpy(),dtype=(torch.long))\n",
    "print(data_numpy[:5])\n",
    "labels=torch.tensor(y_train.to_numpy(),dtype=(torch.long))\n",
    "print(labels[:5])\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "780cf59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelemb= nn.Sequential(\n",
    "    nn.Embedding(data_size, 15),\n",
    "    nn.Flatten(),\n",
    "    nn.BatchNorm1d(15*10),\n",
    "    nn.Linear(15 * 10, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da11c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()  # Binary Cross Entropy\n",
    "optimizer = optim.AdamW(modelemb.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aba4397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-137e307aa58f>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = criterion(outputs.squeeze(), torch.tensor(labels, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.7314654588699341\n",
      "___________________\n",
      "Epoch:1\n",
      "Loss:0.7295438051223755\n",
      "___________________\n",
      "Epoch:2\n",
      "Loss:0.7276917099952698\n",
      "___________________\n",
      "Epoch:3\n",
      "Loss:0.7259085774421692\n",
      "___________________\n",
      "Epoch:4\n",
      "Loss:0.7241934537887573\n",
      "___________________\n",
      "Epoch:5\n",
      "Loss:0.7225451469421387\n",
      "___________________\n",
      "Epoch:6\n",
      "Loss:0.7209619879722595\n",
      "___________________\n",
      "Epoch:7\n",
      "Loss:0.7194423079490662\n",
      "___________________\n",
      "Epoch:8\n",
      "Loss:0.7179840803146362\n",
      "___________________\n",
      "Epoch:9\n",
      "Loss:0.7165849804878235\n",
      "___________________\n",
      "Epoch:10\n",
      "Loss:0.7152430415153503\n",
      "___________________\n",
      "Epoch:11\n",
      "Loss:0.713956356048584\n",
      "___________________\n",
      "Epoch:12\n",
      "Loss:0.7127225399017334\n",
      "___________________\n",
      "Epoch:13\n",
      "Loss:0.7115395665168762\n",
      "___________________\n",
      "Epoch:14\n",
      "Loss:0.7104053497314453\n",
      "___________________\n",
      "Epoch:15\n",
      "Loss:0.7093178629875183\n",
      "___________________\n",
      "Epoch:16\n",
      "Loss:0.7082751989364624\n",
      "___________________\n",
      "Epoch:17\n",
      "Loss:0.707275390625\n",
      "___________________\n",
      "Epoch:18\n",
      "Loss:0.7063168883323669\n",
      "___________________\n",
      "Epoch:19\n",
      "Loss:0.7053978443145752\n",
      "___________________\n",
      "Epoch:20\n",
      "Loss:0.704517126083374\n",
      "___________________\n",
      "Epoch:21\n",
      "Loss:0.7036728262901306\n",
      "___________________\n",
      "Epoch:22\n",
      "Loss:0.7028640508651733\n",
      "___________________\n",
      "Epoch:23\n",
      "Loss:0.702089250087738\n",
      "___________________\n",
      "Epoch:24\n",
      "Loss:0.701347291469574\n",
      "___________________\n",
      "Epoch:25\n",
      "Loss:0.7006368041038513\n",
      "___________________\n",
      "Epoch:26\n",
      "Loss:0.6999567747116089\n",
      "___________________\n",
      "Epoch:27\n",
      "Loss:0.6993059515953064\n",
      "___________________\n",
      "Epoch:28\n",
      "Loss:0.6986832022666931\n",
      "___________________\n",
      "Epoch:29\n",
      "Loss:0.6980873942375183\n",
      "___________________\n",
      "Epoch:30\n",
      "Loss:0.6975175738334656\n",
      "___________________\n",
      "Epoch:31\n",
      "Loss:0.6969724893569946\n",
      "___________________\n",
      "Epoch:32\n",
      "Loss:0.6964513063430786\n",
      "___________________\n",
      "Epoch:33\n",
      "Loss:0.6959527134895325\n",
      "___________________\n",
      "Epoch:34\n",
      "Loss:0.6954757571220398\n",
      "___________________\n",
      "Epoch:35\n",
      "Loss:0.6950196027755737\n",
      "___________________\n",
      "Epoch:36\n",
      "Loss:0.694582998752594\n",
      "___________________\n",
      "Epoch:37\n",
      "Loss:0.6941651105880737\n",
      "___________________\n",
      "Epoch:38\n",
      "Loss:0.6937649250030518\n",
      "___________________\n",
      "Epoch:39\n",
      "Loss:0.6933814287185669\n",
      "___________________\n",
      "Epoch:40\n",
      "Loss:0.6930139660835266\n",
      "___________________\n",
      "Epoch:41\n",
      "Loss:0.692661464214325\n",
      "___________________\n",
      "Epoch:42\n",
      "Loss:0.6923229694366455\n",
      "___________________\n",
      "Epoch:43\n",
      "Loss:0.6919979453086853\n",
      "___________________\n",
      "Epoch:44\n",
      "Loss:0.6916855573654175\n",
      "___________________\n",
      "Epoch:45\n",
      "Loss:0.6913849711418152\n",
      "___________________\n",
      "Epoch:46\n",
      "Loss:0.691095769405365\n",
      "___________________\n",
      "Epoch:47\n",
      "Loss:0.6908169984817505\n",
      "___________________\n",
      "Epoch:48\n",
      "Loss:0.6905484199523926\n",
      "___________________\n",
      "Epoch:49\n",
      "Loss:0.6902891397476196\n",
      "___________________\n",
      "Epoch:50\n",
      "Loss:0.6900389790534973\n",
      "___________________\n",
      "Epoch:51\n",
      "Loss:0.689797043800354\n",
      "___________________\n",
      "Epoch:52\n",
      "Loss:0.6895631551742554\n",
      "___________________\n",
      "Epoch:53\n",
      "Loss:0.689336895942688\n",
      "___________________\n",
      "Epoch:54\n",
      "Loss:0.6891176700592041\n",
      "___________________\n",
      "Epoch:55\n",
      "Loss:0.6889051795005798\n",
      "___________________\n",
      "Epoch:56\n",
      "Loss:0.688698947429657\n",
      "___________________\n",
      "Epoch:57\n",
      "Loss:0.6884987354278564\n",
      "___________________\n",
      "Epoch:58\n",
      "Loss:0.6883041858673096\n",
      "___________________\n",
      "Epoch:59\n",
      "Loss:0.6881148219108582\n",
      "___________________\n",
      "Epoch:60\n",
      "Loss:0.6879306435585022\n",
      "___________________\n",
      "Epoch:61\n",
      "Loss:0.687751054763794\n",
      "___________________\n",
      "Epoch:62\n",
      "Loss:0.6875759363174438\n",
      "___________________\n",
      "Epoch:63\n",
      "Loss:0.6874050498008728\n",
      "___________________\n",
      "Epoch:64\n",
      "Loss:0.6872380971908569\n",
      "___________________\n",
      "Epoch:65\n",
      "Loss:0.6870747208595276\n",
      "___________________\n",
      "Epoch:66\n",
      "Loss:0.6869149208068848\n",
      "___________________\n",
      "Epoch:67\n",
      "Loss:0.6867583990097046\n",
      "___________________\n",
      "Epoch:68\n",
      "Loss:0.686604917049408\n",
      "___________________\n",
      "Epoch:69\n",
      "Loss:0.6864542961120605\n",
      "___________________\n",
      "Epoch:70\n",
      "Loss:0.6863064169883728\n",
      "___________________\n",
      "Epoch:71\n",
      "Loss:0.6861610412597656\n",
      "___________________\n",
      "Epoch:72\n",
      "Loss:0.6860179901123047\n",
      "___________________\n",
      "Epoch:73\n",
      "Loss:0.68587726354599\n",
      "___________________\n",
      "Epoch:74\n",
      "Loss:0.6857385635375977\n",
      "___________________\n",
      "Epoch:75\n",
      "Loss:0.6856018304824829\n",
      "___________________\n",
      "Epoch:76\n",
      "Loss:0.6854668855667114\n",
      "___________________\n",
      "Epoch:77\n",
      "Loss:0.6853336691856384\n",
      "___________________\n",
      "Epoch:78\n",
      "Loss:0.6852021217346191\n",
      "___________________\n",
      "Epoch:79\n",
      "Loss:0.6850720643997192\n",
      "___________________\n",
      "Epoch:80\n",
      "Loss:0.6849433779716492\n",
      "___________________\n",
      "Epoch:81\n",
      "Loss:0.6848160624504089\n",
      "___________________\n",
      "Epoch:82\n",
      "Loss:0.6846899390220642\n",
      "___________________\n",
      "Epoch:83\n",
      "Loss:0.6845649480819702\n",
      "___________________\n",
      "Epoch:84\n",
      "Loss:0.6844411492347717\n",
      "___________________\n",
      "Epoch:85\n",
      "Loss:0.6843183040618896\n",
      "___________________\n",
      "Epoch:86\n",
      "Loss:0.6841964721679688\n",
      "___________________\n",
      "Epoch:87\n",
      "Loss:0.6840754151344299\n",
      "___________________\n",
      "Epoch:88\n",
      "Loss:0.6839552521705627\n",
      "___________________\n",
      "Epoch:89\n",
      "Loss:0.6838359236717224\n",
      "___________________\n",
      "Epoch:90\n",
      "Loss:0.6837171912193298\n",
      "___________________\n",
      "Epoch:91\n",
      "Loss:0.6835992336273193\n",
      "___________________\n",
      "Epoch:92\n",
      "Loss:0.6834818124771118\n",
      "___________________\n",
      "Epoch:93\n",
      "Loss:0.6833651065826416\n",
      "___________________\n",
      "Epoch:94\n",
      "Loss:0.6832488179206848\n",
      "___________________\n",
      "Epoch:95\n",
      "Loss:0.6831331253051758\n",
      "___________________\n",
      "Epoch:96\n",
      "Loss:0.6830178499221802\n",
      "___________________\n",
      "Epoch:97\n",
      "Loss:0.6829030513763428\n",
      "___________________\n",
      "Epoch:98\n",
      "Loss:0.682788610458374\n",
      "___________________\n",
      "Epoch:99\n",
      "Loss:0.6826745271682739\n",
      "___________________\n",
      "Epoch:100\n",
      "Loss:0.6825608611106873\n",
      "___________________\n",
      "Epoch:101\n",
      "Loss:0.6824474334716797\n",
      "___________________\n",
      "Epoch:102\n",
      "Loss:0.682334303855896\n",
      "___________________\n",
      "Epoch:103\n",
      "Loss:0.6822214126586914\n",
      "___________________\n",
      "Epoch:104\n",
      "Loss:0.6821087598800659\n",
      "___________________\n",
      "Epoch:105\n",
      "Loss:0.6819964051246643\n",
      "___________________\n",
      "Epoch:106\n",
      "Loss:0.6818841099739075\n",
      "___________________\n",
      "Epoch:107\n",
      "Loss:0.681771993637085\n",
      "___________________\n",
      "Epoch:108\n",
      "Loss:0.6816601753234863\n",
      "___________________\n",
      "Epoch:109\n",
      "Loss:0.6815483570098877\n",
      "___________________\n",
      "Epoch:110\n",
      "Loss:0.6814367175102234\n",
      "___________________\n",
      "Epoch:111\n",
      "Loss:0.6813251972198486\n",
      "___________________\n",
      "Epoch:112\n",
      "Loss:0.6812137365341187\n",
      "___________________\n",
      "Epoch:113\n",
      "Loss:0.6811022758483887\n",
      "___________________\n",
      "Epoch:114\n",
      "Loss:0.6809909343719482\n",
      "___________________\n",
      "Epoch:115\n",
      "Loss:0.6808796525001526\n",
      "___________________\n",
      "Epoch:116\n",
      "Loss:0.6807683706283569\n",
      "___________________\n",
      "Epoch:117\n",
      "Loss:0.680657148361206\n",
      "___________________\n",
      "Epoch:118\n",
      "Loss:0.6805459260940552\n",
      "___________________\n",
      "Epoch:119\n",
      "Loss:0.6804347038269043\n",
      "___________________\n",
      "Epoch:120\n",
      "Loss:0.6803234815597534\n",
      "___________________\n",
      "Epoch:121\n",
      "Loss:0.6802123188972473\n",
      "___________________\n",
      "Epoch:122\n",
      "Loss:0.6801010966300964\n",
      "___________________\n",
      "Epoch:123\n",
      "Loss:0.6799898147583008\n",
      "___________________\n",
      "Epoch:124\n",
      "Loss:0.6798785924911499\n",
      "___________________\n",
      "Epoch:125\n",
      "Loss:0.6797672510147095\n",
      "___________________\n",
      "Epoch:126\n",
      "Loss:0.6796559691429138\n",
      "___________________\n",
      "Epoch:127\n",
      "Loss:0.6795444488525391\n",
      "___________________\n",
      "Epoch:128\n",
      "Loss:0.6794331073760986\n",
      "___________________\n",
      "Epoch:129\n",
      "Loss:0.6793215870857239\n",
      "___________________\n",
      "Epoch:130\n",
      "Loss:0.6792100667953491\n",
      "___________________\n",
      "Epoch:131\n",
      "Loss:0.67909836769104\n",
      "___________________\n",
      "Epoch:132\n",
      "Loss:0.6789867281913757\n",
      "___________________\n",
      "Epoch:133\n",
      "Loss:0.6788750886917114\n",
      "___________________\n",
      "Epoch:134\n",
      "Loss:0.6787633299827576\n",
      "___________________\n",
      "Epoch:135\n",
      "Loss:0.6786514520645142\n",
      "___________________\n",
      "Epoch:136\n",
      "Loss:0.6785395741462708\n",
      "___________________\n",
      "Epoch:137\n",
      "Loss:0.678427517414093\n",
      "___________________\n",
      "Epoch:138\n",
      "Loss:0.6783155202865601\n",
      "___________________\n",
      "Epoch:139\n",
      "Loss:0.6782034039497375\n",
      "___________________\n",
      "Epoch:140\n",
      "Loss:0.6780912280082703\n",
      "___________________\n",
      "Epoch:141\n",
      "Loss:0.6779789924621582\n",
      "___________________\n",
      "Epoch:142\n",
      "Loss:0.6778667569160461\n",
      "___________________\n",
      "Epoch:143\n",
      "Loss:0.6777544021606445\n",
      "___________________\n",
      "Epoch:144\n",
      "Loss:0.6776419878005981\n",
      "___________________\n",
      "Epoch:145\n",
      "Loss:0.6775294542312622\n",
      "___________________\n",
      "Epoch:146\n",
      "Loss:0.6774169206619263\n",
      "___________________\n",
      "Epoch:147\n",
      "Loss:0.6773042678833008\n",
      "___________________\n",
      "Epoch:148\n",
      "Loss:0.6771916747093201\n",
      "___________________\n",
      "Epoch:149\n",
      "Loss:0.6770790219306946\n",
      "___________________\n",
      "Epoch:150\n",
      "Loss:0.6769661903381348\n",
      "___________________\n",
      "Epoch:151\n",
      "Loss:0.6768534183502197\n",
      "___________________\n",
      "Epoch:152\n",
      "Loss:0.6767405271530151\n",
      "___________________\n",
      "Epoch:153\n",
      "Loss:0.6766275763511658\n",
      "___________________\n",
      "Epoch:154\n",
      "Loss:0.6765146255493164\n",
      "___________________\n",
      "Epoch:155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.676401674747467\n",
      "___________________\n",
      "Epoch:156\n",
      "Loss:0.6762886643409729\n",
      "___________________\n",
      "Epoch:157\n",
      "Loss:0.6761756539344788\n",
      "___________________\n",
      "Epoch:158\n",
      "Loss:0.6760625243186951\n",
      "___________________\n",
      "Epoch:159\n",
      "Loss:0.6759495139122009\n",
      "___________________\n",
      "Epoch:160\n",
      "Loss:0.6758363246917725\n",
      "___________________\n",
      "Epoch:161\n",
      "Loss:0.6757232546806335\n",
      "___________________\n",
      "Epoch:162\n",
      "Loss:0.6756101250648499\n",
      "___________________\n",
      "Epoch:163\n",
      "Loss:0.6754969358444214\n",
      "___________________\n",
      "Epoch:164\n",
      "Loss:0.6753838658332825\n",
      "___________________\n",
      "Epoch:165\n",
      "Loss:0.675270676612854\n",
      "___________________\n",
      "Epoch:166\n",
      "Loss:0.6751575469970703\n",
      "___________________\n",
      "Epoch:167\n",
      "Loss:0.6750444173812866\n",
      "___________________\n",
      "Epoch:168\n",
      "Loss:0.6749313473701477\n",
      "___________________\n",
      "Epoch:169\n",
      "Loss:0.6748182773590088\n",
      "___________________\n",
      "Epoch:170\n",
      "Loss:0.6747052073478699\n",
      "___________________\n",
      "Epoch:171\n",
      "Loss:0.6745920777320862\n",
      "___________________\n",
      "Epoch:172\n",
      "Loss:0.6744791269302368\n",
      "___________________\n",
      "Epoch:173\n",
      "Loss:0.6743662357330322\n",
      "___________________\n",
      "Epoch:174\n",
      "Loss:0.6742532253265381\n",
      "___________________\n",
      "Epoch:175\n",
      "Loss:0.674140453338623\n",
      "___________________\n",
      "Epoch:176\n",
      "Loss:0.6740276217460632\n",
      "___________________\n",
      "Epoch:177\n",
      "Loss:0.6739148497581482\n",
      "___________________\n",
      "Epoch:178\n",
      "Loss:0.6738021969795227\n",
      "___________________\n",
      "Epoch:179\n",
      "Loss:0.6736896634101868\n",
      "___________________\n",
      "Epoch:180\n",
      "Loss:0.6735771298408508\n",
      "___________________\n",
      "Epoch:181\n",
      "Loss:0.6734646558761597\n",
      "___________________\n",
      "Epoch:182\n",
      "Loss:0.6733523607254028\n",
      "___________________\n",
      "Epoch:183\n",
      "Loss:0.673240065574646\n",
      "___________________\n",
      "Epoch:184\n",
      "Loss:0.6731278896331787\n",
      "___________________\n",
      "Epoch:185\n",
      "Loss:0.6730158925056458\n",
      "___________________\n",
      "Epoch:186\n",
      "Loss:0.6729040145874023\n",
      "___________________\n",
      "Epoch:187\n",
      "Loss:0.6727921962738037\n",
      "___________________\n",
      "Epoch:188\n",
      "Loss:0.6726804971694946\n",
      "___________________\n",
      "Epoch:189\n",
      "Loss:0.6725689172744751\n",
      "___________________\n",
      "Epoch:190\n",
      "Loss:0.6724575757980347\n",
      "___________________\n",
      "Epoch:191\n",
      "Loss:0.672346293926239\n",
      "___________________\n",
      "Epoch:192\n",
      "Loss:0.6722351312637329\n",
      "___________________\n",
      "Epoch:193\n",
      "Loss:0.6721242070198059\n",
      "___________________\n",
      "Epoch:194\n",
      "Loss:0.6720134019851685\n",
      "___________________\n",
      "Epoch:195\n",
      "Loss:0.6719028353691101\n",
      "___________________\n",
      "Epoch:196\n",
      "Loss:0.6717922687530518\n",
      "___________________\n",
      "Epoch:197\n",
      "Loss:0.6716820597648621\n",
      "___________________\n",
      "Epoch:198\n",
      "Loss:0.6715719103813171\n",
      "___________________\n",
      "Epoch:199\n",
      "Loss:0.6714619994163513\n",
      "___________________\n",
      "Epoch:200\n",
      "Loss:0.6713523268699646\n",
      "___________________\n",
      "Epoch:201\n",
      "Loss:0.6712427735328674\n",
      "___________________\n",
      "Epoch:202\n",
      "Loss:0.6711335182189941\n",
      "___________________\n",
      "Epoch:203\n",
      "Loss:0.6710244417190552\n",
      "___________________\n",
      "Epoch:204\n",
      "Loss:0.6709155440330505\n",
      "___________________\n",
      "Epoch:205\n",
      "Loss:0.670806884765625\n",
      "___________________\n",
      "Epoch:206\n",
      "Loss:0.6706985235214233\n",
      "___________________\n",
      "Epoch:207\n",
      "Loss:0.670590341091156\n",
      "___________________\n",
      "Epoch:208\n",
      "Loss:0.6704824566841125\n",
      "___________________\n",
      "Epoch:209\n",
      "Loss:0.6703746914863586\n",
      "___________________\n",
      "Epoch:210\n",
      "Loss:0.6702672839164734\n",
      "___________________\n",
      "Epoch:211\n",
      "Loss:0.6701600551605225\n",
      "___________________\n",
      "Epoch:212\n",
      "Loss:0.6700531244277954\n",
      "___________________\n",
      "Epoch:213\n",
      "Loss:0.6699464917182922\n",
      "___________________\n",
      "Epoch:214\n",
      "Loss:0.6698401570320129\n",
      "___________________\n",
      "Epoch:215\n",
      "Loss:0.6697340607643127\n",
      "___________________\n",
      "Epoch:216\n",
      "Loss:0.6696282029151917\n",
      "___________________\n",
      "Epoch:217\n",
      "Loss:0.6695227026939392\n",
      "___________________\n",
      "Epoch:218\n",
      "Loss:0.6694175004959106\n",
      "___________________\n",
      "Epoch:219\n",
      "Loss:0.669312596321106\n",
      "___________________\n",
      "Epoch:220\n",
      "Loss:0.6692079305648804\n",
      "___________________\n",
      "Epoch:221\n",
      "Loss:0.6691036224365234\n",
      "___________________\n",
      "Epoch:222\n",
      "Loss:0.6689996123313904\n",
      "___________________\n",
      "Epoch:223\n",
      "Loss:0.6688959002494812\n",
      "___________________\n",
      "Epoch:224\n",
      "Loss:0.6687926054000854\n",
      "___________________\n",
      "Epoch:225\n",
      "Loss:0.6686895489692688\n",
      "___________________\n",
      "Epoch:226\n",
      "Loss:0.668586790561676\n",
      "___________________\n",
      "Epoch:227\n",
      "Loss:0.6684844493865967\n",
      "___________________\n",
      "Epoch:228\n",
      "Loss:0.6683824062347412\n",
      "___________________\n",
      "Epoch:229\n",
      "Loss:0.6682807803153992\n",
      "___________________\n",
      "Epoch:230\n",
      "Loss:0.6681795120239258\n",
      "___________________\n",
      "Epoch:231\n",
      "Loss:0.6680784225463867\n",
      "___________________\n",
      "Epoch:232\n",
      "Loss:0.6679778099060059\n",
      "___________________\n",
      "Epoch:233\n",
      "Loss:0.6678776144981384\n",
      "___________________\n",
      "Epoch:234\n",
      "Loss:0.6677777171134949\n",
      "___________________\n",
      "Epoch:235\n",
      "Loss:0.6676782369613647\n",
      "___________________\n",
      "Epoch:236\n",
      "Loss:0.6675791144371033\n",
      "___________________\n",
      "Epoch:237\n",
      "Loss:0.6674802899360657\n",
      "___________________\n",
      "Epoch:238\n",
      "Loss:0.6673819422721863\n",
      "___________________\n",
      "Epoch:239\n",
      "Loss:0.6672838926315308\n",
      "___________________\n",
      "Epoch:240\n",
      "Loss:0.6671863198280334\n",
      "___________________\n",
      "Epoch:241\n",
      "Loss:0.6670891642570496\n",
      "___________________\n",
      "Epoch:242\n",
      "Loss:0.6669923067092896\n",
      "___________________\n",
      "Epoch:243\n",
      "Loss:0.6668959856033325\n",
      "___________________\n",
      "Epoch:244\n",
      "Loss:0.6667999029159546\n",
      "___________________\n",
      "Epoch:245\n",
      "Loss:0.6667044162750244\n",
      "___________________\n",
      "Epoch:246\n",
      "Loss:0.6666091680526733\n",
      "___________________\n",
      "Epoch:247\n",
      "Loss:0.6665144562721252\n",
      "___________________\n",
      "Epoch:248\n",
      "Loss:0.666420042514801\n",
      "___________________\n",
      "Epoch:249\n",
      "Loss:0.6663261651992798\n",
      "___________________\n",
      "Epoch:250\n",
      "Loss:0.6662326455116272\n",
      "___________________\n",
      "Epoch:251\n",
      "Loss:0.666139543056488\n",
      "___________________\n",
      "Epoch:252\n",
      "Loss:0.6660468578338623\n",
      "___________________\n",
      "Epoch:253\n",
      "Loss:0.6659547090530396\n",
      "___________________\n",
      "Epoch:254\n",
      "Loss:0.6658629179000854\n",
      "___________________\n",
      "Epoch:255\n",
      "Loss:0.6657716035842896\n",
      "___________________\n",
      "Epoch:256\n",
      "Loss:0.6656807065010071\n",
      "___________________\n",
      "Epoch:257\n",
      "Loss:0.6655902862548828\n",
      "___________________\n",
      "Epoch:258\n",
      "Loss:0.6655002236366272\n",
      "___________________\n",
      "Epoch:259\n",
      "Loss:0.6654107570648193\n",
      "___________________\n",
      "Epoch:260\n",
      "Loss:0.6653216481208801\n",
      "___________________\n",
      "Epoch:261\n",
      "Loss:0.6652328968048096\n",
      "___________________\n",
      "Epoch:262\n",
      "Loss:0.6651447415351868\n",
      "___________________\n",
      "Epoch:263\n",
      "Loss:0.6650569438934326\n",
      "___________________\n",
      "Epoch:264\n",
      "Loss:0.6649697422981262\n",
      "___________________\n",
      "Epoch:265\n",
      "Loss:0.6648828983306885\n",
      "___________________\n",
      "Epoch:266\n",
      "Loss:0.6647965908050537\n",
      "___________________\n",
      "Epoch:267\n",
      "Loss:0.6647106409072876\n",
      "___________________\n",
      "Epoch:268\n",
      "Loss:0.6646251678466797\n",
      "___________________\n",
      "Epoch:269\n",
      "Loss:0.6645402908325195\n",
      "___________________\n",
      "Epoch:270\n",
      "Loss:0.664455771446228\n",
      "___________________\n",
      "Epoch:271\n",
      "Loss:0.66437166929245\n",
      "___________________\n",
      "Epoch:272\n",
      "Loss:0.6642881631851196\n",
      "___________________\n",
      "Epoch:273\n",
      "Loss:0.6642050743103027\n",
      "___________________\n",
      "Epoch:274\n",
      "Loss:0.6641225218772888\n",
      "___________________\n",
      "Epoch:275\n",
      "Loss:0.6640404462814331\n",
      "___________________\n",
      "Epoch:276\n",
      "Loss:0.6639586687088013\n",
      "___________________\n",
      "Epoch:277\n",
      "Loss:0.663877546787262\n",
      "___________________\n",
      "Epoch:278\n",
      "Loss:0.6637967824935913\n",
      "___________________\n",
      "Epoch:279\n",
      "Loss:0.6637165546417236\n",
      "___________________\n",
      "Epoch:280\n",
      "Loss:0.6636368036270142\n",
      "___________________\n",
      "Epoch:281\n",
      "Loss:0.6635575294494629\n",
      "___________________\n",
      "Epoch:282\n",
      "Loss:0.6634787321090698\n",
      "___________________\n",
      "Epoch:283\n",
      "Loss:0.663400411605835\n",
      "___________________\n",
      "Epoch:284\n",
      "Loss:0.6633226275444031\n",
      "___________________\n",
      "Epoch:285\n",
      "Loss:0.6632452011108398\n",
      "___________________\n",
      "Epoch:286\n",
      "Loss:0.6631683111190796\n",
      "___________________\n",
      "Epoch:287\n",
      "Loss:0.6630918979644775\n",
      "___________________\n",
      "Epoch:288\n",
      "Loss:0.6630159020423889\n",
      "___________________\n",
      "Epoch:289\n",
      "Loss:0.662940502166748\n",
      "___________________\n",
      "Epoch:290\n",
      "Loss:0.6628655195236206\n",
      "___________________\n",
      "Epoch:291\n",
      "Loss:0.6627910137176514\n",
      "___________________\n",
      "Epoch:292\n",
      "Loss:0.6627169847488403\n",
      "___________________\n",
      "Epoch:293\n",
      "Loss:0.6626434326171875\n",
      "___________________\n",
      "Epoch:294\n",
      "Loss:0.6625704169273376\n",
      "___________________\n",
      "Epoch:295\n",
      "Loss:0.6624978184700012\n",
      "___________________\n",
      "Epoch:296\n",
      "Loss:0.662425696849823\n",
      "___________________\n",
      "Epoch:297\n",
      "Loss:0.6623539924621582\n",
      "___________________\n",
      "Epoch:298\n",
      "Loss:0.6622827649116516\n",
      "___________________\n",
      "Epoch:299\n",
      "Loss:0.6622121334075928\n",
      "___________________\n",
      "Epoch:300\n",
      "Loss:0.6621419191360474\n",
      "___________________\n",
      "Epoch:301\n",
      "Loss:0.6620720624923706\n",
      "___________________\n",
      "Epoch:302\n",
      "Loss:0.6620028018951416\n",
      "___________________\n",
      "Epoch:303\n",
      "Loss:0.661933958530426\n",
      "___________________\n",
      "Epoch:304\n",
      "Loss:0.6618655323982239\n",
      "___________________\n",
      "Epoch:305\n",
      "Loss:0.6617976427078247\n",
      "___________________\n",
      "Epoch:306\n",
      "Loss:0.6617302298545837\n",
      "___________________\n",
      "Epoch:307\n",
      "Loss:0.661663293838501\n",
      "___________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:308\n",
      "Loss:0.6615967750549316\n",
      "___________________\n",
      "Epoch:309\n",
      "Loss:0.6615306735038757\n",
      "___________________\n",
      "Epoch:310\n",
      "Loss:0.6614651083946228\n",
      "___________________\n",
      "Epoch:311\n",
      "Loss:0.6613999009132385\n",
      "___________________\n",
      "Epoch:312\n",
      "Loss:0.6613352298736572\n",
      "___________________\n",
      "Epoch:313\n",
      "Loss:0.6612710356712341\n",
      "___________________\n",
      "Epoch:314\n",
      "Loss:0.6612071990966797\n",
      "___________________\n",
      "Epoch:315\n",
      "Loss:0.6611440181732178\n",
      "___________________\n",
      "Epoch:316\n",
      "Loss:0.661081075668335\n",
      "___________________\n",
      "Epoch:317\n",
      "Loss:0.6610186696052551\n",
      "___________________\n",
      "Epoch:318\n",
      "Loss:0.6609567403793335\n",
      "___________________\n",
      "Epoch:319\n",
      "Loss:0.6608952283859253\n",
      "___________________\n",
      "Epoch:320\n",
      "Loss:0.6608340740203857\n",
      "___________________\n",
      "Epoch:321\n",
      "Loss:0.6607734560966492\n",
      "___________________\n",
      "Epoch:322\n",
      "Loss:0.660713255405426\n",
      "___________________\n",
      "Epoch:323\n",
      "Loss:0.6606535315513611\n",
      "___________________\n",
      "Epoch:324\n",
      "Loss:0.6605941653251648\n",
      "___________________\n",
      "Epoch:325\n",
      "Loss:0.6605353355407715\n",
      "___________________\n",
      "Epoch:326\n",
      "Loss:0.6604768633842468\n",
      "___________________\n",
      "Epoch:327\n",
      "Loss:0.6604188680648804\n",
      "___________________\n",
      "Epoch:328\n",
      "Loss:0.6603612303733826\n",
      "___________________\n",
      "Epoch:329\n",
      "Loss:0.6603041291236877\n",
      "___________________\n",
      "Epoch:330\n",
      "Loss:0.6602474451065063\n",
      "___________________\n",
      "Epoch:331\n",
      "Loss:0.6601911187171936\n",
      "___________________\n",
      "Epoch:332\n",
      "Loss:0.6601352691650391\n",
      "___________________\n",
      "Epoch:333\n",
      "Loss:0.6600798964500427\n",
      "___________________\n",
      "Epoch:334\n",
      "Loss:0.6600248217582703\n",
      "___________________\n",
      "Epoch:335\n",
      "Loss:0.6599702835083008\n",
      "___________________\n",
      "Epoch:336\n",
      "Loss:0.6599161028862\n",
      "___________________\n",
      "Epoch:337\n",
      "Loss:0.6598623991012573\n",
      "___________________\n",
      "Epoch:338\n",
      "Loss:0.6598090529441833\n",
      "___________________\n",
      "Epoch:339\n",
      "Loss:0.6597561836242676\n",
      "___________________\n",
      "Epoch:340\n",
      "Loss:0.6597037315368652\n",
      "___________________\n",
      "Epoch:341\n",
      "Loss:0.6596516370773315\n",
      "___________________\n",
      "Epoch:342\n",
      "Loss:0.659600019454956\n",
      "___________________\n",
      "Epoch:343\n",
      "Loss:0.6595487594604492\n",
      "___________________\n",
      "Epoch:344\n",
      "Loss:0.6594979166984558\n",
      "___________________\n",
      "Epoch:345\n",
      "Loss:0.6594474911689758\n",
      "___________________\n",
      "Epoch:346\n",
      "Loss:0.6593974828720093\n",
      "___________________\n",
      "Epoch:347\n",
      "Loss:0.6593478322029114\n",
      "___________________\n",
      "Epoch:348\n",
      "Loss:0.6592986583709717\n",
      "___________________\n",
      "Epoch:349\n",
      "Loss:0.6592497825622559\n",
      "___________________\n",
      "Epoch:350\n",
      "Loss:0.659201443195343\n",
      "___________________\n",
      "Epoch:351\n",
      "Loss:0.659153401851654\n",
      "___________________\n",
      "Epoch:352\n",
      "Loss:0.6591057777404785\n",
      "___________________\n",
      "Epoch:353\n",
      "Loss:0.6590585112571716\n",
      "___________________\n",
      "Epoch:354\n",
      "Loss:0.6590117812156677\n",
      "___________________\n",
      "Epoch:355\n",
      "Loss:0.6589652895927429\n",
      "___________________\n",
      "Epoch:356\n",
      "Loss:0.6589192152023315\n",
      "___________________\n",
      "Epoch:357\n",
      "Loss:0.6588735580444336\n",
      "___________________\n",
      "Epoch:358\n",
      "Loss:0.6588283181190491\n",
      "___________________\n",
      "Epoch:359\n",
      "Loss:0.658783495426178\n",
      "___________________\n",
      "Epoch:360\n",
      "Loss:0.6587389707565308\n",
      "___________________\n",
      "Epoch:361\n",
      "Loss:0.6586948037147522\n",
      "___________________\n",
      "Epoch:362\n",
      "Loss:0.6586511135101318\n",
      "___________________\n",
      "Epoch:363\n",
      "Loss:0.6586078405380249\n",
      "___________________\n",
      "Epoch:364\n",
      "Loss:0.6585648655891418\n",
      "___________________\n",
      "Epoch:365\n",
      "Loss:0.6585221886634827\n",
      "___________________\n",
      "Epoch:366\n",
      "Loss:0.6584800481796265\n",
      "___________________\n",
      "Epoch:367\n",
      "Loss:0.6584382057189941\n",
      "___________________\n",
      "Epoch:368\n",
      "Loss:0.6583966612815857\n",
      "___________________\n",
      "Epoch:369\n",
      "Loss:0.6583555936813354\n",
      "___________________\n",
      "Epoch:370\n",
      "Loss:0.6583148241043091\n",
      "___________________\n",
      "Epoch:371\n",
      "Loss:0.6582744717597961\n",
      "___________________\n",
      "Epoch:372\n",
      "Loss:0.6582344770431519\n",
      "___________________\n",
      "Epoch:373\n",
      "Loss:0.6581948399543762\n",
      "___________________\n",
      "Epoch:374\n",
      "Loss:0.6581555604934692\n",
      "___________________\n",
      "Epoch:375\n",
      "Loss:0.6581165790557861\n",
      "___________________\n",
      "Epoch:376\n",
      "Loss:0.6580780148506165\n",
      "___________________\n",
      "Epoch:377\n",
      "Loss:0.6580398678779602\n",
      "___________________\n",
      "Epoch:378\n",
      "Loss:0.6580020785331726\n",
      "___________________\n",
      "Epoch:379\n",
      "Loss:0.6579645276069641\n",
      "___________________\n",
      "Epoch:380\n",
      "Loss:0.6579273343086243\n",
      "___________________\n",
      "Epoch:381\n",
      "Loss:0.6578904986381531\n",
      "___________________\n",
      "Epoch:382\n",
      "Loss:0.6578540802001953\n",
      "___________________\n",
      "Epoch:383\n",
      "Loss:0.6578180193901062\n",
      "___________________\n",
      "Epoch:384\n",
      "Loss:0.6577821969985962\n",
      "___________________\n",
      "Epoch:385\n",
      "Loss:0.6577468514442444\n",
      "___________________\n",
      "Epoch:386\n",
      "Loss:0.6577117443084717\n",
      "___________________\n",
      "Epoch:387\n",
      "Loss:0.6576769351959229\n",
      "___________________\n",
      "Epoch:388\n",
      "Loss:0.6576426029205322\n",
      "___________________\n",
      "Epoch:389\n",
      "Loss:0.6576085090637207\n",
      "___________________\n",
      "Epoch:390\n",
      "Loss:0.6575747728347778\n",
      "___________________\n",
      "Epoch:391\n",
      "Loss:0.6575413346290588\n",
      "___________________\n",
      "Epoch:392\n",
      "Loss:0.6575082540512085\n",
      "___________________\n",
      "Epoch:393\n",
      "Loss:0.657475471496582\n",
      "___________________\n",
      "Epoch:394\n",
      "Loss:0.6574430465698242\n",
      "___________________\n",
      "Epoch:395\n",
      "Loss:0.6574109196662903\n",
      "___________________\n",
      "Epoch:396\n",
      "Loss:0.6573790907859802\n",
      "___________________\n",
      "Epoch:397\n",
      "Loss:0.6573476791381836\n",
      "___________________\n",
      "Epoch:398\n",
      "Loss:0.6573165059089661\n",
      "___________________\n",
      "Epoch:399\n",
      "Loss:0.6572856307029724\n",
      "___________________\n",
      "Epoch:400\n",
      "Loss:0.6572550535202026\n",
      "___________________\n",
      "Epoch:401\n",
      "Loss:0.6572248339653015\n",
      "___________________\n",
      "Epoch:402\n",
      "Loss:0.6571949124336243\n",
      "___________________\n",
      "Epoch:403\n",
      "Loss:0.6571653485298157\n",
      "___________________\n",
      "Epoch:404\n",
      "Loss:0.6571360230445862\n",
      "___________________\n",
      "Epoch:405\n",
      "Loss:0.6571069955825806\n",
      "___________________\n",
      "Epoch:406\n",
      "Loss:0.6570782661437988\n",
      "___________________\n",
      "Epoch:407\n",
      "Loss:0.6570497751235962\n",
      "___________________\n",
      "Epoch:408\n",
      "Loss:0.657021701335907\n",
      "___________________\n",
      "Epoch:409\n",
      "Loss:0.6569938659667969\n",
      "___________________\n",
      "Epoch:410\n",
      "Loss:0.6569662690162659\n",
      "___________________\n",
      "Epoch:411\n",
      "Loss:0.6569390296936035\n",
      "___________________\n",
      "Epoch:412\n",
      "Loss:0.6569120287895203\n",
      "___________________\n",
      "Epoch:413\n",
      "Loss:0.6568853259086609\n",
      "___________________\n",
      "Epoch:414\n",
      "Loss:0.6568589210510254\n",
      "___________________\n",
      "Epoch:415\n",
      "Loss:0.6568328738212585\n",
      "___________________\n",
      "Epoch:416\n",
      "Loss:0.656807005405426\n",
      "___________________\n",
      "Epoch:417\n",
      "Loss:0.6567813754081726\n",
      "___________________\n",
      "Epoch:418\n",
      "Loss:0.6567559838294983\n",
      "___________________\n",
      "Epoch:419\n",
      "Loss:0.6567309498786926\n",
      "___________________\n",
      "Epoch:420\n",
      "Loss:0.6567062139511108\n",
      "___________________\n",
      "Epoch:421\n",
      "Loss:0.6566816568374634\n",
      "___________________\n",
      "Epoch:422\n",
      "Loss:0.6566573977470398\n",
      "___________________\n",
      "Epoch:423\n",
      "Loss:0.6566333770751953\n",
      "___________________\n",
      "Epoch:424\n",
      "Loss:0.6566096544265747\n",
      "___________________\n",
      "Epoch:425\n",
      "Loss:0.656586229801178\n",
      "___________________\n",
      "Epoch:426\n",
      "Loss:0.656562864780426\n",
      "___________________\n",
      "Epoch:427\n",
      "Loss:0.6565399169921875\n",
      "___________________\n",
      "Epoch:428\n",
      "Loss:0.6565172076225281\n",
      "___________________\n",
      "Epoch:429\n",
      "Loss:0.6564947366714478\n",
      "___________________\n",
      "Epoch:430\n",
      "Loss:0.6564724445343018\n",
      "___________________\n",
      "Epoch:431\n",
      "Loss:0.6564505100250244\n",
      "___________________\n",
      "Epoch:432\n",
      "Loss:0.6564286947250366\n",
      "___________________\n",
      "Epoch:433\n",
      "Loss:0.6564072370529175\n",
      "___________________\n",
      "Epoch:434\n",
      "Loss:0.6563858389854431\n",
      "___________________\n",
      "Epoch:435\n",
      "Loss:0.6563647389411926\n",
      "___________________\n",
      "Epoch:436\n",
      "Loss:0.656343936920166\n",
      "___________________\n",
      "Epoch:437\n",
      "Loss:0.6563233137130737\n",
      "___________________\n",
      "Epoch:438\n",
      "Loss:0.6563029289245605\n",
      "___________________\n",
      "Epoch:439\n",
      "Loss:0.6562827229499817\n",
      "___________________\n",
      "Epoch:440\n",
      "Loss:0.6562628149986267\n",
      "___________________\n",
      "Epoch:441\n",
      "Loss:0.656243085861206\n",
      "___________________\n",
      "Epoch:442\n",
      "Loss:0.6562235355377197\n",
      "___________________\n",
      "Epoch:443\n",
      "Loss:0.6562042236328125\n",
      "___________________\n",
      "Epoch:444\n",
      "Loss:0.6561850905418396\n",
      "___________________\n",
      "Epoch:445\n",
      "Loss:0.6561662554740906\n",
      "___________________\n",
      "Epoch:446\n",
      "Loss:0.6561475396156311\n",
      "___________________\n",
      "Epoch:447\n",
      "Loss:0.6561290621757507\n",
      "___________________\n",
      "Epoch:448\n",
      "Loss:0.6561107635498047\n",
      "___________________\n",
      "Epoch:449\n",
      "Loss:0.6560927629470825\n",
      "___________________\n",
      "Epoch:450\n",
      "Loss:0.6560748219490051\n",
      "___________________\n",
      "Epoch:451\n",
      "Loss:0.6560570597648621\n",
      "___________________\n",
      "Epoch:452\n",
      "Loss:0.6560395359992981\n",
      "___________________\n",
      "Epoch:453\n",
      "Loss:0.6560222506523132\n",
      "___________________\n",
      "Epoch:454\n",
      "Loss:0.6560052037239075\n",
      "___________________\n",
      "Epoch:455\n",
      "Loss:0.6559881567955017\n",
      "___________________\n",
      "Epoch:456\n",
      "Loss:0.6559714078903198\n",
      "___________________\n",
      "Epoch:457\n",
      "Loss:0.655954897403717\n",
      "___________________\n",
      "Epoch:458\n",
      "Loss:0.6559385061264038\n",
      "___________________\n",
      "Epoch:459\n",
      "Loss:0.6559222936630249\n",
      "___________________\n",
      "Epoch:460\n",
      "Loss:0.6559061408042908\n",
      "___________________\n",
      "Epoch:461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.6558902263641357\n",
      "___________________\n",
      "Epoch:462\n",
      "Loss:0.6558746099472046\n",
      "___________________\n",
      "Epoch:463\n",
      "Loss:0.6558590531349182\n",
      "___________________\n",
      "Epoch:464\n",
      "Loss:0.6558436751365662\n",
      "___________________\n",
      "Epoch:465\n",
      "Loss:0.6558284163475037\n",
      "___________________\n",
      "Epoch:466\n",
      "Loss:0.6558133363723755\n",
      "___________________\n",
      "Epoch:467\n",
      "Loss:0.6557984948158264\n",
      "___________________\n",
      "Epoch:468\n",
      "Loss:0.6557837128639221\n",
      "___________________\n",
      "Epoch:469\n",
      "Loss:0.6557691693305969\n",
      "___________________\n",
      "Epoch:470\n",
      "Loss:0.655754566192627\n",
      "___________________\n",
      "Epoch:471\n",
      "Loss:0.6557403802871704\n",
      "___________________\n",
      "Epoch:472\n",
      "Loss:0.6557262539863586\n",
      "___________________\n",
      "Epoch:473\n",
      "Loss:0.6557121872901917\n",
      "___________________\n",
      "Epoch:474\n",
      "Loss:0.6556983590126038\n",
      "___________________\n",
      "Epoch:475\n",
      "Loss:0.6556846499443054\n",
      "___________________\n",
      "Epoch:476\n",
      "Loss:0.6556710600852966\n",
      "___________________\n",
      "Epoch:477\n",
      "Loss:0.6556577086448669\n",
      "___________________\n",
      "Epoch:478\n",
      "Loss:0.6556443572044373\n",
      "___________________\n",
      "Epoch:479\n",
      "Loss:0.6556311249732971\n",
      "___________________\n",
      "Epoch:480\n",
      "Loss:0.6556181907653809\n",
      "___________________\n",
      "Epoch:481\n",
      "Loss:0.6556052565574646\n",
      "___________________\n",
      "Epoch:482\n",
      "Loss:0.6555925011634827\n",
      "___________________\n",
      "Epoch:483\n",
      "Loss:0.6555798053741455\n",
      "___________________\n",
      "Epoch:484\n",
      "Loss:0.6555672883987427\n",
      "___________________\n",
      "Epoch:485\n",
      "Loss:0.6555548906326294\n",
      "___________________\n",
      "Epoch:486\n",
      "Loss:0.6555425524711609\n",
      "___________________\n",
      "Epoch:487\n",
      "Loss:0.6555303931236267\n",
      "___________________\n",
      "Epoch:488\n",
      "Loss:0.6555183529853821\n",
      "___________________\n",
      "Epoch:489\n",
      "Loss:0.6555064916610718\n",
      "___________________\n",
      "Epoch:490\n",
      "Loss:0.6554946303367615\n",
      "___________________\n",
      "Epoch:491\n",
      "Loss:0.6554828882217407\n",
      "___________________\n",
      "Epoch:492\n",
      "Loss:0.6554712653160095\n",
      "___________________\n",
      "Epoch:493\n",
      "Loss:0.6554598212242126\n",
      "___________________\n",
      "Epoch:494\n",
      "Loss:0.6554484367370605\n",
      "___________________\n",
      "Epoch:495\n",
      "Loss:0.6554371118545532\n",
      "___________________\n",
      "Epoch:496\n",
      "Loss:0.6554259061813354\n",
      "___________________\n",
      "Epoch:497\n",
      "Loss:0.6554148197174072\n",
      "___________________\n",
      "Epoch:498\n",
      "Loss:0.6554038524627686\n",
      "___________________\n",
      "Epoch:499\n",
      "Loss:0.6553929448127747\n",
      "___________________\n",
      "Epoch:500\n",
      "Loss:0.6553822159767151\n",
      "___________________\n",
      "Epoch:501\n",
      "Loss:0.6553715467453003\n",
      "___________________\n",
      "Epoch:502\n",
      "Loss:0.6553608775138855\n",
      "___________________\n",
      "Epoch:503\n",
      "Loss:0.655350387096405\n",
      "___________________\n",
      "Epoch:504\n",
      "Loss:0.6553399562835693\n",
      "___________________\n",
      "Epoch:505\n",
      "Loss:0.6553296446800232\n",
      "___________________\n",
      "Epoch:506\n",
      "Loss:0.6553193926811218\n",
      "___________________\n",
      "Epoch:507\n",
      "Loss:0.6553092002868652\n",
      "___________________\n",
      "Epoch:508\n",
      "Loss:0.6552992463111877\n",
      "___________________\n",
      "Epoch:509\n",
      "Loss:0.6552891731262207\n",
      "___________________\n",
      "Epoch:510\n",
      "Loss:0.6552792191505432\n",
      "___________________\n",
      "Epoch:511\n",
      "Loss:0.6552694439888\n",
      "___________________\n",
      "Epoch:512\n",
      "Loss:0.6552596688270569\n",
      "___________________\n",
      "Epoch:513\n",
      "Loss:0.655250072479248\n",
      "___________________\n",
      "Epoch:514\n",
      "Loss:0.6552403569221497\n",
      "___________________\n",
      "Epoch:515\n",
      "Loss:0.6552308797836304\n",
      "___________________\n",
      "Epoch:516\n",
      "Loss:0.6552214622497559\n",
      "___________________\n",
      "Epoch:517\n",
      "Loss:0.6552120447158813\n",
      "___________________\n",
      "Epoch:518\n",
      "Loss:0.6552027463912964\n",
      "___________________\n",
      "Epoch:519\n",
      "Loss:0.6551934480667114\n",
      "___________________\n",
      "Epoch:520\n",
      "Loss:0.655184268951416\n",
      "___________________\n",
      "Epoch:521\n",
      "Loss:0.6551751494407654\n",
      "___________________\n",
      "Epoch:522\n",
      "Loss:0.6551661491394043\n",
      "___________________\n",
      "Epoch:523\n",
      "Loss:0.6551571488380432\n",
      "___________________\n",
      "Epoch:524\n",
      "Loss:0.6551482677459717\n",
      "___________________\n",
      "Epoch:525\n",
      "Loss:0.6551393270492554\n",
      "___________________\n",
      "Epoch:526\n",
      "Loss:0.6551306843757629\n",
      "___________________\n",
      "Epoch:527\n",
      "Loss:0.6551218628883362\n",
      "___________________\n",
      "Epoch:528\n",
      "Loss:0.655113160610199\n",
      "___________________\n",
      "Epoch:529\n",
      "Loss:0.6551045179367065\n",
      "___________________\n",
      "Epoch:530\n",
      "Loss:0.6550959944725037\n",
      "___________________\n",
      "Epoch:531\n",
      "Loss:0.6550874710083008\n",
      "___________________\n",
      "Epoch:532\n",
      "Loss:0.6550790071487427\n",
      "___________________\n",
      "Epoch:533\n",
      "Loss:0.6550706028938293\n",
      "___________________\n",
      "Epoch:534\n",
      "Loss:0.655062198638916\n",
      "___________________\n",
      "Epoch:535\n",
      "Loss:0.6550540328025818\n",
      "___________________\n",
      "Epoch:536\n",
      "Loss:0.6550456881523132\n",
      "___________________\n",
      "Epoch:537\n",
      "Loss:0.655037522315979\n",
      "___________________\n",
      "Epoch:538\n",
      "Loss:0.6550294160842896\n",
      "___________________\n",
      "Epoch:539\n",
      "Loss:0.6550211906433105\n",
      "___________________\n",
      "Epoch:540\n",
      "Loss:0.6550131440162659\n",
      "___________________\n",
      "Epoch:541\n",
      "Loss:0.655005156993866\n",
      "___________________\n",
      "Epoch:542\n",
      "Loss:0.6549972295761108\n",
      "___________________\n",
      "Epoch:543\n",
      "Loss:0.6549893021583557\n",
      "___________________\n",
      "Epoch:544\n",
      "Loss:0.6549813747406006\n",
      "___________________\n",
      "Epoch:545\n",
      "Loss:0.6549735069274902\n",
      "___________________\n",
      "Epoch:546\n",
      "Loss:0.6549656987190247\n",
      "___________________\n",
      "Epoch:547\n",
      "Loss:0.6549579501152039\n",
      "___________________\n",
      "Epoch:548\n",
      "Loss:0.6549502611160278\n",
      "___________________\n",
      "Epoch:549\n",
      "Loss:0.6549425721168518\n",
      "___________________\n",
      "Epoch:550\n",
      "Loss:0.6549348831176758\n",
      "___________________\n",
      "Epoch:551\n",
      "Loss:0.6549273729324341\n",
      "___________________\n",
      "Epoch:552\n",
      "Loss:0.6549197435379028\n",
      "___________________\n",
      "Epoch:553\n",
      "Loss:0.6549121737480164\n",
      "___________________\n",
      "Epoch:554\n",
      "Loss:0.6549046039581299\n",
      "___________________\n",
      "Epoch:555\n",
      "Loss:0.654897153377533\n",
      "___________________\n",
      "Epoch:556\n",
      "Loss:0.6548897624015808\n",
      "___________________\n",
      "Epoch:557\n",
      "Loss:0.6548822522163391\n",
      "___________________\n",
      "Epoch:558\n",
      "Loss:0.6548749208450317\n",
      "___________________\n",
      "Epoch:559\n",
      "Loss:0.6548675894737244\n",
      "___________________\n",
      "Epoch:560\n",
      "Loss:0.654860258102417\n",
      "___________________\n",
      "Epoch:561\n",
      "Loss:0.6548530459403992\n",
      "___________________\n",
      "Epoch:562\n",
      "Loss:0.6548457741737366\n",
      "___________________\n",
      "Epoch:563\n",
      "Loss:0.654838502407074\n",
      "___________________\n",
      "Epoch:564\n",
      "Loss:0.6548312902450562\n",
      "___________________\n",
      "Epoch:565\n",
      "Loss:0.6548241376876831\n",
      "___________________\n",
      "Epoch:566\n",
      "Loss:0.6548169851303101\n",
      "___________________\n",
      "Epoch:567\n",
      "Loss:0.6548098921775818\n",
      "___________________\n",
      "Epoch:568\n",
      "Loss:0.6548027396202087\n",
      "___________________\n",
      "Epoch:569\n",
      "Loss:0.6547957062721252\n",
      "___________________\n",
      "Epoch:570\n",
      "Loss:0.6547886729240417\n",
      "___________________\n",
      "Epoch:571\n",
      "Loss:0.6547816395759583\n",
      "___________________\n",
      "Epoch:572\n",
      "Loss:0.6547746062278748\n",
      "___________________\n",
      "Epoch:573\n",
      "Loss:0.6547676920890808\n",
      "___________________\n",
      "Epoch:574\n",
      "Loss:0.6547606587409973\n",
      "___________________\n",
      "Epoch:575\n",
      "Loss:0.6547536849975586\n",
      "___________________\n",
      "Epoch:576\n",
      "Loss:0.6547468900680542\n",
      "___________________\n",
      "Epoch:577\n",
      "Loss:0.6547399163246155\n",
      "___________________\n",
      "Epoch:578\n",
      "Loss:0.6547331213951111\n",
      "___________________\n",
      "Epoch:579\n",
      "Loss:0.6547262072563171\n",
      "___________________\n",
      "Epoch:580\n",
      "Loss:0.6547194123268127\n",
      "___________________\n",
      "Epoch:581\n",
      "Loss:0.6547124981880188\n",
      "___________________\n",
      "Epoch:582\n",
      "Loss:0.6547057628631592\n",
      "___________________\n",
      "Epoch:583\n",
      "Loss:0.65469890832901\n",
      "___________________\n",
      "Epoch:584\n",
      "Loss:0.6546921730041504\n",
      "___________________\n",
      "Epoch:585\n",
      "Loss:0.6546854972839355\n",
      "___________________\n",
      "Epoch:586\n",
      "Loss:0.6546788215637207\n",
      "___________________\n",
      "Epoch:587\n",
      "Loss:0.6546720862388611\n",
      "___________________\n",
      "Epoch:588\n",
      "Loss:0.6546653509140015\n",
      "___________________\n",
      "Epoch:589\n",
      "Loss:0.6546586155891418\n",
      "___________________\n",
      "Epoch:590\n",
      "Loss:0.654651939868927\n",
      "___________________\n",
      "Epoch:591\n",
      "Loss:0.6546453237533569\n",
      "___________________\n",
      "Epoch:592\n",
      "Loss:0.6546386480331421\n",
      "___________________\n",
      "Epoch:593\n",
      "Loss:0.654632031917572\n",
      "___________________\n",
      "Epoch:594\n",
      "Loss:0.6546254754066467\n",
      "___________________\n",
      "Epoch:595\n",
      "Loss:0.6546188592910767\n",
      "___________________\n",
      "Epoch:596\n",
      "Loss:0.6546123027801514\n",
      "___________________\n",
      "Epoch:597\n",
      "Loss:0.6546057462692261\n",
      "___________________\n",
      "Epoch:598\n",
      "Loss:0.654599130153656\n",
      "___________________\n",
      "Epoch:599\n",
      "Loss:0.6545926928520203\n",
      "___________________\n",
      "Epoch:600\n",
      "Loss:0.654586136341095\n",
      "___________________\n",
      "Epoch:601\n",
      "Loss:0.6545795798301697\n",
      "___________________\n",
      "Epoch:602\n",
      "Loss:0.6545730233192444\n",
      "___________________\n",
      "Epoch:603\n",
      "Loss:0.6545665860176086\n",
      "___________________\n",
      "Epoch:604\n",
      "Loss:0.6545600891113281\n",
      "___________________\n",
      "Epoch:605\n",
      "Loss:0.6545535922050476\n",
      "___________________\n",
      "Epoch:606\n",
      "Loss:0.6545471549034119\n",
      "___________________\n",
      "Epoch:607\n",
      "Loss:0.6545407176017761\n",
      "___________________\n",
      "Epoch:608\n",
      "Loss:0.6545342803001404\n",
      "___________________\n",
      "Epoch:609\n",
      "Loss:0.6545279026031494\n",
      "___________________\n",
      "Epoch:610\n",
      "Loss:0.6545214056968689\n",
      "___________________\n",
      "Epoch:611\n",
      "Loss:0.6545150279998779\n",
      "___________________\n",
      "Epoch:612\n",
      "Loss:0.6545085310935974\n",
      "___________________\n",
      "Epoch:613\n",
      "Loss:0.6545021533966064\n",
      "___________________\n",
      "Epoch:614\n",
      "Loss:0.6544957756996155\n",
      "___________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:615\n",
      "Loss:0.6544893383979797\n",
      "___________________\n",
      "Epoch:616\n",
      "Loss:0.6544830799102783\n",
      "___________________\n",
      "Epoch:617\n",
      "Loss:0.6544766426086426\n",
      "___________________\n",
      "Epoch:618\n",
      "Loss:0.6544703245162964\n",
      "___________________\n",
      "Epoch:619\n",
      "Loss:0.6544639468193054\n",
      "___________________\n",
      "Epoch:620\n",
      "Loss:0.6544576287269592\n",
      "___________________\n",
      "Epoch:621\n",
      "Loss:0.6544512510299683\n",
      "___________________\n",
      "Epoch:622\n",
      "Loss:0.6544449329376221\n",
      "___________________\n",
      "Epoch:623\n",
      "Loss:0.6544386148452759\n",
      "___________________\n",
      "Epoch:624\n",
      "Loss:0.6544322967529297\n",
      "___________________\n",
      "Epoch:625\n",
      "Loss:0.6544259786605835\n",
      "___________________\n",
      "Epoch:626\n",
      "Loss:0.6544196009635925\n",
      "___________________\n",
      "Epoch:627\n",
      "Loss:0.6544133424758911\n",
      "___________________\n",
      "Epoch:628\n",
      "Loss:0.6544070243835449\n",
      "___________________\n",
      "Epoch:629\n",
      "Loss:0.6544007658958435\n",
      "___________________\n",
      "Epoch:630\n",
      "Loss:0.6543945074081421\n",
      "___________________\n",
      "Epoch:631\n",
      "Loss:0.6543881893157959\n",
      "___________________\n",
      "Epoch:632\n",
      "Loss:0.6543819308280945\n",
      "___________________\n",
      "Epoch:633\n",
      "Loss:0.6543756723403931\n",
      "___________________\n",
      "Epoch:634\n",
      "Loss:0.6543694138526917\n",
      "___________________\n",
      "Epoch:635\n",
      "Loss:0.6543631553649902\n",
      "___________________\n",
      "Epoch:636\n",
      "Loss:0.654356837272644\n",
      "___________________\n",
      "Epoch:637\n",
      "Loss:0.6543506979942322\n",
      "___________________\n",
      "Epoch:638\n",
      "Loss:0.6543444395065308\n",
      "___________________\n",
      "Epoch:639\n",
      "Loss:0.6543380618095398\n",
      "___________________\n",
      "Epoch:640\n",
      "Loss:0.6543319225311279\n",
      "___________________\n",
      "Epoch:641\n",
      "Loss:0.6543256044387817\n",
      "___________________\n",
      "Epoch:642\n",
      "Loss:0.6543195247650146\n",
      "___________________\n",
      "Epoch:643\n",
      "Loss:0.6543132066726685\n",
      "___________________\n",
      "Epoch:644\n",
      "Loss:0.6543070077896118\n",
      "___________________\n",
      "Epoch:645\n",
      "Loss:0.6543008089065552\n",
      "___________________\n",
      "Epoch:646\n",
      "Loss:0.6542945504188538\n",
      "___________________\n",
      "Epoch:647\n",
      "Loss:0.6542883515357971\n",
      "___________________\n",
      "Epoch:648\n",
      "Loss:0.6542821526527405\n",
      "___________________\n",
      "Epoch:649\n",
      "Loss:0.6542759537696838\n",
      "___________________\n",
      "Epoch:650\n",
      "Loss:0.6542697548866272\n",
      "___________________\n",
      "Epoch:651\n",
      "Loss:0.6542634963989258\n",
      "___________________\n",
      "Epoch:652\n",
      "Loss:0.6542572975158691\n",
      "___________________\n",
      "Epoch:653\n",
      "Loss:0.6542511582374573\n",
      "___________________\n",
      "Epoch:654\n",
      "Loss:0.6542448997497559\n",
      "___________________\n",
      "Epoch:655\n",
      "Loss:0.654238760471344\n",
      "___________________\n",
      "Epoch:656\n",
      "Loss:0.6542325019836426\n",
      "___________________\n",
      "Epoch:657\n",
      "Loss:0.6542263627052307\n",
      "___________________\n",
      "Epoch:658\n",
      "Loss:0.6542201042175293\n",
      "___________________\n",
      "Epoch:659\n",
      "Loss:0.654214084148407\n",
      "___________________\n",
      "Epoch:660\n",
      "Loss:0.6542078256607056\n",
      "___________________\n",
      "Epoch:661\n",
      "Loss:0.6542016863822937\n",
      "___________________\n",
      "Epoch:662\n",
      "Loss:0.6541954278945923\n",
      "___________________\n",
      "Epoch:663\n",
      "Loss:0.6541892290115356\n",
      "___________________\n",
      "Epoch:664\n",
      "Loss:0.6541830897331238\n",
      "___________________\n",
      "Epoch:665\n",
      "Loss:0.6541769504547119\n",
      "___________________\n",
      "Epoch:666\n",
      "Loss:0.6541708111763\n",
      "___________________\n",
      "Epoch:667\n",
      "Loss:0.6541646122932434\n",
      "___________________\n",
      "Epoch:668\n",
      "Loss:0.6541584730148315\n",
      "___________________\n",
      "Epoch:669\n",
      "Loss:0.6541522741317749\n",
      "___________________\n",
      "Epoch:670\n",
      "Loss:0.654146134853363\n",
      "___________________\n",
      "Epoch:671\n",
      "Loss:0.654140055179596\n",
      "___________________\n",
      "Epoch:672\n",
      "Loss:0.6541337966918945\n",
      "___________________\n",
      "Epoch:673\n",
      "Loss:0.6541276574134827\n",
      "___________________\n",
      "Epoch:674\n",
      "Loss:0.654121458530426\n",
      "___________________\n",
      "Epoch:675\n",
      "Loss:0.6541153192520142\n",
      "___________________\n",
      "Epoch:676\n",
      "Loss:0.6541091799736023\n",
      "___________________\n",
      "Epoch:677\n",
      "Loss:0.6541030406951904\n",
      "___________________\n",
      "Epoch:678\n",
      "Loss:0.6540969014167786\n",
      "___________________\n",
      "Epoch:679\n",
      "Loss:0.6540907025337219\n",
      "___________________\n",
      "Epoch:680\n",
      "Loss:0.6540845632553101\n",
      "___________________\n",
      "Epoch:681\n",
      "Loss:0.654078483581543\n",
      "___________________\n",
      "Epoch:682\n",
      "Loss:0.6540722846984863\n",
      "___________________\n",
      "Epoch:683\n",
      "Loss:0.6540661454200745\n",
      "___________________\n",
      "Epoch:684\n",
      "Loss:0.6540599465370178\n",
      "___________________\n",
      "Epoch:685\n",
      "Loss:0.6540539264678955\n",
      "___________________\n",
      "Epoch:686\n",
      "Loss:0.6540477275848389\n",
      "___________________\n",
      "Epoch:687\n",
      "Loss:0.654041588306427\n",
      "___________________\n",
      "Epoch:688\n",
      "Loss:0.6540354490280151\n",
      "___________________\n",
      "Epoch:689\n",
      "Loss:0.6540292501449585\n",
      "___________________\n",
      "Epoch:690\n",
      "Loss:0.6540231704711914\n",
      "___________________\n",
      "Epoch:691\n",
      "Loss:0.6540169715881348\n",
      "___________________\n",
      "Epoch:692\n",
      "Loss:0.6540108919143677\n",
      "___________________\n",
      "Epoch:693\n",
      "Loss:0.6540048122406006\n",
      "___________________\n",
      "Epoch:694\n",
      "Loss:0.653998613357544\n",
      "___________________\n",
      "Epoch:695\n",
      "Loss:0.6539923548698425\n",
      "___________________\n",
      "Epoch:696\n",
      "Loss:0.6539863348007202\n",
      "___________________\n",
      "Epoch:697\n",
      "Loss:0.6539801955223083\n",
      "___________________\n",
      "Epoch:698\n",
      "Loss:0.6539739966392517\n",
      "___________________\n",
      "Epoch:699\n",
      "Loss:0.6539679765701294\n",
      "___________________\n",
      "Epoch:700\n",
      "Loss:0.6539617776870728\n",
      "___________________\n",
      "Epoch:701\n",
      "Loss:0.6539556384086609\n",
      "___________________\n",
      "Epoch:702\n",
      "Loss:0.6539495587348938\n",
      "___________________\n",
      "Epoch:703\n",
      "Loss:0.6539433598518372\n",
      "___________________\n",
      "Epoch:704\n",
      "Loss:0.6539372205734253\n",
      "___________________\n",
      "Epoch:705\n",
      "Loss:0.6539311408996582\n",
      "___________________\n",
      "Epoch:706\n",
      "Loss:0.6539250016212463\n",
      "___________________\n",
      "Epoch:707\n",
      "Loss:0.6539188623428345\n",
      "___________________\n",
      "Epoch:708\n",
      "Loss:0.6539127230644226\n",
      "___________________\n",
      "Epoch:709\n",
      "Loss:0.6539065837860107\n",
      "___________________\n",
      "Epoch:710\n",
      "Loss:0.6539005041122437\n",
      "___________________\n",
      "Epoch:711\n",
      "Loss:0.653894305229187\n",
      "___________________\n",
      "Epoch:712\n",
      "Loss:0.6538881659507751\n",
      "___________________\n",
      "Epoch:713\n",
      "Loss:0.6538821458816528\n",
      "___________________\n",
      "Epoch:714\n",
      "Loss:0.6538758873939514\n",
      "___________________\n",
      "Epoch:715\n",
      "Loss:0.6538697481155396\n",
      "___________________\n",
      "Epoch:716\n",
      "Loss:0.6538636684417725\n",
      "___________________\n",
      "Epoch:717\n",
      "Loss:0.6538575291633606\n",
      "___________________\n",
      "Epoch:718\n",
      "Loss:0.6538514494895935\n",
      "___________________\n",
      "Epoch:719\n",
      "Loss:0.6538452506065369\n",
      "___________________\n",
      "Epoch:720\n",
      "Loss:0.6538391709327698\n",
      "___________________\n",
      "Epoch:721\n",
      "Loss:0.6538330316543579\n",
      "___________________\n",
      "Epoch:722\n",
      "Loss:0.6538269519805908\n",
      "___________________\n",
      "Epoch:723\n",
      "Loss:0.653820812702179\n",
      "___________________\n",
      "Epoch:724\n",
      "Loss:0.6538146138191223\n",
      "___________________\n",
      "Epoch:725\n",
      "Loss:0.6538084745407104\n",
      "___________________\n",
      "Epoch:726\n",
      "Loss:0.6538023948669434\n",
      "___________________\n",
      "Epoch:727\n",
      "Loss:0.6537963151931763\n",
      "___________________\n",
      "Epoch:728\n",
      "Loss:0.6537901163101196\n",
      "___________________\n",
      "Epoch:729\n",
      "Loss:0.6537840366363525\n",
      "___________________\n",
      "Epoch:730\n",
      "Loss:0.6537778973579407\n",
      "___________________\n",
      "Epoch:731\n",
      "Loss:0.6537717580795288\n",
      "___________________\n",
      "Epoch:732\n",
      "Loss:0.6537656188011169\n",
      "___________________\n",
      "Epoch:733\n",
      "Loss:0.6537595391273499\n",
      "___________________\n",
      "Epoch:734\n",
      "Loss:0.6537533402442932\n",
      "___________________\n",
      "Epoch:735\n",
      "Loss:0.6537472605705261\n",
      "___________________\n",
      "Epoch:736\n",
      "Loss:0.653741180896759\n",
      "___________________\n",
      "Epoch:737\n",
      "Loss:0.6537349820137024\n",
      "___________________\n",
      "Epoch:738\n",
      "Loss:0.6537288427352905\n",
      "___________________\n",
      "Epoch:739\n",
      "Loss:0.6537227630615234\n",
      "___________________\n",
      "Epoch:740\n",
      "Loss:0.6537166237831116\n",
      "___________________\n",
      "Epoch:741\n",
      "Loss:0.6537104249000549\n",
      "___________________\n",
      "Epoch:742\n",
      "Loss:0.6537043452262878\n",
      "___________________\n",
      "Epoch:743\n",
      "Loss:0.6536982655525208\n",
      "___________________\n",
      "Epoch:744\n",
      "Loss:0.6536921262741089\n",
      "___________________\n",
      "Epoch:745\n",
      "Loss:0.6536859273910522\n",
      "___________________\n",
      "Epoch:746\n",
      "Loss:0.6536799073219299\n",
      "___________________\n",
      "Epoch:747\n",
      "Loss:0.6536737084388733\n",
      "___________________\n",
      "Epoch:748\n",
      "Loss:0.6536675691604614\n",
      "___________________\n",
      "Epoch:749\n",
      "Loss:0.6536614894866943\n",
      "___________________\n",
      "Epoch:750\n",
      "Loss:0.6536553502082825\n",
      "___________________\n",
      "Epoch:751\n",
      "Loss:0.6536492705345154\n",
      "___________________\n",
      "Epoch:752\n",
      "Loss:0.6536430716514587\n",
      "___________________\n",
      "Epoch:753\n",
      "Loss:0.6536369919776917\n",
      "___________________\n",
      "Epoch:754\n",
      "Loss:0.6536308526992798\n",
      "___________________\n",
      "Epoch:755\n",
      "Loss:0.6536247134208679\n",
      "___________________\n",
      "Epoch:756\n",
      "Loss:0.6536186337471008\n",
      "___________________\n",
      "Epoch:757\n",
      "Loss:0.653612494468689\n",
      "___________________\n",
      "Epoch:758\n",
      "Loss:0.6536064743995667\n",
      "___________________\n",
      "Epoch:759\n",
      "Loss:0.65360027551651\n",
      "___________________\n",
      "Epoch:760\n",
      "Loss:0.6535940766334534\n",
      "___________________\n",
      "Epoch:761\n",
      "Loss:0.6535879969596863\n",
      "___________________\n",
      "Epoch:762\n",
      "Loss:0.6535819172859192\n",
      "___________________\n",
      "Epoch:763\n",
      "Loss:0.6535757780075073\n",
      "___________________\n",
      "Epoch:764\n",
      "Loss:0.6535696983337402\n",
      "___________________\n",
      "Epoch:765\n",
      "Loss:0.6535634994506836\n",
      "___________________\n",
      "Epoch:766\n",
      "Loss:0.6535574197769165\n",
      "___________________\n",
      "Epoch:767\n",
      "Loss:0.6535512804985046\n",
      "___________________\n",
      "Epoch:768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.6535452008247375\n",
      "___________________\n",
      "Epoch:769\n",
      "Loss:0.6535390615463257\n",
      "___________________\n",
      "Epoch:770\n",
      "Loss:0.6535329222679138\n",
      "___________________\n",
      "Epoch:771\n",
      "Loss:0.6535268425941467\n",
      "___________________\n",
      "Epoch:772\n",
      "Loss:0.6535207033157349\n",
      "___________________\n",
      "Epoch:773\n",
      "Loss:0.653514564037323\n",
      "___________________\n",
      "Epoch:774\n",
      "Loss:0.6535084247589111\n",
      "___________________\n",
      "Epoch:775\n",
      "Loss:0.6535024046897888\n",
      "___________________\n",
      "Epoch:776\n",
      "Loss:0.653496265411377\n",
      "___________________\n",
      "Epoch:777\n",
      "Loss:0.6534901261329651\n",
      "___________________\n",
      "Epoch:778\n",
      "Loss:0.6534841060638428\n",
      "___________________\n",
      "Epoch:779\n",
      "Loss:0.6534779071807861\n",
      "___________________\n",
      "Epoch:780\n",
      "Loss:0.6534717679023743\n",
      "___________________\n",
      "Epoch:781\n",
      "Loss:0.6534656286239624\n",
      "___________________\n",
      "Epoch:782\n",
      "Loss:0.6534594893455505\n",
      "___________________\n",
      "Epoch:783\n",
      "Loss:0.6534534096717834\n",
      "___________________\n",
      "Epoch:784\n",
      "Loss:0.6534473896026611\n",
      "___________________\n",
      "Epoch:785\n",
      "Loss:0.6534411907196045\n",
      "___________________\n",
      "Epoch:786\n",
      "Loss:0.6534351706504822\n",
      "___________________\n",
      "Epoch:787\n",
      "Loss:0.6534290313720703\n",
      "___________________\n",
      "Epoch:788\n",
      "Loss:0.6534228920936584\n",
      "___________________\n",
      "Epoch:789\n",
      "Loss:0.6534168124198914\n",
      "___________________\n",
      "Epoch:790\n",
      "Loss:0.6534106731414795\n",
      "___________________\n",
      "Epoch:791\n",
      "Loss:0.6534045934677124\n",
      "___________________\n",
      "Epoch:792\n",
      "Loss:0.6533984541893005\n",
      "___________________\n",
      "Epoch:793\n",
      "Loss:0.6533923149108887\n",
      "___________________\n",
      "Epoch:794\n",
      "Loss:0.6533862352371216\n",
      "___________________\n",
      "Epoch:795\n",
      "Loss:0.6533801555633545\n",
      "___________________\n",
      "Epoch:796\n",
      "Loss:0.6533739566802979\n",
      "___________________\n",
      "Epoch:797\n",
      "Loss:0.6533678770065308\n",
      "___________________\n",
      "Epoch:798\n",
      "Loss:0.6533617973327637\n",
      "___________________\n",
      "Epoch:799\n",
      "Loss:0.6533556580543518\n",
      "___________________\n",
      "Epoch:800\n",
      "Loss:0.6533495783805847\n",
      "___________________\n",
      "Epoch:801\n",
      "Loss:0.6533434391021729\n",
      "___________________\n",
      "Epoch:802\n",
      "Loss:0.6533373594284058\n",
      "___________________\n",
      "Epoch:803\n",
      "Loss:0.6533313393592834\n",
      "___________________\n",
      "Epoch:804\n",
      "Loss:0.6533252000808716\n",
      "___________________\n",
      "Epoch:805\n",
      "Loss:0.6533191204071045\n",
      "___________________\n",
      "Epoch:806\n",
      "Loss:0.6533129811286926\n",
      "___________________\n",
      "Epoch:807\n",
      "Loss:0.6533068418502808\n",
      "___________________\n",
      "Epoch:808\n",
      "Loss:0.6533007621765137\n",
      "___________________\n",
      "Epoch:809\n",
      "Loss:0.6532946228981018\n",
      "___________________\n",
      "Epoch:810\n",
      "Loss:0.6532886028289795\n",
      "___________________\n",
      "Epoch:811\n",
      "Loss:0.6532824635505676\n",
      "___________________\n",
      "Epoch:812\n",
      "Loss:0.6532763838768005\n",
      "___________________\n",
      "Epoch:813\n",
      "Loss:0.6532703042030334\n",
      "___________________\n",
      "Epoch:814\n",
      "Loss:0.6532642841339111\n",
      "___________________\n",
      "Epoch:815\n",
      "Loss:0.6532580852508545\n",
      "___________________\n",
      "Epoch:816\n",
      "Loss:0.6532520055770874\n",
      "___________________\n",
      "Epoch:817\n",
      "Loss:0.6532459259033203\n",
      "___________________\n",
      "Epoch:818\n",
      "Loss:0.6532398462295532\n",
      "___________________\n",
      "Epoch:819\n",
      "Loss:0.6532337665557861\n",
      "___________________\n",
      "Epoch:820\n",
      "Loss:0.6532276272773743\n",
      "___________________\n",
      "Epoch:821\n",
      "Loss:0.653221607208252\n",
      "___________________\n",
      "Epoch:822\n",
      "Loss:0.6532155275344849\n",
      "___________________\n",
      "Epoch:823\n",
      "Loss:0.653209388256073\n",
      "___________________\n",
      "Epoch:824\n",
      "Loss:0.6532033085823059\n",
      "___________________\n",
      "Epoch:825\n",
      "Loss:0.653197169303894\n",
      "___________________\n",
      "Epoch:826\n",
      "Loss:0.653191089630127\n",
      "___________________\n",
      "Epoch:827\n",
      "Loss:0.6531850695610046\n",
      "___________________\n",
      "Epoch:828\n",
      "Loss:0.6531789898872375\n",
      "___________________\n",
      "Epoch:829\n",
      "Loss:0.6531729102134705\n",
      "___________________\n",
      "Epoch:830\n",
      "Loss:0.6531667709350586\n",
      "___________________\n",
      "Epoch:831\n",
      "Loss:0.6531607508659363\n",
      "___________________\n",
      "Epoch:832\n",
      "Loss:0.6531546115875244\n",
      "___________________\n",
      "Epoch:833\n",
      "Loss:0.6531485319137573\n",
      "___________________\n",
      "Epoch:834\n",
      "Loss:0.6531424522399902\n",
      "___________________\n",
      "Epoch:835\n",
      "Loss:0.6531364321708679\n",
      "___________________\n",
      "Epoch:836\n",
      "Loss:0.6531303524971008\n",
      "___________________\n",
      "Epoch:837\n",
      "Loss:0.6531242728233337\n",
      "___________________\n",
      "Epoch:838\n",
      "Loss:0.6531181931495667\n",
      "___________________\n",
      "Epoch:839\n",
      "Loss:0.6531121134757996\n",
      "___________________\n",
      "Epoch:840\n",
      "Loss:0.6531060338020325\n",
      "___________________\n",
      "Epoch:841\n",
      "Loss:0.6531000137329102\n",
      "___________________\n",
      "Epoch:842\n",
      "Loss:0.6530938744544983\n",
      "___________________\n",
      "Epoch:843\n",
      "Loss:0.6530879139900208\n",
      "___________________\n",
      "Epoch:844\n",
      "Loss:0.6530817747116089\n",
      "___________________\n",
      "Epoch:845\n",
      "Loss:0.6530756950378418\n",
      "___________________\n",
      "Epoch:846\n",
      "Loss:0.6530697345733643\n",
      "___________________\n",
      "Epoch:847\n",
      "Loss:0.6530635952949524\n",
      "___________________\n",
      "Epoch:848\n",
      "Loss:0.6530574560165405\n",
      "___________________\n",
      "Epoch:849\n",
      "Loss:0.6530514359474182\n",
      "___________________\n",
      "Epoch:850\n",
      "Loss:0.6530454158782959\n",
      "___________________\n",
      "Epoch:851\n",
      "Loss:0.6530393362045288\n",
      "___________________\n",
      "Epoch:852\n",
      "Loss:0.6530333161354065\n",
      "___________________\n",
      "Epoch:853\n",
      "Loss:0.6530272364616394\n",
      "___________________\n",
      "Epoch:854\n",
      "Loss:0.6530212163925171\n",
      "___________________\n",
      "Epoch:855\n",
      "Loss:0.65301513671875\n",
      "___________________\n",
      "Epoch:856\n",
      "Loss:0.6530090570449829\n",
      "___________________\n",
      "Epoch:857\n",
      "Loss:0.6530030369758606\n",
      "___________________\n",
      "Epoch:858\n",
      "Loss:0.6529969573020935\n",
      "___________________\n",
      "Epoch:859\n",
      "Loss:0.652990996837616\n",
      "___________________\n",
      "Epoch:860\n",
      "Loss:0.6529849767684937\n",
      "___________________\n",
      "Epoch:861\n",
      "Loss:0.6529788374900818\n",
      "___________________\n",
      "Epoch:862\n",
      "Loss:0.6529728174209595\n",
      "___________________\n",
      "Epoch:863\n",
      "Loss:0.6529667973518372\n",
      "___________________\n",
      "Epoch:864\n",
      "Loss:0.6529607176780701\n",
      "___________________\n",
      "Epoch:865\n",
      "Loss:0.6529546976089478\n",
      "___________________\n",
      "Epoch:866\n",
      "Loss:0.6529486179351807\n",
      "___________________\n",
      "Epoch:867\n",
      "Loss:0.6529425978660583\n",
      "___________________\n",
      "Epoch:868\n",
      "Loss:0.6529366374015808\n",
      "___________________\n",
      "Epoch:869\n",
      "Loss:0.6529305577278137\n",
      "___________________\n",
      "Epoch:870\n",
      "Loss:0.6529245376586914\n",
      "___________________\n",
      "Epoch:871\n",
      "Loss:0.6529184579849243\n",
      "___________________\n",
      "Epoch:872\n",
      "Loss:0.6529124975204468\n",
      "___________________\n",
      "Epoch:873\n",
      "Loss:0.6529064178466797\n",
      "___________________\n",
      "Epoch:874\n",
      "Loss:0.6529004573822021\n",
      "___________________\n",
      "Epoch:875\n",
      "Loss:0.6528943777084351\n",
      "___________________\n",
      "Epoch:876\n",
      "Loss:0.6528883576393127\n",
      "___________________\n",
      "Epoch:877\n",
      "Loss:0.6528823375701904\n",
      "___________________\n",
      "Epoch:878\n",
      "Loss:0.6528763771057129\n",
      "___________________\n",
      "Epoch:879\n",
      "Loss:0.6528703570365906\n",
      "___________________\n",
      "Epoch:880\n",
      "Loss:0.6528642773628235\n",
      "___________________\n",
      "Epoch:881\n",
      "Loss:0.652858316898346\n",
      "___________________\n",
      "Epoch:882\n",
      "Loss:0.6528522372245789\n",
      "___________________\n",
      "Epoch:883\n",
      "Loss:0.6528462767601013\n",
      "___________________\n",
      "Epoch:884\n",
      "Loss:0.652840256690979\n",
      "___________________\n",
      "Epoch:885\n",
      "Loss:0.6528342366218567\n",
      "___________________\n",
      "Epoch:886\n",
      "Loss:0.6528282761573792\n",
      "___________________\n",
      "Epoch:887\n",
      "Loss:0.6528221964836121\n",
      "___________________\n",
      "Epoch:888\n",
      "Loss:0.6528162360191345\n",
      "___________________\n",
      "Epoch:889\n",
      "Loss:0.652810275554657\n",
      "___________________\n",
      "Epoch:890\n",
      "Loss:0.6528041958808899\n",
      "___________________\n",
      "Epoch:891\n",
      "Loss:0.6527982354164124\n",
      "___________________\n",
      "Epoch:892\n",
      "Loss:0.65279221534729\n",
      "___________________\n",
      "Epoch:893\n",
      "Loss:0.6527862548828125\n",
      "___________________\n",
      "Epoch:894\n",
      "Loss:0.6527801752090454\n",
      "___________________\n",
      "Epoch:895\n",
      "Loss:0.6527742743492126\n",
      "___________________\n",
      "Epoch:896\n",
      "Loss:0.6527682542800903\n",
      "___________________\n",
      "Epoch:897\n",
      "Loss:0.652762234210968\n",
      "___________________\n",
      "Epoch:898\n",
      "Loss:0.6527563333511353\n",
      "___________________\n",
      "Epoch:899\n",
      "Loss:0.6527503132820129\n",
      "___________________\n",
      "Epoch:900\n",
      "Loss:0.6527442932128906\n",
      "___________________\n",
      "Epoch:901\n",
      "Loss:0.6527383923530579\n",
      "___________________\n",
      "Epoch:902\n",
      "Loss:0.6527323126792908\n",
      "___________________\n",
      "Epoch:903\n",
      "Loss:0.6527263522148132\n",
      "___________________\n",
      "Epoch:904\n",
      "Loss:0.6527203917503357\n",
      "___________________\n",
      "Epoch:905\n",
      "Loss:0.6527144312858582\n",
      "___________________\n",
      "Epoch:906\n",
      "Loss:0.6527084708213806\n",
      "___________________\n",
      "Epoch:907\n",
      "Loss:0.6527025103569031\n",
      "___________________\n",
      "Epoch:908\n",
      "Loss:0.6526964902877808\n",
      "___________________\n",
      "Epoch:909\n",
      "Loss:0.652690589427948\n",
      "___________________\n",
      "Epoch:910\n",
      "Loss:0.6526845693588257\n",
      "___________________\n",
      "Epoch:911\n",
      "Loss:0.6526786684989929\n",
      "___________________\n",
      "Epoch:912\n",
      "Loss:0.6526725888252258\n",
      "___________________\n",
      "Epoch:913\n",
      "Loss:0.6526666879653931\n",
      "___________________\n",
      "Epoch:914\n",
      "Loss:0.6526607275009155\n",
      "___________________\n",
      "Epoch:915\n",
      "Loss:0.6526548862457275\n",
      "___________________\n",
      "Epoch:916\n",
      "Loss:0.6526488065719604\n",
      "___________________\n",
      "Epoch:917\n",
      "Loss:0.6526428461074829\n",
      "___________________\n",
      "Epoch:918\n",
      "Loss:0.6526369452476501\n",
      "___________________\n",
      "Epoch:919\n",
      "Loss:0.6526309847831726\n",
      "___________________\n",
      "Epoch:920\n",
      "Loss:0.6526250839233398\n",
      "___________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:921\n",
      "Loss:0.6526190638542175\n",
      "___________________\n",
      "Epoch:922\n",
      "Loss:0.6526131629943848\n",
      "___________________\n",
      "Epoch:923\n",
      "Loss:0.6526072025299072\n",
      "___________________\n",
      "Epoch:924\n",
      "Loss:0.6526013016700745\n",
      "___________________\n",
      "Epoch:925\n",
      "Loss:0.6525953412055969\n",
      "___________________\n",
      "Epoch:926\n",
      "Loss:0.6525894403457642\n",
      "___________________\n",
      "Epoch:927\n",
      "Loss:0.6525834798812866\n",
      "___________________\n",
      "Epoch:928\n",
      "Loss:0.6525775194168091\n",
      "___________________\n",
      "Epoch:929\n",
      "Loss:0.6525715589523315\n",
      "___________________\n",
      "Epoch:930\n",
      "Loss:0.6525657176971436\n",
      "___________________\n",
      "Epoch:931\n",
      "Loss:0.652559757232666\n",
      "___________________\n",
      "Epoch:932\n",
      "Loss:0.652553915977478\n",
      "___________________\n",
      "Epoch:933\n",
      "Loss:0.6525478959083557\n",
      "___________________\n",
      "Epoch:934\n",
      "Loss:0.6525421142578125\n",
      "___________________\n",
      "Epoch:935\n",
      "Loss:0.652536153793335\n",
      "___________________\n",
      "Epoch:936\n",
      "Loss:0.6525301933288574\n",
      "___________________\n",
      "Epoch:937\n",
      "Loss:0.6525242924690247\n",
      "___________________\n",
      "Epoch:938\n",
      "Loss:0.6525183320045471\n",
      "___________________\n",
      "Epoch:939\n",
      "Loss:0.6525124907493591\n",
      "___________________\n",
      "Epoch:940\n",
      "Loss:0.6525065302848816\n",
      "___________________\n",
      "Epoch:941\n",
      "Loss:0.6525006890296936\n",
      "___________________\n",
      "Epoch:942\n",
      "Loss:0.6524947285652161\n",
      "___________________\n",
      "Epoch:943\n",
      "Loss:0.6524888873100281\n",
      "___________________\n",
      "Epoch:944\n",
      "Loss:0.6524829864501953\n",
      "___________________\n",
      "Epoch:945\n",
      "Loss:0.6524770259857178\n",
      "___________________\n",
      "Epoch:946\n",
      "Loss:0.6524711847305298\n",
      "___________________\n",
      "Epoch:947\n",
      "Loss:0.6524653434753418\n",
      "___________________\n",
      "Epoch:948\n",
      "Loss:0.6524593830108643\n",
      "___________________\n",
      "Epoch:949\n",
      "Loss:0.6524535417556763\n",
      "___________________\n",
      "Epoch:950\n",
      "Loss:0.6524476408958435\n",
      "___________________\n",
      "Epoch:951\n",
      "Loss:0.6524417996406555\n",
      "___________________\n",
      "Epoch:952\n",
      "Loss:0.6524359583854675\n",
      "___________________\n",
      "Epoch:953\n",
      "Loss:0.65242999792099\n",
      "___________________\n",
      "Epoch:954\n",
      "Loss:0.6524240970611572\n",
      "___________________\n",
      "Epoch:955\n",
      "Loss:0.6524182558059692\n",
      "___________________\n",
      "Epoch:956\n",
      "Loss:0.6524124145507812\n",
      "___________________\n",
      "Epoch:957\n",
      "Loss:0.6524065136909485\n",
      "___________________\n",
      "Epoch:958\n",
      "Loss:0.6524006128311157\n",
      "___________________\n",
      "Epoch:959\n",
      "Loss:0.6523947715759277\n",
      "___________________\n",
      "Epoch:960\n",
      "Loss:0.6523889899253845\n",
      "___________________\n",
      "Epoch:961\n",
      "Loss:0.6523830890655518\n",
      "___________________\n",
      "Epoch:962\n",
      "Loss:0.6523772478103638\n",
      "___________________\n",
      "Epoch:963\n",
      "Loss:0.6523714065551758\n",
      "___________________\n",
      "Epoch:964\n",
      "Loss:0.652365505695343\n",
      "___________________\n",
      "Epoch:965\n",
      "Loss:0.652359664440155\n",
      "___________________\n",
      "Epoch:966\n",
      "Loss:0.652353823184967\n",
      "___________________\n",
      "Epoch:967\n",
      "Loss:0.6523479223251343\n",
      "___________________\n",
      "Epoch:968\n",
      "Loss:0.6523420810699463\n",
      "___________________\n",
      "Epoch:969\n",
      "Loss:0.6523362994194031\n",
      "___________________\n",
      "Epoch:970\n",
      "Loss:0.6523304581642151\n",
      "___________________\n",
      "Epoch:971\n",
      "Loss:0.6523246169090271\n",
      "___________________\n",
      "Epoch:972\n",
      "Loss:0.6523188352584839\n",
      "___________________\n",
      "Epoch:973\n",
      "Loss:0.6523129940032959\n",
      "___________________\n",
      "Epoch:974\n",
      "Loss:0.6523071527481079\n",
      "___________________\n",
      "Epoch:975\n",
      "Loss:0.6523013114929199\n",
      "___________________\n",
      "Epoch:976\n",
      "Loss:0.6522954106330872\n",
      "___________________\n",
      "Epoch:977\n",
      "Loss:0.652289628982544\n",
      "___________________\n",
      "Epoch:978\n",
      "Loss:0.6522839069366455\n",
      "___________________\n",
      "Epoch:979\n",
      "Loss:0.6522780060768127\n",
      "___________________\n",
      "Epoch:980\n",
      "Loss:0.6522721648216248\n",
      "___________________\n",
      "Epoch:981\n",
      "Loss:0.6522663831710815\n",
      "___________________\n",
      "Epoch:982\n",
      "Loss:0.6522605419158936\n",
      "___________________\n",
      "Epoch:983\n",
      "Loss:0.6522547602653503\n",
      "___________________\n",
      "Epoch:984\n",
      "Loss:0.6522489786148071\n",
      "___________________\n",
      "Epoch:985\n",
      "Loss:0.6522431373596191\n",
      "___________________\n",
      "Epoch:986\n",
      "Loss:0.6522374153137207\n",
      "___________________\n",
      "Epoch:987\n",
      "Loss:0.6522315144538879\n",
      "___________________\n",
      "Epoch:988\n",
      "Loss:0.6522257924079895\n",
      "___________________\n",
      "Epoch:989\n",
      "Loss:0.6522200107574463\n",
      "___________________\n",
      "Epoch:990\n",
      "Loss:0.6522141695022583\n",
      "___________________\n",
      "Epoch:991\n",
      "Loss:0.6522083878517151\n",
      "___________________\n",
      "Epoch:992\n",
      "Loss:0.6522026658058167\n",
      "___________________\n",
      "Epoch:993\n",
      "Loss:0.6521968245506287\n",
      "___________________\n",
      "Epoch:994\n",
      "Loss:0.6521911025047302\n",
      "___________________\n",
      "Epoch:995\n",
      "Loss:0.6521853804588318\n",
      "___________________\n",
      "Epoch:996\n",
      "Loss:0.652179479598999\n",
      "___________________\n",
      "Epoch:997\n",
      "Loss:0.6521737575531006\n",
      "___________________\n",
      "Epoch:998\n",
      "Loss:0.6521679162979126\n",
      "___________________\n",
      "Epoch:999\n",
      "Loss:0.6521621942520142\n",
      "___________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = modelemb(data_numpy.long())\n",
    "    loss = criterion(outputs.squeeze(), torch.tensor(labels, dtype=torch.float))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch:{epoch}\")\n",
    "    print(f\"Loss:{loss.item()}\")\n",
    "    print(\"___________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f32311c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2257,  0.5949,  0.4770,  2.0268, -1.2480, -1.3774, -3.1464,  2.1765,\n",
       "          0.1908, -2.2394,  0.4046, -1.1960, -0.9957,  0.4171,  0.3456],\n",
       "        [ 0.6076, -1.4441, -0.4170,  2.6588, -1.5536, -1.4166,  1.7525, -1.2560,\n",
       "          1.0865, -1.3854,  1.3008, -0.7778,  1.5958,  0.0983,  0.5017],\n",
       "        [-0.5293,  0.6957,  1.1857, -0.5401, -0.8959, -1.0740,  0.0363,  0.0137,\n",
       "          0.3968,  0.2901, -1.4893, -0.7288, -1.0630,  0.4484, -0.7116],\n",
       "        [-0.8806,  2.9346, -0.0638, -0.4809, -0.0718, -0.8453,  0.9828, -1.1196,\n",
       "          0.1944,  0.4415, -0.0063,  1.2198, -0.7421, -0.2109, -1.7832],\n",
       "        [-0.6759,  0.2464, -0.9186,  0.1559,  0.8134, -0.8796, -2.0011,  1.0789,\n",
       "          1.1105, -0.9642,  0.0072,  1.3911,  0.3949, -0.8311, -1.0298]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings=list(modelemb[0].parameters())[0]\n",
    "embeddings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "024e5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeds=embeddings[data_numpy]\n",
    "test_embeds=embeddings[torch.tensor(X_test[['Radiant1', 'Radiant2','Radiant3','Radiant4','Radiant5','Dire1','Dire2','Dire3','Dire4','Dire5']].to_numpy(),dtype=(torch.long))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3215438e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40000, 10, 15]), torch.Size([10000, 10, 15]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeds.shape, test_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cf56126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten\n",
    "train_embeds=np.array([i.flatten().detach().cpu().numpy() for i in train_embeds])\n",
    "test_embeds=np.array([i.flatten().detach().cpu().numpy() for i in test_embeds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "041924c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (40000, 150))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_embeds),train_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a29d88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num=train_embeds\n",
    "X_test_num=test_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727c6f1",
   "metadata": {},
   "source": [
    "Logistic, XGboost, random forest, ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1902681c",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdc30ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellog=LogisticRegression()\n",
    "modellog.fit(X_train_num,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3140e91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellog.predict([X_train_num[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2def6d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5902"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellog.score(X_test_num,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bf94635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.617075"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellog.score(X_train_num,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d0d1dc",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6734be59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_randfor=X_train.to_numpy().reshape(X_train.shape[0],-1)\n",
    "X_randfor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cc9d32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelforest=RandomForestClassifier(n_estimators=100)\n",
    "modelforest.fit(X_randfor,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f380b152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.5151)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelforest.predict([X_randfor[0]]),modelforest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9acf54eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelforest2=RandomForestClassifier(n_estimators=100)\n",
    "modelforest2.fit(X_train_num,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0d578bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.5545)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelforest2.predict([X_train_num[0]]),modelforest2.score(X_test_num,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65bfbb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelforest2.score(X_train_num,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a90b1",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db56bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(X_train_num, y_train)\n",
    "xgb_test = xgb.DMatrix(X_test_num, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "819d7197",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=200\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "434293fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelxgb = xgb.train(params=params,dtrain=xgb_train,num_boost_round=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83cad2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4859"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = modelxgb.predict(xgb_test)\n",
    "preds = preds.astype(int)\n",
    "accuracy= accuracy_score(y_test,preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4eda3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train1 = xgb.DMatrix(X_train, y_train)\n",
    "xgb_test1 = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27afca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=200\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0860cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelxgb1 = xgb.train(params=params,dtrain=xgb_train1,num_boost_round=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9aafbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4859"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = modelxgb1.predict(xgb_test1)\n",
    "preds = preds.astype(int)\n",
    "accuracy= accuracy_score(y_test,preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aee787c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47995"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = modelxgb1.predict(xgb_train1)\n",
    "preds = preds.astype(int)\n",
    "accuracy= accuracy_score(y_train,preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1970c1b",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41e63ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassification(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=150, out_features=16, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=4, bias=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=4, out_features=1, bias=True)\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Linear(in_features=150,out_features=16),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16,out_features=4),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4,out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer1(x)\n",
    "\n",
    "modelNN=BinaryClassification()\n",
    "modelNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e8f07d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()  # Binary Cross Entropy\n",
    "optimizer = optim.SGD(modelNN.parameters(),lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac018fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Train Loss:0.7202391624450684\n",
      "Test Loss:0.7220606207847595\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:1\n",
      "Train Loss:0.7239857316017151\n",
      "Test Loss:0.7210315465927124\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:2\n",
      "Train Loss:0.7228988409042358\n",
      "Test Loss:0.7200323343276978\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:3\n",
      "Train Loss:0.7218424081802368\n",
      "Test Loss:0.7190610766410828\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:4\n",
      "Train Loss:0.7208149433135986\n",
      "Test Loss:0.7181178331375122\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:5\n",
      "Train Loss:0.7198144793510437\n",
      "Test Loss:0.7172001600265503\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:6\n",
      "Train Loss:0.7188405990600586\n",
      "Test Loss:0.7163101434707642\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:7\n",
      "Train Loss:0.7178934812545776\n",
      "Test Loss:0.7154463529586792\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:8\n",
      "Train Loss:0.7169732451438904\n",
      "Test Loss:0.7146065831184387\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:9\n",
      "Train Loss:0.7160782217979431\n",
      "Test Loss:0.7137921452522278\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:10\n",
      "Train Loss:0.7152089476585388\n",
      "Test Loss:0.713003396987915\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:11\n",
      "Train Loss:0.7143649458885193\n",
      "Test Loss:0.7122389674186707\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:12\n",
      "Train Loss:0.7135455012321472\n",
      "Test Loss:0.7114968299865723\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:13\n",
      "Train Loss:0.7127480506896973\n",
      "Test Loss:0.710776686668396\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:14\n",
      "Train Loss:0.7119728326797485\n",
      "Test Loss:0.7100791931152344\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:15\n",
      "Train Loss:0.711220383644104\n",
      "Test Loss:0.7094041705131531\n",
      "Accuracy:0.48590001463890076\n",
      "___________________\n",
      "Epoch:16\n",
      "Train Loss:0.7104906439781189\n",
      "Test Loss:0.7087501883506775\n",
      "Accuracy:0.4859028458595276\n",
      "___________________\n",
      "Epoch:17\n",
      "Train Loss:0.7097825407981873\n",
      "Test Loss:0.7081178426742554\n",
      "Accuracy:0.4859056770801544\n",
      "___________________\n",
      "Epoch:18\n",
      "Train Loss:0.7090964913368225\n",
      "Test Loss:0.7075058817863464\n",
      "Accuracy:0.4859056770801544\n",
      "___________________\n",
      "Epoch:19\n",
      "Train Loss:0.7084326148033142\n",
      "Test Loss:0.7069152593612671\n",
      "Accuracy:0.4859056770801544\n",
      "___________________\n",
      "Epoch:20\n",
      "Train Loss:0.7077910304069519\n",
      "Test Loss:0.7063453793525696\n",
      "Accuracy:0.48590847849845886\n",
      "___________________\n",
      "Epoch:21\n",
      "Train Loss:0.7071701884269714\n",
      "Test Loss:0.7057950496673584\n",
      "Accuracy:0.48591408133506775\n",
      "___________________\n",
      "Epoch:22\n",
      "Train Loss:0.706571102142334\n",
      "Test Loss:0.7052637338638306\n",
      "Accuracy:0.485919713973999\n",
      "___________________\n",
      "Epoch:23\n",
      "Train Loss:0.705993115901947\n",
      "Test Loss:0.704750657081604\n",
      "Accuracy:0.4859282374382019\n",
      "___________________\n",
      "Epoch:24\n",
      "Train Loss:0.7054353356361389\n",
      "Test Loss:0.7042553424835205\n",
      "Accuracy:0.48593664169311523\n",
      "___________________\n",
      "Epoch:25\n",
      "Train Loss:0.7048959136009216\n",
      "Test Loss:0.7037771940231323\n",
      "Accuracy:0.48593953251838684\n",
      "___________________\n",
      "Epoch:26\n",
      "Train Loss:0.7043733596801758\n",
      "Test Loss:0.7033153772354126\n",
      "Accuracy:0.48596489429473877\n",
      "___________________\n",
      "Epoch:27\n",
      "Train Loss:0.7038684487342834\n",
      "Test Loss:0.7028701305389404\n",
      "Accuracy:0.48598745465278625\n",
      "___________________\n",
      "Epoch:28\n",
      "Train Loss:0.7033808827400208\n",
      "Test Loss:0.7024417519569397\n",
      "Accuracy:0.48601558804512024\n",
      "___________________\n",
      "Epoch:29\n",
      "Train Loss:0.702910840511322\n",
      "Test Loss:0.7020289301872253\n",
      "Accuracy:0.4860466420650482\n",
      "___________________\n",
      "Epoch:30\n",
      "Train Loss:0.7024564146995544\n",
      "Test Loss:0.7016317844390869\n",
      "Accuracy:0.48605790734291077\n",
      "___________________\n",
      "Epoch:31\n",
      "Train Loss:0.7020182013511658\n",
      "Test Loss:0.7012502551078796\n",
      "Accuracy:0.48609456419944763\n",
      "___________________\n",
      "Epoch:32\n",
      "Train Loss:0.7015960216522217\n",
      "Test Loss:0.7008832693099976\n",
      "Accuracy:0.48614251613616943\n",
      "___________________\n",
      "Epoch:33\n",
      "Train Loss:0.7011887431144714\n",
      "Test Loss:0.7005309462547302\n",
      "Accuracy:0.48619893193244934\n",
      "___________________\n",
      "Epoch:34\n",
      "Train Loss:0.7007960677146912\n",
      "Test Loss:0.7001926302909851\n",
      "Accuracy:0.48626944422721863\n",
      "___________________\n",
      "Epoch:35\n",
      "Train Loss:0.7004170417785645\n",
      "Test Loss:0.6998671293258667\n",
      "Accuracy:0.48635685443878174\n",
      "___________________\n",
      "Epoch:36\n",
      "Train Loss:0.70005202293396\n",
      "Test Loss:0.6995543837547302\n",
      "Accuracy:0.48646119236946106\n",
      "___________________\n",
      "Epoch:37\n",
      "Train Loss:0.6997007727622986\n",
      "Test Loss:0.6992541551589966\n",
      "Accuracy:0.48654016852378845\n",
      "___________________\n",
      "Epoch:38\n",
      "Train Loss:0.6993635296821594\n",
      "Test Loss:0.6989661455154419\n",
      "Accuracy:0.4866444766521454\n",
      "___________________\n",
      "Epoch:39\n",
      "Train Loss:0.6990392804145813\n",
      "Test Loss:0.6986899375915527\n",
      "Accuracy:0.4867572784423828\n",
      "___________________\n",
      "Epoch:40\n",
      "Train Loss:0.6987273693084717\n",
      "Test Loss:0.698424756526947\n",
      "Accuracy:0.48687291145324707\n",
      "___________________\n",
      "Epoch:41\n",
      "Train Loss:0.6984268426895142\n",
      "Test Loss:0.6981701850891113\n",
      "Accuracy:0.48700544238090515\n",
      "___________________\n",
      "Epoch:42\n",
      "Train Loss:0.6981375813484192\n",
      "Test Loss:0.6979261636734009\n",
      "Accuracy:0.4871210753917694\n",
      "___________________\n",
      "Epoch:43\n",
      "Train Loss:0.6978593468666077\n",
      "Test Loss:0.6976922154426575\n",
      "Accuracy:0.4872536063194275\n",
      "___________________\n",
      "Epoch:44\n",
      "Train Loss:0.6975914835929871\n",
      "Test Loss:0.6974681615829468\n",
      "Accuracy:0.4874425530433655\n",
      "___________________\n",
      "Epoch:45\n",
      "Train Loss:0.697333574295044\n",
      "Test Loss:0.6972531676292419\n",
      "Accuracy:0.48759764432907104\n",
      "___________________\n",
      "Epoch:46\n",
      "Train Loss:0.6970853805541992\n",
      "Test Loss:0.6970469355583191\n",
      "Accuracy:0.4878119230270386\n",
      "___________________\n",
      "Epoch:47\n",
      "Train Loss:0.6968470811843872\n",
      "Test Loss:0.6968494057655334\n",
      "Accuracy:0.48799243569374084\n",
      "___________________\n",
      "Epoch:48\n",
      "Train Loss:0.6966179013252258\n",
      "Test Loss:0.696660578250885\n",
      "Accuracy:0.4882405996322632\n",
      "___________________\n",
      "Epoch:49\n",
      "Train Loss:0.6963984370231628\n",
      "Test Loss:0.6964797377586365\n",
      "Accuracy:0.48850569128990173\n",
      "___________________\n",
      "Epoch:50\n",
      "Train Loss:0.6961874961853027\n",
      "Test Loss:0.6963067650794983\n",
      "Accuracy:0.48868051171302795\n",
      "___________________\n",
      "Epoch:51\n",
      "Train Loss:0.6959850788116455\n",
      "Test Loss:0.6961410641670227\n",
      "Accuracy:0.48891744017601013\n",
      "___________________\n",
      "Epoch:52\n",
      "Train Loss:0.6957905292510986\n",
      "Test Loss:0.6959824562072754\n",
      "Accuracy:0.4891824722290039\n",
      "___________________\n",
      "Epoch:53\n",
      "Train Loss:0.6956034302711487\n",
      "Test Loss:0.6958307027816772\n",
      "Accuracy:0.4894447326660156\n",
      "___________________\n",
      "Epoch:54\n",
      "Train Loss:0.69542396068573\n",
      "Test Loss:0.6956853270530701\n",
      "Accuracy:0.4896985590457916\n",
      "___________________\n",
      "Epoch:55\n",
      "Train Loss:0.6952516436576843\n",
      "Test Loss:0.6955469250679016\n",
      "Accuracy:0.4900200366973877\n",
      "___________________\n",
      "Epoch:56\n",
      "Train Loss:0.6950864791870117\n",
      "Test Loss:0.6954149007797241\n",
      "Accuracy:0.4903358519077301\n",
      "___________________\n",
      "Epoch:57\n",
      "Train Loss:0.6949278116226196\n",
      "Test Loss:0.6952888369560242\n",
      "Accuracy:0.49057555198669434\n",
      "___________________\n",
      "Epoch:58\n",
      "Train Loss:0.6947758793830872\n",
      "Test Loss:0.6951683163642883\n",
      "Accuracy:0.49089422821998596\n",
      "___________________\n",
      "Epoch:59\n",
      "Train Loss:0.6946300864219666\n",
      "Test Loss:0.6950531005859375\n",
      "Accuracy:0.49118468165397644\n",
      "___________________\n",
      "Epoch:60\n",
      "Train Loss:0.6944902539253235\n",
      "Test Loss:0.6949431300163269\n",
      "Accuracy:0.4914807975292206\n",
      "___________________\n",
      "Epoch:61\n",
      "Train Loss:0.6943559646606445\n",
      "Test Loss:0.6948381066322327\n",
      "Accuracy:0.49177125096321106\n",
      "___________________\n",
      "Epoch:62\n",
      "Train Loss:0.6942271590232849\n",
      "Test Loss:0.6947381496429443\n",
      "Accuracy:0.49208712577819824\n",
      "___________________\n",
      "Epoch:63\n",
      "Train Loss:0.6941037178039551\n",
      "Test Loss:0.6946426033973694\n",
      "Accuracy:0.4924085736274719\n",
      "___________________\n",
      "Epoch:64\n",
      "Train Loss:0.6939851641654968\n",
      "Test Loss:0.6945513486862183\n",
      "Accuracy:0.49269619584083557\n",
      "___________________\n",
      "Epoch:65\n",
      "Train Loss:0.6938715577125549\n",
      "Test Loss:0.6944643259048462\n",
      "Accuracy:0.4930543601512909\n",
      "___________________\n",
      "Epoch:66\n",
      "Train Loss:0.6937623023986816\n",
      "Test Loss:0.6943811774253845\n",
      "Accuracy:0.4933870732784271\n",
      "___________________\n",
      "Epoch:67\n",
      "Train Loss:0.6936573386192322\n",
      "Test Loss:0.6943019032478333\n",
      "Accuracy:0.49369728565216064\n",
      "___________________\n",
      "Epoch:68\n",
      "Train Loss:0.6935566663742065\n",
      "Test Loss:0.694226086139679\n",
      "Accuracy:0.4940272867679596\n",
      "___________________\n",
      "Epoch:69\n",
      "Train Loss:0.6934600472450256\n",
      "Test Loss:0.6941537857055664\n",
      "Accuracy:0.49433743953704834\n",
      "___________________\n",
      "Epoch:70\n",
      "Train Loss:0.6933671832084656\n",
      "Test Loss:0.694084882736206\n",
      "Accuracy:0.49463072419166565\n",
      "___________________\n",
      "Epoch:71\n",
      "Train Loss:0.6932778358459473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.6940187811851501\n",
      "Accuracy:0.49492964148521423\n",
      "___________________\n",
      "Epoch:72\n",
      "Train Loss:0.6931919455528259\n",
      "Test Loss:0.6939557790756226\n",
      "Accuracy:0.49528780579566956\n",
      "___________________\n",
      "Epoch:73\n",
      "Train Loss:0.6931092739105225\n",
      "Test Loss:0.6938954591751099\n",
      "Accuracy:0.4955754280090332\n",
      "___________________\n",
      "Epoch:74\n",
      "Train Loss:0.6930297613143921\n",
      "Test Loss:0.6938378214836121\n",
      "Accuracy:0.49591100215911865\n",
      "___________________\n",
      "Epoch:75\n",
      "Train Loss:0.6929534077644348\n",
      "Test Loss:0.6937828660011292\n",
      "Accuracy:0.4961845576763153\n",
      "___________________\n",
      "Epoch:76\n",
      "Train Loss:0.6928800940513611\n",
      "Test Loss:0.6937304139137268\n",
      "Accuracy:0.4964863061904907\n",
      "___________________\n",
      "Epoch:77\n",
      "Train Loss:0.6928094625473022\n",
      "Test Loss:0.6936805248260498\n",
      "Accuracy:0.4967767298221588\n",
      "___________________\n",
      "Epoch:78\n",
      "Train Loss:0.6927415728569031\n",
      "Test Loss:0.6936326026916504\n",
      "Accuracy:0.49703335762023926\n",
      "___________________\n",
      "Epoch:79\n",
      "Train Loss:0.6926762461662292\n",
      "Test Loss:0.6935869455337524\n",
      "Accuracy:0.4973520040512085\n",
      "___________________\n",
      "Epoch:80\n",
      "Train Loss:0.6926132440567017\n",
      "Test Loss:0.6935434341430664\n",
      "Accuracy:0.497628390789032\n",
      "___________________\n",
      "Epoch:81\n",
      "Train Loss:0.6925525665283203\n",
      "Test Loss:0.6935018301010132\n",
      "Accuracy:0.49790191650390625\n",
      "___________________\n",
      "Epoch:82\n",
      "Train Loss:0.6924940347671509\n",
      "Test Loss:0.6934618949890137\n",
      "Accuracy:0.4981754720211029\n",
      "___________________\n",
      "Epoch:83\n",
      "Train Loss:0.6924375891685486\n",
      "Test Loss:0.6934238076210022\n",
      "Accuracy:0.49852511286735535\n",
      "___________________\n",
      "Epoch:84\n",
      "Train Loss:0.692383348941803\n",
      "Test Loss:0.6933873295783997\n",
      "Accuracy:0.4987986385822296\n",
      "___________________\n",
      "Epoch:85\n",
      "Train Loss:0.692331075668335\n",
      "Test Loss:0.693352460861206\n",
      "Accuracy:0.4990299344062805\n",
      "___________________\n",
      "Epoch:86\n",
      "Train Loss:0.6922805905342102\n",
      "Test Loss:0.6933191418647766\n",
      "Accuracy:0.4992668032646179\n",
      "___________________\n",
      "Epoch:87\n",
      "Train Loss:0.6922318935394287\n",
      "Test Loss:0.6932871341705322\n",
      "Accuracy:0.4995206296443939\n",
      "___________________\n",
      "Epoch:88\n",
      "Train Loss:0.6921848654747009\n",
      "Test Loss:0.6932565569877625\n",
      "Accuracy:0.49973776936531067\n",
      "___________________\n",
      "Epoch:89\n",
      "Train Loss:0.6921394467353821\n",
      "Test Loss:0.6932271718978882\n",
      "Accuracy:0.4999464452266693\n",
      "___________________\n",
      "Epoch:90\n",
      "Train Loss:0.6920955777168274\n",
      "Test Loss:0.6931989789009094\n",
      "Accuracy:0.50015789270401\n",
      "___________________\n",
      "Epoch:91\n",
      "Train Loss:0.6920530200004578\n",
      "Test Loss:0.693172037601471\n",
      "Accuracy:0.5003976225852966\n",
      "___________________\n",
      "Epoch:92\n",
      "Train Loss:0.6920118927955627\n",
      "Test Loss:0.6931461691856384\n",
      "Accuracy:0.5005978345870972\n",
      "___________________\n",
      "Epoch:93\n",
      "Train Loss:0.6919721961021423\n",
      "Test Loss:0.6931213736534119\n",
      "Accuracy:0.5008319020271301\n",
      "___________________\n",
      "Epoch:94\n",
      "Train Loss:0.6919336915016174\n",
      "Test Loss:0.6930974721908569\n",
      "Accuracy:0.5010856986045837\n",
      "___________________\n",
      "Epoch:95\n",
      "Train Loss:0.691896378993988\n",
      "Test Loss:0.693074643611908\n",
      "Accuracy:0.5012548565864563\n",
      "___________________\n",
      "Epoch:96\n",
      "Train Loss:0.6918602585792542\n",
      "Test Loss:0.6930525302886963\n",
      "Accuracy:0.5014325380325317\n",
      "___________________\n",
      "Epoch:97\n",
      "Train Loss:0.6918250918388367\n",
      "Test Loss:0.693031370639801\n",
      "Accuracy:0.5016187429428101\n",
      "___________________\n",
      "Epoch:98\n",
      "Train Loss:0.6917911171913147\n",
      "Test Loss:0.6930107474327087\n",
      "Accuracy:0.5018612146377563\n",
      "___________________\n",
      "Epoch:99\n",
      "Train Loss:0.6917579174041748\n",
      "Test Loss:0.6929909586906433\n",
      "Accuracy:0.5020529627799988\n",
      "___________________\n",
      "Epoch:100\n",
      "Train Loss:0.6917257905006409\n",
      "Test Loss:0.69297194480896\n",
      "Accuracy:0.5022306442260742\n",
      "___________________\n",
      "Epoch:101\n",
      "Train Loss:0.6916945576667786\n",
      "Test Loss:0.6929535865783691\n",
      "Accuracy:0.5024420619010925\n",
      "___________________\n",
      "Epoch:102\n",
      "Train Loss:0.6916640996932983\n",
      "Test Loss:0.6929357051849365\n",
      "Accuracy:0.5026226043701172\n",
      "___________________\n",
      "Epoch:103\n",
      "Train Loss:0.691634476184845\n",
      "Test Loss:0.6929184794425964\n",
      "Accuracy:0.502794623374939\n",
      "___________________\n",
      "Epoch:104\n",
      "Train Loss:0.6916056871414185\n",
      "Test Loss:0.6929018497467041\n",
      "Accuracy:0.5029468536376953\n",
      "___________________\n",
      "Epoch:105\n",
      "Train Loss:0.6915775537490845\n",
      "Test Loss:0.6928856372833252\n",
      "Accuracy:0.5030596852302551\n",
      "___________________\n",
      "Epoch:106\n",
      "Train Loss:0.691550076007843\n",
      "Test Loss:0.6928699612617493\n",
      "Accuracy:0.5032203793525696\n",
      "___________________\n",
      "Epoch:107\n",
      "Train Loss:0.6915232539176941\n",
      "Test Loss:0.6928547620773315\n",
      "Accuracy:0.503355860710144\n",
      "___________________\n",
      "Epoch:108\n",
      "Train Loss:0.6914969682693481\n",
      "Test Loss:0.6928399205207825\n",
      "Accuracy:0.503491222858429\n",
      "___________________\n",
      "Epoch:109\n",
      "Train Loss:0.6914713978767395\n",
      "Test Loss:0.6928254961967468\n",
      "Accuracy:0.5036406517028809\n",
      "___________________\n",
      "Epoch:110\n",
      "Train Loss:0.6914463639259338\n",
      "Test Loss:0.6928114295005798\n",
      "Accuracy:0.5037731528282166\n",
      "___________________\n",
      "Epoch:111\n",
      "Train Loss:0.6914218068122864\n",
      "Test Loss:0.6927977204322815\n",
      "Accuracy:0.5039254426956177\n",
      "___________________\n",
      "Epoch:112\n",
      "Train Loss:0.6913977861404419\n",
      "Test Loss:0.6927842497825623\n",
      "Accuracy:0.5040410161018372\n",
      "___________________\n",
      "Epoch:113\n",
      "Train Loss:0.6913741230964661\n",
      "Test Loss:0.6927711367607117\n",
      "Accuracy:0.5041510462760925\n",
      "___________________\n",
      "Epoch:114\n",
      "Train Loss:0.691351056098938\n",
      "Test Loss:0.6927583813667297\n",
      "Accuracy:0.50429767370224\n",
      "___________________\n",
      "Epoch:115\n",
      "Train Loss:0.6913283467292786\n",
      "Test Loss:0.6927458643913269\n",
      "Accuracy:0.5044358372688293\n",
      "___________________\n",
      "Epoch:116\n",
      "Train Loss:0.6913060545921326\n",
      "Test Loss:0.6927335858345032\n",
      "Accuracy:0.5045514702796936\n",
      "___________________\n",
      "Epoch:117\n",
      "Train Loss:0.6912840604782104\n",
      "Test Loss:0.6927215456962585\n",
      "Accuracy:0.5046558380126953\n",
      "___________________\n",
      "Epoch:118\n",
      "Train Loss:0.6912626028060913\n",
      "Test Loss:0.6927096247673035\n",
      "Accuracy:0.5047601461410522\n",
      "___________________\n",
      "Epoch:119\n",
      "Train Loss:0.6912413835525513\n",
      "Test Loss:0.6926980018615723\n",
      "Accuracy:0.5048559904098511\n",
      "___________________\n",
      "Epoch:120\n",
      "Train Loss:0.6912205219268799\n",
      "Test Loss:0.6926864981651306\n",
      "Accuracy:0.5049604177474976\n",
      "___________________\n",
      "Epoch:121\n",
      "Train Loss:0.6911998987197876\n",
      "Test Loss:0.6926752328872681\n",
      "Accuracy:0.5051013827323914\n",
      "___________________\n",
      "Epoch:122\n",
      "Train Loss:0.6911796927452087\n",
      "Test Loss:0.6926640868186951\n",
      "Accuracy:0.5052029490470886\n",
      "___________________\n",
      "Epoch:123\n",
      "Train Loss:0.6911596059799194\n",
      "Test Loss:0.6926531195640564\n",
      "Accuracy:0.5053241848945618\n",
      "___________________\n",
      "Epoch:124\n",
      "Train Loss:0.691139817237854\n",
      "Test Loss:0.692642331123352\n",
      "Accuracy:0.5054031014442444\n",
      "___________________\n",
      "Epoch:125\n",
      "Train Loss:0.6911203265190125\n",
      "Test Loss:0.6926316022872925\n",
      "Accuracy:0.5055018663406372\n",
      "___________________\n",
      "Epoch:126\n",
      "Train Loss:0.69110107421875\n",
      "Test Loss:0.6926209330558777\n",
      "Accuracy:0.5055949091911316\n",
      "___________________\n",
      "Epoch:127\n",
      "Train Loss:0.6910819411277771\n",
      "Test Loss:0.692610502243042\n",
      "Accuracy:0.5056710243225098\n",
      "___________________\n",
      "Epoch:128\n",
      "Train Loss:0.6910631060600281\n",
      "Test Loss:0.6926001906394958\n",
      "Accuracy:0.505741536617279\n",
      "___________________\n",
      "Epoch:129\n",
      "Train Loss:0.6910444498062134\n",
      "Test Loss:0.6925898790359497\n",
      "Accuracy:0.505845844745636\n",
      "___________________\n",
      "Epoch:130\n",
      "Train Loss:0.691025972366333\n",
      "Test Loss:0.6925796866416931\n",
      "Accuracy:0.5059220194816589\n",
      "___________________\n",
      "Epoch:131\n",
      "Train Loss:0.6910076141357422\n",
      "Test Loss:0.6925697326660156\n",
      "Accuracy:0.5060094594955444\n",
      "___________________\n",
      "Epoch:132\n",
      "Train Loss:0.6909895539283752\n",
      "Test Loss:0.6925595998764038\n",
      "Accuracy:0.5060657858848572\n",
      "___________________\n",
      "Epoch:133\n",
      "Train Loss:0.6909715533256531\n",
      "Test Loss:0.6925496459007263\n",
      "Accuracy:0.5061391592025757\n",
      "___________________\n",
      "Epoch:134\n",
      "Train Loss:0.69095379114151\n",
      "Test Loss:0.6925398111343384\n",
      "Accuracy:0.5062012076377869\n",
      "___________________\n",
      "Epoch:135\n",
      "Train Loss:0.6909361481666565\n",
      "Test Loss:0.6925299167633057\n",
      "Accuracy:0.5062603950500488\n",
      "___________________\n",
      "Epoch:136\n",
      "Train Loss:0.6909185647964478\n",
      "Test Loss:0.6925201416015625\n",
      "Accuracy:0.5063281059265137\n",
      "___________________\n",
      "Epoch:137\n",
      "Train Loss:0.6909011602401733\n",
      "Test Loss:0.6925103068351746\n",
      "Accuracy:0.5063703656196594\n",
      "___________________\n",
      "Epoch:138\n",
      "Train Loss:0.6908838152885437\n",
      "Test Loss:0.6925005912780762\n",
      "Accuracy:0.50641268491745\n",
      "___________________\n",
      "Epoch:139\n",
      "Train Loss:0.6908666491508484\n",
      "Test Loss:0.6924907565116882\n",
      "Accuracy:0.5064549446105957\n",
      "___________________\n",
      "Epoch:140\n",
      "Train Loss:0.6908494830131531\n",
      "Test Loss:0.6924810409545898\n",
      "Accuracy:0.5065226554870605\n",
      "___________________\n",
      "Epoch:141\n",
      "Train Loss:0.6908326148986816\n",
      "Test Loss:0.692471444606781\n",
      "Accuracy:0.5065621733665466\n",
      "___________________\n",
      "Epoch:142\n",
      "Train Loss:0.6908155679702759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.6924618482589722\n",
      "Accuracy:0.5065987706184387\n",
      "___________________\n",
      "Epoch:143\n",
      "Train Loss:0.690798819065094\n",
      "Test Loss:0.6924522519111633\n",
      "Accuracy:0.5066410899162292\n",
      "___________________\n",
      "Epoch:144\n",
      "Train Loss:0.6907821297645569\n",
      "Test Loss:0.6924426555633545\n",
      "Accuracy:0.5067031383514404\n",
      "___________________\n",
      "Epoch:145\n",
      "Train Loss:0.6907654404640198\n",
      "Test Loss:0.6924330592155457\n",
      "Accuracy:0.5067651867866516\n",
      "___________________\n",
      "Epoch:146\n",
      "Train Loss:0.6907488703727722\n",
      "Test Loss:0.6924235224723816\n",
      "Accuracy:0.5068046450614929\n",
      "___________________\n",
      "Epoch:147\n",
      "Train Loss:0.6907323002815247\n",
      "Test Loss:0.6924139857292175\n",
      "Accuracy:0.5068526268005371\n",
      "___________________\n",
      "Epoch:148\n",
      "Train Loss:0.6907159090042114\n",
      "Test Loss:0.6924044489860535\n",
      "Accuracy:0.5068836212158203\n",
      "___________________\n",
      "Epoch:149\n",
      "Train Loss:0.690699577331543\n",
      "Test Loss:0.6923949718475342\n",
      "Accuracy:0.5069146156311035\n",
      "___________________\n",
      "Epoch:150\n",
      "Train Loss:0.6906831860542297\n",
      "Test Loss:0.6923854351043701\n",
      "Accuracy:0.5069597363471985\n",
      "___________________\n",
      "Epoch:151\n",
      "Train Loss:0.690666913986206\n",
      "Test Loss:0.692375898361206\n",
      "Accuracy:0.5070105195045471\n",
      "___________________\n",
      "Epoch:152\n",
      "Train Loss:0.6906506419181824\n",
      "Test Loss:0.6923663020133972\n",
      "Accuracy:0.5070584416389465\n",
      "___________________\n",
      "Epoch:153\n",
      "Train Loss:0.6906344890594482\n",
      "Test Loss:0.6923568248748779\n",
      "Accuracy:0.507092297077179\n",
      "___________________\n",
      "Epoch:154\n",
      "Train Loss:0.6906183362007141\n",
      "Test Loss:0.6923471689224243\n",
      "Accuracy:0.5071289539337158\n",
      "___________________\n",
      "Epoch:155\n",
      "Train Loss:0.6906023621559143\n",
      "Test Loss:0.692337691783905\n",
      "Accuracy:0.5071571469306946\n",
      "___________________\n",
      "Epoch:156\n",
      "Train Loss:0.6905862092971802\n",
      "Test Loss:0.6923280358314514\n",
      "Accuracy:0.5071966648101807\n",
      "___________________\n",
      "Epoch:157\n",
      "Train Loss:0.6905702352523804\n",
      "Test Loss:0.6923184394836426\n",
      "Accuracy:0.5072163939476013\n",
      "___________________\n",
      "Epoch:158\n",
      "Train Loss:0.6905542016029358\n",
      "Test Loss:0.6923088431358337\n",
      "Accuracy:0.5072360634803772\n",
      "___________________\n",
      "Epoch:159\n",
      "Train Loss:0.690538227558136\n",
      "Test Loss:0.6922993063926697\n",
      "Accuracy:0.5072586536407471\n",
      "___________________\n",
      "Epoch:160\n",
      "Train Loss:0.6905223727226257\n",
      "Test Loss:0.6922895312309265\n",
      "Accuracy:0.5072783827781677\n",
      "___________________\n",
      "Epoch:161\n",
      "Train Loss:0.6905064582824707\n",
      "Test Loss:0.6922800540924072\n",
      "Accuracy:0.5073122382164001\n",
      "___________________\n",
      "Epoch:162\n",
      "Train Loss:0.6904906034469604\n",
      "Test Loss:0.6922703385353088\n",
      "Accuracy:0.5073460936546326\n",
      "___________________\n",
      "Epoch:163\n",
      "Train Loss:0.690474808216095\n",
      "Test Loss:0.6922606229782104\n",
      "Accuracy:0.5073827505111694\n",
      "___________________\n",
      "Epoch:164\n",
      "Train Loss:0.6904588937759399\n",
      "Test Loss:0.6922510266304016\n",
      "Accuracy:0.5074166655540466\n",
      "___________________\n",
      "Epoch:165\n",
      "Train Loss:0.6904430389404297\n",
      "Test Loss:0.6922413110733032\n",
      "Accuracy:0.507439136505127\n",
      "___________________\n",
      "Epoch:166\n",
      "Train Loss:0.690427303314209\n",
      "Test Loss:0.6922315359115601\n",
      "Accuracy:0.5074701905250549\n",
      "___________________\n",
      "Epoch:167\n",
      "Train Loss:0.6904114484786987\n",
      "Test Loss:0.6922217607498169\n",
      "Accuracy:0.507478654384613\n",
      "___________________\n",
      "Epoch:168\n",
      "Train Loss:0.6903955936431885\n",
      "Test Loss:0.6922119855880737\n",
      "Accuracy:0.5074983835220337\n",
      "___________________\n",
      "Epoch:169\n",
      "Train Loss:0.6903798580169678\n",
      "Test Loss:0.6922022104263306\n",
      "Accuracy:0.5075209140777588\n",
      "___________________\n",
      "Epoch:170\n",
      "Train Loss:0.6903640627861023\n",
      "Test Loss:0.6921923756599426\n",
      "Accuracy:0.5075379014015198\n",
      "___________________\n",
      "Epoch:171\n",
      "Train Loss:0.6903482675552368\n",
      "Test Loss:0.6921825408935547\n",
      "Accuracy:0.507554829120636\n",
      "___________________\n",
      "Epoch:172\n",
      "Train Loss:0.6903323531150818\n",
      "Test Loss:0.6921727061271667\n",
      "Accuracy:0.5075716972351074\n",
      "___________________\n",
      "Epoch:173\n",
      "Train Loss:0.6903165578842163\n",
      "Test Loss:0.6921628713607788\n",
      "Accuracy:0.5075942873954773\n",
      "___________________\n",
      "Epoch:174\n",
      "Train Loss:0.690300703048706\n",
      "Test Loss:0.6921528577804565\n",
      "Accuracy:0.5076168179512024\n",
      "___________________\n",
      "Epoch:175\n",
      "Train Loss:0.6902849078178406\n",
      "Test Loss:0.6921430230140686\n",
      "Accuracy:0.5076337456703186\n",
      "___________________\n",
      "Epoch:176\n",
      "Train Loss:0.6902691125869751\n",
      "Test Loss:0.6921331286430359\n",
      "Accuracy:0.5076732039451599\n",
      "___________________\n",
      "Epoch:177\n",
      "Train Loss:0.6902531981468201\n",
      "Test Loss:0.6921231150627136\n",
      "Accuracy:0.5076985955238342\n",
      "___________________\n",
      "Epoch:178\n",
      "Train Loss:0.6902374625205994\n",
      "Test Loss:0.6921131610870361\n",
      "Accuracy:0.507712721824646\n",
      "___________________\n",
      "Epoch:179\n",
      "Train Loss:0.6902216076850891\n",
      "Test Loss:0.6921032071113586\n",
      "Accuracy:0.50774085521698\n",
      "___________________\n",
      "Epoch:180\n",
      "Train Loss:0.6902057528495789\n",
      "Test Loss:0.6920931935310364\n",
      "Accuracy:0.5077521800994873\n",
      "___________________\n",
      "Epoch:181\n",
      "Train Loss:0.6901899576187134\n",
      "Test Loss:0.6920830011367798\n",
      "Accuracy:0.5077635049819946\n",
      "___________________\n",
      "Epoch:182\n",
      "Train Loss:0.6901740431785583\n",
      "Test Loss:0.6920729279518127\n",
      "Accuracy:0.5077606439590454\n",
      "___________________\n",
      "Epoch:183\n",
      "Train Loss:0.6901581287384033\n",
      "Test Loss:0.6920629143714905\n",
      "Accuracy:0.5077691078186035\n",
      "___________________\n",
      "Epoch:184\n",
      "Train Loss:0.6901422739028931\n",
      "Test Loss:0.6920527815818787\n",
      "Accuracy:0.5077944993972778\n",
      "___________________\n",
      "Epoch:185\n",
      "Train Loss:0.6901262998580933\n",
      "Test Loss:0.6920426487922668\n",
      "Accuracy:0.5078029632568359\n",
      "___________________\n",
      "Epoch:186\n",
      "Train Loss:0.690110445022583\n",
      "Test Loss:0.692032516002655\n",
      "Accuracy:0.507825493812561\n",
      "___________________\n",
      "Epoch:187\n",
      "Train Loss:0.690094530582428\n",
      "Test Loss:0.6920223832130432\n",
      "Accuracy:0.5078310966491699\n",
      "___________________\n",
      "Epoch:188\n",
      "Train Loss:0.6900785565376282\n",
      "Test Loss:0.6920121312141418\n",
      "Accuracy:0.5078424215316772\n",
      "___________________\n",
      "Epoch:189\n",
      "Train Loss:0.6900625824928284\n",
      "Test Loss:0.6920018792152405\n",
      "Accuracy:0.5078537464141846\n",
      "___________________\n",
      "Epoch:190\n",
      "Train Loss:0.6900466680526733\n",
      "Test Loss:0.6919916272163391\n",
      "Accuracy:0.5078621506690979\n",
      "___________________\n",
      "Epoch:191\n",
      "Train Loss:0.6900306344032288\n",
      "Test Loss:0.6919813752174377\n",
      "Accuracy:0.5078819394111633\n",
      "___________________\n",
      "Epoch:192\n",
      "Train Loss:0.690014660358429\n",
      "Test Loss:0.6919710636138916\n",
      "Accuracy:0.5078875422477722\n",
      "___________________\n",
      "Epoch:193\n",
      "Train Loss:0.6899986267089844\n",
      "Test Loss:0.6919607520103455\n",
      "Accuracy:0.5078988075256348\n",
      "___________________\n",
      "Epoch:194\n",
      "Train Loss:0.6899825930595398\n",
      "Test Loss:0.6919503211975098\n",
      "Accuracy:0.5079129338264465\n",
      "___________________\n",
      "Epoch:195\n",
      "Train Loss:0.6899664998054504\n",
      "Test Loss:0.6919399499893188\n",
      "Accuracy:0.5079241394996643\n",
      "___________________\n",
      "Epoch:196\n",
      "Train Loss:0.6899504661560059\n",
      "Test Loss:0.6919295191764832\n",
      "Accuracy:0.5079270601272583\n",
      "___________________\n",
      "Epoch:197\n",
      "Train Loss:0.689934253692627\n",
      "Test Loss:0.6919190287590027\n",
      "Accuracy:0.5079355239868164\n",
      "___________________\n",
      "Epoch:198\n",
      "Train Loss:0.6899182796478271\n",
      "Test Loss:0.691908597946167\n",
      "Accuracy:0.507946789264679\n",
      "___________________\n",
      "Epoch:199\n",
      "Train Loss:0.689902126789093\n",
      "Test Loss:0.6918981671333313\n",
      "Accuracy:0.5079495906829834\n",
      "___________________\n",
      "Epoch:200\n",
      "Train Loss:0.6898859143257141\n",
      "Test Loss:0.6918876767158508\n",
      "Accuracy:0.5079552531242371\n",
      "___________________\n",
      "Epoch:201\n",
      "Train Loss:0.68986976146698\n",
      "Test Loss:0.6918771266937256\n",
      "Accuracy:0.5079551935195923\n",
      "___________________\n",
      "Epoch:202\n",
      "Train Loss:0.6898534893989563\n",
      "Test Loss:0.6918665766716003\n",
      "Accuracy:0.5079579949378967\n",
      "___________________\n",
      "Epoch:203\n",
      "Train Loss:0.6898373961448669\n",
      "Test Loss:0.6918560862541199\n",
      "Accuracy:0.5079636573791504\n",
      "___________________\n",
      "Epoch:204\n",
      "Train Loss:0.689821183681488\n",
      "Test Loss:0.6918455362319946\n",
      "Accuracy:0.5079692602157593\n",
      "___________________\n",
      "Epoch:205\n",
      "Train Loss:0.6898049712181091\n",
      "Test Loss:0.6918349266052246\n",
      "Accuracy:0.5079890489578247\n",
      "___________________\n",
      "Epoch:206\n",
      "Train Loss:0.6897886991500854\n",
      "Test Loss:0.6918243765830994\n",
      "Accuracy:0.5079947113990784\n",
      "___________________\n",
      "Epoch:207\n",
      "Train Loss:0.689772367477417\n",
      "Test Loss:0.6918136477470398\n",
      "Accuracy:0.5080031156539917\n",
      "___________________\n",
      "Epoch:208\n",
      "Train Loss:0.6897560358047485\n",
      "Test Loss:0.6918030381202698\n",
      "Accuracy:0.508014440536499\n",
      "___________________\n",
      "Epoch:209\n",
      "Train Loss:0.6897397637367249\n",
      "Test Loss:0.6917923092842102\n",
      "Accuracy:0.5080229043960571\n",
      "___________________\n",
      "Epoch:210\n",
      "Train Loss:0.6897233128547668\n",
      "Test Loss:0.6917815804481506\n",
      "Accuracy:0.5080229043960571\n",
      "___________________\n",
      "Epoch:211\n",
      "Train Loss:0.6897069215774536\n",
      "Test Loss:0.6917708516120911\n",
      "Accuracy:0.5080229043960571\n",
      "___________________\n",
      "Epoch:212\n",
      "Train Loss:0.6896905303001404\n",
      "Test Loss:0.6917599439620972\n",
      "Accuracy:0.5080201029777527\n",
      "___________________\n",
      "Epoch:213\n",
      "Train Loss:0.6896741390228271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.691749095916748\n",
      "Accuracy:0.5080173015594482\n",
      "___________________\n",
      "Epoch:214\n",
      "Train Loss:0.6896576285362244\n",
      "Test Loss:0.6917383074760437\n",
      "Accuracy:0.5080285668373108\n",
      "___________________\n",
      "Epoch:215\n",
      "Train Loss:0.6896411180496216\n",
      "Test Loss:0.6917275190353394\n",
      "Accuracy:0.5080285668373108\n",
      "___________________\n",
      "Epoch:216\n",
      "Train Loss:0.6896244287490845\n",
      "Test Loss:0.6917164921760559\n",
      "Accuracy:0.5080313682556152\n",
      "___________________\n",
      "Epoch:217\n",
      "Train Loss:0.6896079182624817\n",
      "Test Loss:0.691705584526062\n",
      "Accuracy:0.5080285668373108\n",
      "___________________\n",
      "Epoch:218\n",
      "Train Loss:0.6895912885665894\n",
      "Test Loss:0.6916945576667786\n",
      "Accuracy:0.5080285668373108\n",
      "___________________\n",
      "Epoch:219\n",
      "Train Loss:0.6895745396614075\n",
      "Test Loss:0.6916835904121399\n",
      "Accuracy:0.5080341696739197\n",
      "___________________\n",
      "Epoch:220\n",
      "Train Loss:0.6895577907562256\n",
      "Test Loss:0.6916725039482117\n",
      "Accuracy:0.5080398321151733\n",
      "___________________\n",
      "Epoch:221\n",
      "Train Loss:0.6895410418510437\n",
      "Test Loss:0.6916614770889282\n",
      "Accuracy:0.5080482959747314\n",
      "___________________\n",
      "Epoch:222\n",
      "Train Loss:0.6895242929458618\n",
      "Test Loss:0.6916502714157104\n",
      "Accuracy:0.508059561252594\n",
      "___________________\n",
      "Epoch:223\n",
      "Train Loss:0.6895074248313904\n",
      "Test Loss:0.6916391849517822\n",
      "Accuracy:0.5080567002296448\n",
      "___________________\n",
      "Epoch:224\n",
      "Train Loss:0.689490556716919\n",
      "Test Loss:0.6916280388832092\n",
      "Accuracy:0.5080595016479492\n",
      "___________________\n",
      "Epoch:225\n",
      "Train Loss:0.689473569393158\n",
      "Test Loss:0.691616952419281\n",
      "Accuracy:0.5080623626708984\n",
      "___________________\n",
      "Epoch:226\n",
      "Train Loss:0.6894566416740417\n",
      "Test Loss:0.6916057467460632\n",
      "Accuracy:0.5080652236938477\n",
      "___________________\n",
      "Epoch:227\n",
      "Train Loss:0.6894396543502808\n",
      "Test Loss:0.6915944218635559\n",
      "Accuracy:0.5080708265304565\n",
      "___________________\n",
      "Epoch:228\n",
      "Train Loss:0.6894225478172302\n",
      "Test Loss:0.6915832757949829\n",
      "Accuracy:0.5080736875534058\n",
      "___________________\n",
      "Epoch:229\n",
      "Train Loss:0.6894055604934692\n",
      "Test Loss:0.6915719509124756\n",
      "Accuracy:0.5080680251121521\n",
      "___________________\n",
      "Epoch:230\n",
      "Train Loss:0.6893883943557739\n",
      "Test Loss:0.6915606260299683\n",
      "Accuracy:0.5080652236938477\n",
      "___________________\n",
      "Epoch:231\n",
      "Train Loss:0.6893712878227234\n",
      "Test Loss:0.6915492415428162\n",
      "Accuracy:0.508059561252594\n",
      "___________________\n",
      "Epoch:232\n",
      "Train Loss:0.6893540024757385\n",
      "Test Loss:0.6915379166603088\n",
      "Accuracy:0.5080652236938477\n",
      "___________________\n",
      "Epoch:233\n",
      "Train Loss:0.6893368363380432\n",
      "Test Loss:0.6915265321731567\n",
      "Accuracy:0.508059561252594\n",
      "___________________\n",
      "Epoch:234\n",
      "Train Loss:0.6893194317817688\n",
      "Test Loss:0.6915149688720703\n",
      "Accuracy:0.5080652236938477\n",
      "___________________\n",
      "Epoch:235\n",
      "Train Loss:0.6893021464347839\n",
      "Test Loss:0.6915034055709839\n",
      "Accuracy:0.5080680251121521\n",
      "___________________\n",
      "Epoch:236\n",
      "Train Loss:0.6892847418785095\n",
      "Test Loss:0.6914920210838318\n",
      "Accuracy:0.5080680251121521\n",
      "___________________\n",
      "Epoch:237\n",
      "Train Loss:0.6892673969268799\n",
      "Test Loss:0.6914803981781006\n",
      "Accuracy:0.5080708265304565\n",
      "___________________\n",
      "Epoch:238\n",
      "Train Loss:0.6892499327659607\n",
      "Test Loss:0.6914688348770142\n",
      "Accuracy:0.5080736875534058\n",
      "___________________\n",
      "Epoch:239\n",
      "Train Loss:0.6892325282096863\n",
      "Test Loss:0.691457211971283\n",
      "Accuracy:0.5080680251121521\n",
      "___________________\n",
      "Epoch:240\n",
      "Train Loss:0.6892150044441223\n",
      "Test Loss:0.6914456486701965\n",
      "Accuracy:0.5080792903900146\n",
      "___________________\n",
      "Epoch:241\n",
      "Train Loss:0.6891974806785583\n",
      "Test Loss:0.6914339661598206\n",
      "Accuracy:0.5080792903900146\n",
      "___________________\n",
      "Epoch:242\n",
      "Train Loss:0.6891798973083496\n",
      "Test Loss:0.6914223432540894\n",
      "Accuracy:0.5080736875534058\n",
      "___________________\n",
      "Epoch:243\n",
      "Train Loss:0.6891623139381409\n",
      "Test Loss:0.6914105415344238\n",
      "Accuracy:0.5080764889717102\n",
      "___________________\n",
      "Epoch:244\n",
      "Train Loss:0.6891445517539978\n",
      "Test Loss:0.6913988590240479\n",
      "Accuracy:0.5080567598342896\n",
      "___________________\n",
      "Epoch:245\n",
      "Train Loss:0.6891268491744995\n",
      "Test Loss:0.6913871169090271\n",
      "Accuracy:0.5080398321151733\n",
      "___________________\n",
      "Epoch:246\n",
      "Train Loss:0.6891090273857117\n",
      "Test Loss:0.6913753151893616\n",
      "Accuracy:0.5080341696739197\n",
      "___________________\n",
      "Epoch:247\n",
      "Train Loss:0.6890912055969238\n",
      "Test Loss:0.6913634538650513\n",
      "Accuracy:0.5080229043960571\n",
      "___________________\n",
      "Epoch:248\n",
      "Train Loss:0.6890733242034912\n",
      "Test Loss:0.6913517117500305\n",
      "Accuracy:0.5080173015594482\n",
      "___________________\n",
      "Epoch:249\n",
      "Train Loss:0.6890554428100586\n",
      "Test Loss:0.6913397312164307\n",
      "Accuracy:0.5080145001411438\n",
      "___________________\n",
      "Epoch:250\n",
      "Train Loss:0.689037561416626\n",
      "Test Loss:0.6913278102874756\n",
      "Accuracy:0.5080087780952454\n",
      "___________________\n",
      "Epoch:251\n",
      "Train Loss:0.6890195608139038\n",
      "Test Loss:0.6913158297538757\n",
      "Accuracy:0.5079890489578247\n",
      "___________________\n",
      "Epoch:252\n",
      "Train Loss:0.6890015602111816\n",
      "Test Loss:0.6913039088249207\n",
      "Accuracy:0.5079777836799622\n",
      "___________________\n",
      "Epoch:253\n",
      "Train Loss:0.6889836192131042\n",
      "Test Loss:0.691291868686676\n",
      "Accuracy:0.5079777836799622\n",
      "___________________\n",
      "Epoch:254\n",
      "Train Loss:0.6889654994010925\n",
      "Test Loss:0.6912798285484314\n",
      "Accuracy:0.507983386516571\n",
      "___________________\n",
      "Epoch:255\n",
      "Train Loss:0.6889473795890808\n",
      "Test Loss:0.6912678480148315\n",
      "Accuracy:0.5079777836799622\n",
      "___________________\n",
      "Epoch:256\n",
      "Train Loss:0.6889292001724243\n",
      "Test Loss:0.6912557482719421\n",
      "Accuracy:0.5079664587974548\n",
      "___________________\n",
      "Epoch:257\n",
      "Train Loss:0.688910961151123\n",
      "Test Loss:0.6912436485290527\n",
      "Accuracy:0.5079636573791504\n",
      "___________________\n",
      "Epoch:258\n",
      "Train Loss:0.6888927817344666\n",
      "Test Loss:0.6912315487861633\n",
      "Accuracy:0.5079523921012878\n",
      "___________________\n",
      "Epoch:259\n",
      "Train Loss:0.6888744831085205\n",
      "Test Loss:0.6912194490432739\n",
      "Accuracy:0.507946789264679\n",
      "___________________\n",
      "Epoch:260\n",
      "Train Loss:0.6888560652732849\n",
      "Test Loss:0.6912072896957397\n",
      "Accuracy:0.5079383254051208\n",
      "___________________\n",
      "Epoch:261\n",
      "Train Loss:0.6888377666473389\n",
      "Test Loss:0.6911951303482056\n",
      "Accuracy:0.507915735244751\n",
      "___________________\n",
      "Epoch:262\n",
      "Train Loss:0.6888193488121033\n",
      "Test Loss:0.6911829113960266\n",
      "Accuracy:0.507901668548584\n",
      "___________________\n",
      "Epoch:263\n",
      "Train Loss:0.6888008117675781\n",
      "Test Loss:0.6911706924438477\n",
      "Accuracy:0.5078988671302795\n",
      "___________________\n",
      "Epoch:264\n",
      "Train Loss:0.6887823343276978\n",
      "Test Loss:0.6911584138870239\n",
      "Accuracy:0.5078847408294678\n",
      "___________________\n",
      "Epoch:265\n",
      "Train Loss:0.6887637972831726\n",
      "Test Loss:0.6911460757255554\n",
      "Accuracy:0.5078932046890259\n",
      "___________________\n",
      "Epoch:266\n",
      "Train Loss:0.6887451410293579\n",
      "Test Loss:0.6911337375640869\n",
      "Accuracy:0.5078875422477722\n",
      "___________________\n",
      "Epoch:267\n",
      "Train Loss:0.6887264847755432\n",
      "Test Loss:0.6911213994026184\n",
      "Accuracy:0.5078875422477722\n",
      "___________________\n",
      "Epoch:268\n",
      "Train Loss:0.688707709312439\n",
      "Test Loss:0.6911090612411499\n",
      "Accuracy:0.5078819394111633\n",
      "___________________\n",
      "Epoch:269\n",
      "Train Loss:0.6886889934539795\n",
      "Test Loss:0.6910966634750366\n",
      "Accuracy:0.5078847408294678\n",
      "___________________\n",
      "Epoch:270\n",
      "Train Loss:0.6886702179908752\n",
      "Test Loss:0.6910842657089233\n",
      "Accuracy:0.5078678131103516\n",
      "___________________\n",
      "Epoch:271\n",
      "Train Loss:0.6886513829231262\n",
      "Test Loss:0.6910717487335205\n",
      "Accuracy:0.507856547832489\n",
      "___________________\n",
      "Epoch:272\n",
      "Train Loss:0.6886324882507324\n",
      "Test Loss:0.6910593509674072\n",
      "Accuracy:0.5078396201133728\n",
      "___________________\n",
      "Epoch:273\n",
      "Train Loss:0.6886135339736938\n",
      "Test Loss:0.6910468935966492\n",
      "Accuracy:0.5078368186950684\n",
      "___________________\n",
      "Epoch:274\n",
      "Train Loss:0.6885945200920105\n",
      "Test Loss:0.6910342574119568\n",
      "Accuracy:0.5078396201133728\n",
      "___________________\n",
      "Epoch:275\n",
      "Train Loss:0.6885754466056824\n",
      "Test Loss:0.6910215616226196\n",
      "Accuracy:0.5078310966491699\n",
      "___________________\n",
      "Epoch:276\n",
      "Train Loss:0.6885563135147095\n",
      "Test Loss:0.6910089254379272\n",
      "Accuracy:0.5078311562538147\n",
      "___________________\n",
      "Epoch:277\n",
      "Train Loss:0.6885371208190918\n",
      "Test Loss:0.6909961700439453\n",
      "Accuracy:0.5078282952308655\n",
      "___________________\n",
      "Epoch:278\n",
      "Train Loss:0.6885177493095398\n",
      "Test Loss:0.6909835338592529\n",
      "Accuracy:0.5078142285346985\n",
      "___________________\n",
      "Epoch:279\n",
      "Train Loss:0.6884984374046326\n",
      "Test Loss:0.6909706592559814\n",
      "Accuracy:0.5078057646751404\n",
      "___________________\n",
      "Epoch:280\n",
      "Train Loss:0.6884790062904358\n",
      "Test Loss:0.6909580230712891\n",
      "Accuracy:0.5078029632568359\n",
      "___________________\n",
      "Epoch:281\n",
      "Train Loss:0.6884596943855286\n",
      "Test Loss:0.6909450888633728\n",
      "Accuracy:0.5078029632568359\n",
      "___________________\n",
      "Epoch:282\n",
      "Train Loss:0.6884401440620422\n",
      "Test Loss:0.6909322142601013\n",
      "Accuracy:0.5077944993972778\n",
      "___________________\n",
      "Epoch:283\n",
      "Train Loss:0.6884205937385559\n",
      "Test Loss:0.6909193396568298\n",
      "Accuracy:0.5077831745147705\n",
      "___________________\n",
      "Epoch:284\n",
      "Train Loss:0.6884011030197144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.6909062266349792\n",
      "Accuracy:0.5077747106552124\n",
      "___________________\n",
      "Epoch:285\n",
      "Train Loss:0.6883814334869385\n",
      "Test Loss:0.6908932328224182\n",
      "Accuracy:0.5077634453773499\n",
      "___________________\n",
      "Epoch:286\n",
      "Train Loss:0.6883618235588074\n",
      "Test Loss:0.690880298614502\n",
      "Accuracy:0.5077521800994873\n",
      "___________________\n",
      "Epoch:287\n",
      "Train Loss:0.6883421540260315\n",
      "Test Loss:0.6908673048019409\n",
      "Accuracy:0.5077493786811829\n",
      "___________________\n",
      "Epoch:288\n",
      "Train Loss:0.6883223652839661\n",
      "Test Loss:0.6908542513847351\n",
      "Accuracy:0.5077380537986755\n",
      "___________________\n",
      "Epoch:289\n",
      "Train Loss:0.6883025169372559\n",
      "Test Loss:0.6908410787582397\n",
      "Accuracy:0.5077324509620667\n",
      "___________________\n",
      "Epoch:290\n",
      "Train Loss:0.6882827281951904\n",
      "Test Loss:0.6908279061317444\n",
      "Accuracy:0.5077239871025085\n",
      "___________________\n",
      "Epoch:291\n",
      "Train Loss:0.6882628202438354\n",
      "Test Loss:0.6908146739006042\n",
      "Accuracy:0.5077183246612549\n",
      "___________________\n",
      "Epoch:292\n",
      "Train Loss:0.6882427930831909\n",
      "Test Loss:0.6908015012741089\n",
      "Accuracy:0.5077098608016968\n",
      "___________________\n",
      "Epoch:293\n",
      "Train Loss:0.6882227659225464\n",
      "Test Loss:0.6907882690429688\n",
      "Accuracy:0.5076985359191895\n",
      "___________________\n",
      "Epoch:294\n",
      "Train Loss:0.6882026791572571\n",
      "Test Loss:0.6907749772071838\n",
      "Accuracy:0.5076844692230225\n",
      "___________________\n",
      "Epoch:295\n",
      "Train Loss:0.688182532787323\n",
      "Test Loss:0.6907617449760437\n",
      "Accuracy:0.507681667804718\n",
      "___________________\n",
      "Epoch:296\n",
      "Train Loss:0.6881623268127441\n",
      "Test Loss:0.690748393535614\n",
      "Accuracy:0.5076872706413269\n",
      "___________________\n",
      "Epoch:297\n",
      "Train Loss:0.6881420016288757\n",
      "Test Loss:0.6907349824905396\n",
      "Accuracy:0.5076788663864136\n",
      "___________________\n",
      "Epoch:298\n",
      "Train Loss:0.6881216168403625\n",
      "Test Loss:0.6907216310501099\n",
      "Accuracy:0.5076647400856018\n",
      "___________________\n",
      "Epoch:299\n",
      "Train Loss:0.6881011724472046\n",
      "Test Loss:0.6907082200050354\n",
      "Accuracy:0.5076563358306885\n",
      "___________________\n",
      "Epoch:300\n",
      "Train Loss:0.6880807876586914\n",
      "Test Loss:0.6906947493553162\n",
      "Accuracy:0.507636547088623\n",
      "___________________\n",
      "Epoch:301\n",
      "Train Loss:0.6880602240562439\n",
      "Test Loss:0.6906812787055969\n",
      "Accuracy:0.5076168179512024\n",
      "___________________\n",
      "Epoch:302\n",
      "Train Loss:0.6880397200584412\n",
      "Test Loss:0.6906677484512329\n",
      "Accuracy:0.5075998902320862\n",
      "___________________\n",
      "Epoch:303\n",
      "Train Loss:0.6880190372467041\n",
      "Test Loss:0.6906541585922241\n",
      "Accuracy:0.5075858235359192\n",
      "___________________\n",
      "Epoch:304\n",
      "Train Loss:0.687998354434967\n",
      "Test Loss:0.6906405687332153\n",
      "Accuracy:0.507568895816803\n",
      "___________________\n",
      "Epoch:305\n",
      "Train Loss:0.6879776120185852\n",
      "Test Loss:0.690626859664917\n",
      "Accuracy:0.5075519680976868\n",
      "___________________\n",
      "Epoch:306\n",
      "Train Loss:0.6879568099975586\n",
      "Test Loss:0.6906131505966187\n",
      "Accuracy:0.5075491666793823\n",
      "___________________\n",
      "Epoch:307\n",
      "Train Loss:0.6879358887672424\n",
      "Test Loss:0.6905993819236755\n",
      "Accuracy:0.5075322389602661\n",
      "___________________\n",
      "Epoch:308\n",
      "Train Loss:0.6879149675369263\n",
      "Test Loss:0.6905856132507324\n",
      "Accuracy:0.5075152516365051\n",
      "___________________\n",
      "Epoch:309\n",
      "Train Loss:0.6878939270973206\n",
      "Test Loss:0.6905719041824341\n",
      "Accuracy:0.5075068473815918\n",
      "___________________\n",
      "Epoch:310\n",
      "Train Loss:0.6878728270530701\n",
      "Test Loss:0.6905580759048462\n",
      "Accuracy:0.5074955821037292\n",
      "___________________\n",
      "Epoch:311\n",
      "Train Loss:0.6878517270088196\n",
      "Test Loss:0.6905441880226135\n",
      "Accuracy:0.5074842572212219\n",
      "___________________\n",
      "Epoch:312\n",
      "Train Loss:0.6878305673599243\n",
      "Test Loss:0.6905301809310913\n",
      "Accuracy:0.5074673891067505\n",
      "___________________\n",
      "Epoch:313\n",
      "Train Loss:0.6878092885017395\n",
      "Test Loss:0.6905161738395691\n",
      "Accuracy:0.5074673891067505\n",
      "___________________\n",
      "Epoch:314\n",
      "Train Loss:0.6877880096435547\n",
      "Test Loss:0.6905022263526917\n",
      "Accuracy:0.5074588656425476\n",
      "___________________\n",
      "Epoch:315\n",
      "Train Loss:0.6877666115760803\n",
      "Test Loss:0.6904882192611694\n",
      "Accuracy:0.5074532628059387\n",
      "___________________\n",
      "Epoch:316\n",
      "Train Loss:0.6877450942993164\n",
      "Test Loss:0.6904740929603577\n",
      "Accuracy:0.5074419975280762\n",
      "___________________\n",
      "Epoch:317\n",
      "Train Loss:0.6877236366271973\n",
      "Test Loss:0.6904599070549011\n",
      "Accuracy:0.5074335336685181\n",
      "___________________\n",
      "Epoch:318\n",
      "Train Loss:0.6877020597457886\n",
      "Test Loss:0.6904457211494446\n",
      "Accuracy:0.5074278116226196\n",
      "___________________\n",
      "Epoch:319\n",
      "Train Loss:0.6876804828643799\n",
      "Test Loss:0.6904315948486328\n",
      "Accuracy:0.5074081420898438\n",
      "___________________\n",
      "Epoch:320\n",
      "Train Loss:0.6876586675643921\n",
      "Test Loss:0.6904173493385315\n",
      "Accuracy:0.5073940753936768\n",
      "___________________\n",
      "Epoch:321\n",
      "Train Loss:0.6876369714736938\n",
      "Test Loss:0.6904030442237854\n",
      "Accuracy:0.5073828101158142\n",
      "___________________\n",
      "Epoch:322\n",
      "Train Loss:0.687615156173706\n",
      "Test Loss:0.6903886795043945\n",
      "Accuracy:0.5073771476745605\n",
      "___________________\n",
      "Epoch:323\n",
      "Train Loss:0.6875932812690735\n",
      "Test Loss:0.6903743147850037\n",
      "Accuracy:0.5073630213737488\n",
      "___________________\n",
      "Epoch:324\n",
      "Train Loss:0.6875712275505066\n",
      "Test Loss:0.6903599500656128\n",
      "Accuracy:0.5073517560958862\n",
      "___________________\n",
      "Epoch:325\n",
      "Train Loss:0.6875492334365845\n",
      "Test Loss:0.6903455257415771\n",
      "Accuracy:0.50733482837677\n",
      "___________________\n",
      "Epoch:326\n",
      "Train Loss:0.6875272393226624\n",
      "Test Loss:0.6903311610221863\n",
      "Accuracy:0.5073150992393494\n",
      "___________________\n",
      "Epoch:327\n",
      "Train Loss:0.6875050663948059\n",
      "Test Loss:0.6903166770935059\n",
      "Accuracy:0.5073122978210449\n",
      "___________________\n",
      "Epoch:328\n",
      "Train Loss:0.6874829530715942\n",
      "Test Loss:0.6903021931648254\n",
      "Accuracy:0.5073009729385376\n",
      "___________________\n",
      "Epoch:329\n",
      "Train Loss:0.6874607801437378\n",
      "Test Loss:0.690287709236145\n",
      "Accuracy:0.5073009729385376\n",
      "___________________\n",
      "Epoch:330\n",
      "Train Loss:0.687438428401947\n",
      "Test Loss:0.6902731657028198\n",
      "Accuracy:0.5072925090789795\n",
      "___________________\n",
      "Epoch:331\n",
      "Train Loss:0.6874160766601562\n",
      "Test Loss:0.6902586221694946\n",
      "Accuracy:0.5072755813598633\n",
      "___________________\n",
      "Epoch:332\n",
      "Train Loss:0.6873936653137207\n",
      "Test Loss:0.6902440190315247\n",
      "Accuracy:0.5072558522224426\n",
      "___________________\n",
      "Epoch:333\n",
      "Train Loss:0.6873711943626404\n",
      "Test Loss:0.6902293562889099\n",
      "Accuracy:0.5072389841079712\n",
      "___________________\n",
      "Epoch:334\n",
      "Train Loss:0.6873486042022705\n",
      "Test Loss:0.6902146339416504\n",
      "Accuracy:0.5072248578071594\n",
      "___________________\n",
      "Epoch:335\n",
      "Train Loss:0.6873260736465454\n",
      "Test Loss:0.6901999115943909\n",
      "Accuracy:0.5072079300880432\n",
      "___________________\n",
      "Epoch:336\n",
      "Train Loss:0.6873033046722412\n",
      "Test Loss:0.6901851296424866\n",
      "Accuracy:0.5071966648101807\n",
      "___________________\n",
      "Epoch:337\n",
      "Train Loss:0.6872805953025818\n",
      "Test Loss:0.6901703476905823\n",
      "Accuracy:0.5071938037872314\n",
      "___________________\n",
      "Epoch:338\n",
      "Train Loss:0.6872576475143433\n",
      "Test Loss:0.690155565738678\n",
      "Accuracy:0.5071882009506226\n",
      "___________________\n",
      "Epoch:339\n",
      "Train Loss:0.6872347593307495\n",
      "Test Loss:0.6901406049728394\n",
      "Accuracy:0.5071796774864197\n",
      "___________________\n",
      "Epoch:340\n",
      "Train Loss:0.687211811542511\n",
      "Test Loss:0.6901257038116455\n",
      "Accuracy:0.5071684122085571\n",
      "___________________\n",
      "Epoch:341\n",
      "Train Loss:0.6871887445449829\n",
      "Test Loss:0.6901106238365173\n",
      "Accuracy:0.5071628093719482\n",
      "___________________\n",
      "Epoch:342\n",
      "Train Loss:0.6871656775474548\n",
      "Test Loss:0.6900956034660339\n",
      "Accuracy:0.5071543455123901\n",
      "___________________\n",
      "Epoch:343\n",
      "Train Loss:0.6871423721313477\n",
      "Test Loss:0.690080463886261\n",
      "Accuracy:0.5071430206298828\n",
      "___________________\n",
      "Epoch:344\n",
      "Train Loss:0.6871190667152405\n",
      "Test Loss:0.6900652647018433\n",
      "Accuracy:0.5071289539337158\n",
      "___________________\n",
      "Epoch:345\n",
      "Train Loss:0.6870957016944885\n",
      "Test Loss:0.6900501251220703\n",
      "Accuracy:0.5071176886558533\n",
      "___________________\n",
      "Epoch:346\n",
      "Train Loss:0.6870721578598022\n",
      "Test Loss:0.6900347471237183\n",
      "Accuracy:0.5071120262145996\n",
      "___________________\n",
      "Epoch:347\n",
      "Train Loss:0.6870485544204712\n",
      "Test Loss:0.690019428730011\n",
      "Accuracy:0.5071120262145996\n",
      "___________________\n",
      "Epoch:348\n",
      "Train Loss:0.6870250105857849\n",
      "Test Loss:0.6900040507316589\n",
      "Accuracy:0.5070950984954834\n",
      "___________________\n",
      "Epoch:349\n",
      "Train Loss:0.6870012879371643\n",
      "Test Loss:0.6899885535240173\n",
      "Accuracy:0.5070894360542297\n",
      "___________________\n",
      "Epoch:350\n",
      "Train Loss:0.6869774460792542\n",
      "Test Loss:0.6899730563163757\n",
      "Accuracy:0.5070781707763672\n",
      "___________________\n",
      "Epoch:351\n",
      "Train Loss:0.6869535446166992\n",
      "Test Loss:0.6899574995040894\n",
      "Accuracy:0.5070641040802002\n",
      "___________________\n",
      "Epoch:352\n",
      "Train Loss:0.6869295239448547\n",
      "Test Loss:0.6899420022964478\n",
      "Accuracy:0.5070556402206421\n",
      "___________________\n",
      "Epoch:353\n",
      "Train Loss:0.686905562877655\n",
      "Test Loss:0.6899263858795166\n",
      "Accuracy:0.5070358514785767\n",
      "___________________\n",
      "Epoch:354\n",
      "Train Loss:0.686881422996521\n",
      "Test Loss:0.6899107694625854\n",
      "Accuracy:0.5070302486419678\n",
      "___________________\n",
      "Epoch:355\n",
      "Train Loss:0.6868572235107422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.6898949146270752\n",
      "Accuracy:0.5070274472236633\n",
      "___________________\n",
      "Epoch:356\n",
      "Train Loss:0.686832845211029\n",
      "Test Loss:0.6898791193962097\n",
      "Accuracy:0.5070246458053589\n",
      "___________________\n",
      "Epoch:357\n",
      "Train Loss:0.6868084669113159\n",
      "Test Loss:0.6898632645606995\n",
      "Accuracy:0.5070133209228516\n",
      "___________________\n",
      "Epoch:358\n",
      "Train Loss:0.686784029006958\n",
      "Test Loss:0.689847469329834\n",
      "Accuracy:0.5069991946220398\n",
      "___________________\n",
      "Epoch:359\n",
      "Train Loss:0.6867595911026001\n",
      "Test Loss:0.6898316144943237\n",
      "Accuracy:0.5069963932037354\n",
      "___________________\n",
      "Epoch:360\n",
      "Train Loss:0.6867349147796631\n",
      "Test Loss:0.6898157000541687\n",
      "Accuracy:0.5069851279258728\n",
      "___________________\n",
      "Epoch:361\n",
      "Train Loss:0.6867101788520813\n",
      "Test Loss:0.6897997260093689\n",
      "Accuracy:0.5069795250892639\n",
      "___________________\n",
      "Epoch:362\n",
      "Train Loss:0.6866853833198547\n",
      "Test Loss:0.6897835731506348\n",
      "Accuracy:0.5069654583930969\n",
      "___________________\n",
      "Epoch:363\n",
      "Train Loss:0.6866604685783386\n",
      "Test Loss:0.6897674798965454\n",
      "Accuracy:0.5069484710693359\n",
      "___________________\n",
      "Epoch:364\n",
      "Train Loss:0.6866355538368225\n",
      "Test Loss:0.6897513270378113\n",
      "Accuracy:0.506942868232727\n",
      "___________________\n",
      "Epoch:365\n",
      "Train Loss:0.6866105198860168\n",
      "Test Loss:0.6897350549697876\n",
      "Accuracy:0.5069287419319153\n",
      "___________________\n",
      "Epoch:366\n",
      "Train Loss:0.6865854263305664\n",
      "Test Loss:0.6897188425064087\n",
      "Accuracy:0.506917417049408\n",
      "___________________\n",
      "Epoch:367\n",
      "Train Loss:0.6865602731704712\n",
      "Test Loss:0.6897025108337402\n",
      "Accuracy:0.5068949460983276\n",
      "___________________\n",
      "Epoch:368\n",
      "Train Loss:0.6865349411964417\n",
      "Test Loss:0.689686119556427\n",
      "Accuracy:0.5068808197975159\n",
      "___________________\n",
      "Epoch:369\n",
      "Train Loss:0.6865096092224121\n",
      "Test Loss:0.6896698474884033\n",
      "Accuracy:0.5068666934967041\n",
      "___________________\n",
      "Epoch:370\n",
      "Train Loss:0.6864842176437378\n",
      "Test Loss:0.6896533966064453\n",
      "Accuracy:0.5068469643592834\n",
      "___________________\n",
      "Epoch:371\n",
      "Train Loss:0.6864587068557739\n",
      "Test Loss:0.6896368861198425\n",
      "Accuracy:0.5068328380584717\n",
      "___________________\n",
      "Epoch:372\n",
      "Train Loss:0.6864331364631653\n",
      "Test Loss:0.6896204352378845\n",
      "Accuracy:0.5068299770355225\n",
      "___________________\n",
      "Epoch:373\n",
      "Train Loss:0.6864074468612671\n",
      "Test Loss:0.6896038055419922\n",
      "Accuracy:0.5068159699440002\n",
      "___________________\n",
      "Epoch:374\n",
      "Train Loss:0.6863816976547241\n",
      "Test Loss:0.6895871162414551\n",
      "Accuracy:0.5068075060844421\n",
      "___________________\n",
      "Epoch:375\n",
      "Train Loss:0.6863558292388916\n",
      "Test Loss:0.6895703673362732\n",
      "Accuracy:0.506799042224884\n",
      "___________________\n",
      "Epoch:376\n",
      "Train Loss:0.6863297820091248\n",
      "Test Loss:0.6895536184310913\n",
      "Accuracy:0.5067849159240723\n",
      "___________________\n",
      "Epoch:377\n",
      "Train Loss:0.6863037943840027\n",
      "Test Loss:0.6895367503166199\n",
      "Accuracy:0.5067708492279053\n",
      "___________________\n",
      "Epoch:378\n",
      "Train Loss:0.6862776279449463\n",
      "Test Loss:0.6895199418067932\n",
      "Accuracy:0.506767988204956\n",
      "___________________\n",
      "Epoch:379\n",
      "Train Loss:0.6862514615058899\n",
      "Test Loss:0.6895029544830322\n",
      "Accuracy:0.506767988204956\n",
      "___________________\n",
      "Epoch:380\n",
      "Train Loss:0.6862252354621887\n",
      "Test Loss:0.6894860863685608\n",
      "Accuracy:0.506759524345398\n",
      "___________________\n",
      "Epoch:381\n",
      "Train Loss:0.6861989498138428\n",
      "Test Loss:0.6894689202308655\n",
      "Accuracy:0.5067510604858398\n",
      "___________________\n",
      "Epoch:382\n",
      "Train Loss:0.6861724853515625\n",
      "Test Loss:0.6894519329071045\n",
      "Accuracy:0.5067398548126221\n",
      "___________________\n",
      "Epoch:383\n",
      "Train Loss:0.6861460208892822\n",
      "Test Loss:0.6894347071647644\n",
      "Accuracy:0.5067313313484192\n",
      "___________________\n",
      "Epoch:384\n",
      "Train Loss:0.6861193180084229\n",
      "Test Loss:0.6894176006317139\n",
      "Accuracy:0.5067228674888611\n",
      "___________________\n",
      "Epoch:385\n",
      "Train Loss:0.6860926747322083\n",
      "Test Loss:0.689400315284729\n",
      "Accuracy:0.5067116022109985\n",
      "___________________\n",
      "Epoch:386\n",
      "Train Loss:0.6860657930374146\n",
      "Test Loss:0.6893828511238098\n",
      "Accuracy:0.5066918134689331\n",
      "___________________\n",
      "Epoch:387\n",
      "Train Loss:0.6860388517379761\n",
      "Test Loss:0.6893655061721802\n",
      "Accuracy:0.5066777467727661\n",
      "___________________\n",
      "Epoch:388\n",
      "Train Loss:0.6860119104385376\n",
      "Test Loss:0.689348042011261\n",
      "Accuracy:0.5066664814949036\n",
      "___________________\n",
      "Epoch:389\n",
      "Train Loss:0.6859847903251648\n",
      "Test Loss:0.6893304586410522\n",
      "Accuracy:0.5066524147987366\n",
      "___________________\n",
      "Epoch:390\n",
      "Train Loss:0.6859576106071472\n",
      "Test Loss:0.6893129348754883\n",
      "Accuracy:0.5066326260566711\n",
      "___________________\n",
      "Epoch:391\n",
      "Train Loss:0.6859302520751953\n",
      "Test Loss:0.68929523229599\n",
      "Accuracy:0.506624162197113\n",
      "___________________\n",
      "Epoch:392\n",
      "Train Loss:0.6859029531478882\n",
      "Test Loss:0.6892775893211365\n",
      "Accuracy:0.5066044330596924\n",
      "___________________\n",
      "Epoch:393\n",
      "Train Loss:0.6858754754066467\n",
      "Test Loss:0.6892598271369934\n",
      "Accuracy:0.5065818428993225\n",
      "___________________\n",
      "Epoch:394\n",
      "Train Loss:0.6858479380607605\n",
      "Test Loss:0.6892419457435608\n",
      "Accuracy:0.5065790414810181\n",
      "___________________\n",
      "Epoch:395\n",
      "Train Loss:0.6858204007148743\n",
      "Test Loss:0.6892241835594177\n",
      "Accuracy:0.50657057762146\n",
      "___________________\n",
      "Epoch:396\n",
      "Train Loss:0.6857927441596985\n",
      "Test Loss:0.6892063617706299\n",
      "Accuracy:0.5065762400627136\n",
      "___________________\n",
      "Epoch:397\n",
      "Train Loss:0.6857650279998779\n",
      "Test Loss:0.6891883015632629\n",
      "Accuracy:0.5065537095069885\n",
      "___________________\n",
      "Epoch:398\n",
      "Train Loss:0.6857373118400574\n",
      "Test Loss:0.689170241355896\n",
      "Accuracy:0.5065537095069885\n",
      "___________________\n",
      "Epoch:399\n",
      "Train Loss:0.6857094764709473\n",
      "Test Loss:0.6891522407531738\n",
      "Accuracy:0.5065423846244812\n",
      "___________________\n",
      "Epoch:400\n",
      "Train Loss:0.6856813430786133\n",
      "Test Loss:0.6891341805458069\n",
      "Accuracy:0.5065395832061768\n",
      "___________________\n",
      "Epoch:401\n",
      "Train Loss:0.6856533885002136\n",
      "Test Loss:0.6891160011291504\n",
      "Accuracy:0.5065339207649231\n",
      "___________________\n",
      "Epoch:402\n",
      "Train Loss:0.6856251955032349\n",
      "Test Loss:0.6890978813171387\n",
      "Accuracy:0.5065169930458069\n",
      "___________________\n",
      "Epoch:403\n",
      "Train Loss:0.6855969429016113\n",
      "Test Loss:0.6890794634819031\n",
      "Accuracy:0.5065000653266907\n",
      "___________________\n",
      "Epoch:404\n",
      "Train Loss:0.6855687499046326\n",
      "Test Loss:0.6890613436698914\n",
      "Accuracy:0.5064859986305237\n",
      "___________________\n",
      "Epoch:405\n",
      "Train Loss:0.6855403184890747\n",
      "Test Loss:0.6890429854393005\n",
      "Accuracy:0.5064775347709656\n",
      "___________________\n",
      "Epoch:406\n",
      "Train Loss:0.6855118274688721\n",
      "Test Loss:0.6890245676040649\n",
      "Accuracy:0.5064464807510376\n",
      "___________________\n",
      "Epoch:407\n",
      "Train Loss:0.6854832768440247\n",
      "Test Loss:0.6890060901641846\n",
      "Accuracy:0.5064296126365662\n",
      "___________________\n",
      "Epoch:408\n",
      "Train Loss:0.6854546666145325\n",
      "Test Loss:0.688987672328949\n",
      "Accuracy:0.5064183473587036\n",
      "___________________\n",
      "Epoch:409\n",
      "Train Loss:0.685425877571106\n",
      "Test Loss:0.6889691352844238\n",
      "Accuracy:0.506398618221283\n",
      "___________________\n",
      "Epoch:410\n",
      "Train Loss:0.6853970289230347\n",
      "Test Loss:0.6889507174491882\n",
      "Accuracy:0.5063844919204712\n",
      "___________________\n",
      "Epoch:411\n",
      "Train Loss:0.6853680610656738\n",
      "Test Loss:0.6889320611953735\n",
      "Accuracy:0.5063732266426086\n",
      "___________________\n",
      "Epoch:412\n",
      "Train Loss:0.6853389143943787\n",
      "Test Loss:0.6889134049415588\n",
      "Accuracy:0.5063676238059998\n",
      "___________________\n",
      "Epoch:413\n",
      "Train Loss:0.6853097677230835\n",
      "Test Loss:0.6888946890830994\n",
      "Accuracy:0.5063506364822388\n",
      "___________________\n",
      "Epoch:414\n",
      "Train Loss:0.6852805614471436\n",
      "Test Loss:0.6888760328292847\n",
      "Accuracy:0.5063449740409851\n",
      "___________________\n",
      "Epoch:415\n",
      "Train Loss:0.6852512359619141\n",
      "Test Loss:0.6888573169708252\n",
      "Accuracy:0.5063337087631226\n",
      "___________________\n",
      "Epoch:416\n",
      "Train Loss:0.6852218508720398\n",
      "Test Loss:0.6888386011123657\n",
      "Accuracy:0.5063083171844482\n",
      "___________________\n",
      "Epoch:417\n",
      "Train Loss:0.6851924061775208\n",
      "Test Loss:0.6888197064399719\n",
      "Accuracy:0.5063027143478394\n",
      "___________________\n",
      "Epoch:418\n",
      "Train Loss:0.6851627826690674\n",
      "Test Loss:0.6888008117675781\n",
      "Accuracy:0.5062942504882812\n",
      "___________________\n",
      "Epoch:419\n",
      "Train Loss:0.6851332783699036\n",
      "Test Loss:0.6887819766998291\n",
      "Accuracy:0.5062885880470276\n",
      "___________________\n",
      "Epoch:420\n",
      "Train Loss:0.6851035952568054\n",
      "Test Loss:0.6887630820274353\n",
      "Accuracy:0.5062744617462158\n",
      "___________________\n",
      "Epoch:421\n",
      "Train Loss:0.6850739121437073\n",
      "Test Loss:0.688744068145752\n",
      "Accuracy:0.5062603950500488\n",
      "___________________\n",
      "Epoch:422\n",
      "Train Loss:0.6850441694259644\n",
      "Test Loss:0.6887251734733582\n",
      "Accuracy:0.5062434673309326\n",
      "___________________\n",
      "Epoch:423\n",
      "Train Loss:0.6850141882896423\n",
      "Test Loss:0.6887059807777405\n",
      "Accuracy:0.506223738193512\n",
      "___________________\n",
      "Epoch:424\n",
      "Train Loss:0.6849842071533203\n",
      "Test Loss:0.6886868476867676\n",
      "Accuracy:0.5061983466148376\n",
      "___________________\n",
      "Epoch:425\n",
      "Train Loss:0.6849539875984192\n",
      "Test Loss:0.6886677145957947\n",
      "Accuracy:0.5061729550361633\n",
      "___________________\n",
      "Epoch:426\n",
      "Train Loss:0.6849237084388733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.6886484026908875\n",
      "Accuracy:0.5061588883399963\n",
      "___________________\n",
      "Epoch:427\n",
      "Train Loss:0.6848933696746826\n",
      "Test Loss:0.6886292099952698\n",
      "Accuracy:0.5061390995979309\n",
      "___________________\n",
      "Epoch:428\n",
      "Train Loss:0.6848629713058472\n",
      "Test Loss:0.6886098384857178\n",
      "Accuracy:0.5061250329017639\n",
      "___________________\n",
      "Epoch:429\n",
      "Train Loss:0.6848323345184326\n",
      "Test Loss:0.6885905861854553\n",
      "Accuracy:0.5061165690422058\n",
      "___________________\n",
      "Epoch:430\n",
      "Train Loss:0.6848017573356628\n",
      "Test Loss:0.6885712146759033\n",
      "Accuracy:0.5061137676239014\n",
      "___________________\n",
      "Epoch:431\n",
      "Train Loss:0.6847710013389587\n",
      "Test Loss:0.6885517835617065\n",
      "Accuracy:0.5061053037643433\n",
      "___________________\n",
      "Epoch:432\n",
      "Train Loss:0.6847401261329651\n",
      "Test Loss:0.6885321736335754\n",
      "Accuracy:0.5060997009277344\n",
      "___________________\n",
      "Epoch:433\n",
      "Train Loss:0.6847092509269714\n",
      "Test Loss:0.6885125041007996\n",
      "Accuracy:0.506088376045227\n",
      "___________________\n",
      "Epoch:434\n",
      "Train Loss:0.6846781969070435\n",
      "Test Loss:0.6884926557540894\n",
      "Accuracy:0.5060742497444153\n",
      "___________________\n",
      "Epoch:435\n",
      "Train Loss:0.6846470236778259\n",
      "Test Loss:0.6884728670120239\n",
      "Accuracy:0.506065845489502\n",
      "___________________\n",
      "Epoch:436\n",
      "Train Loss:0.6846157908439636\n",
      "Test Loss:0.6884528398513794\n",
      "Accuracy:0.5060629844665527\n",
      "___________________\n",
      "Epoch:437\n",
      "Train Loss:0.684584379196167\n",
      "Test Loss:0.6884328722953796\n",
      "Accuracy:0.5060601830482483\n",
      "___________________\n",
      "Epoch:438\n",
      "Train Loss:0.6845529675483704\n",
      "Test Loss:0.6884126663208008\n",
      "Accuracy:0.5060404539108276\n",
      "___________________\n",
      "Epoch:439\n",
      "Train Loss:0.684521496295929\n",
      "Test Loss:0.6883925795555115\n",
      "Accuracy:0.506034791469574\n",
      "___________________\n",
      "Epoch:440\n",
      "Train Loss:0.6844899654388428\n",
      "Test Loss:0.6883725523948669\n",
      "Accuracy:0.5060263276100159\n",
      "___________________\n",
      "Epoch:441\n",
      "Train Loss:0.684458315372467\n",
      "Test Loss:0.6883524656295776\n",
      "Accuracy:0.5060150623321533\n",
      "___________________\n",
      "Epoch:442\n",
      "Train Loss:0.6844265460968018\n",
      "Test Loss:0.6883323192596436\n",
      "Accuracy:0.5060093998908997\n",
      "___________________\n",
      "Epoch:443\n",
      "Train Loss:0.6843947768211365\n",
      "Test Loss:0.6883121728897095\n",
      "Accuracy:0.5059981346130371\n",
      "___________________\n",
      "Epoch:444\n",
      "Train Loss:0.6843627691268921\n",
      "Test Loss:0.6882918477058411\n",
      "Accuracy:0.5059868693351746\n",
      "___________________\n",
      "Epoch:445\n",
      "Train Loss:0.6843307018280029\n",
      "Test Loss:0.688271701335907\n",
      "Accuracy:0.5059671401977539\n",
      "___________________\n",
      "Epoch:446\n",
      "Train Loss:0.6842986345291138\n",
      "Test Loss:0.6882514953613281\n",
      "Accuracy:0.5059473514556885\n",
      "___________________\n",
      "Epoch:447\n",
      "Train Loss:0.6842663884162903\n",
      "Test Loss:0.6882311701774597\n",
      "Accuracy:0.505944550037384\n",
      "___________________\n",
      "Epoch:448\n",
      "Train Loss:0.684234082698822\n",
      "Test Loss:0.6882109045982361\n",
      "Accuracy:0.5059332847595215\n",
      "___________________\n",
      "Epoch:449\n",
      "Train Loss:0.6842017769813538\n",
      "Test Loss:0.6881904006004333\n",
      "Accuracy:0.5059192180633545\n",
      "___________________\n",
      "Epoch:450\n",
      "Train Loss:0.684169352054596\n",
      "Test Loss:0.6881700754165649\n",
      "Accuracy:0.5059078931808472\n",
      "___________________\n",
      "Epoch:451\n",
      "Train Loss:0.6841368079185486\n",
      "Test Loss:0.6881496906280518\n",
      "Accuracy:0.5059022307395935\n",
      "___________________\n",
      "Epoch:452\n",
      "Train Loss:0.6841042637825012\n",
      "Test Loss:0.688129186630249\n",
      "Accuracy:0.5058853626251221\n",
      "___________________\n",
      "Epoch:453\n",
      "Train Loss:0.6840714812278748\n",
      "Test Loss:0.6881087422370911\n",
      "Accuracy:0.5058655738830566\n",
      "___________________\n",
      "Epoch:454\n",
      "Train Loss:0.6840386986732483\n",
      "Test Loss:0.6880882382392883\n",
      "Accuracy:0.5058515071868896\n",
      "___________________\n",
      "Epoch:455\n",
      "Train Loss:0.6840056777000427\n",
      "Test Loss:0.6880675554275513\n",
      "Accuracy:0.5058515071868896\n",
      "___________________\n",
      "Epoch:456\n",
      "Train Loss:0.6839725375175476\n",
      "Test Loss:0.6880467534065247\n",
      "Accuracy:0.505845844745636\n",
      "___________________\n",
      "Epoch:457\n",
      "Train Loss:0.6839394569396973\n",
      "Test Loss:0.6880260109901428\n",
      "Accuracy:0.5058233141899109\n",
      "___________________\n",
      "Epoch:458\n",
      "Train Loss:0.6839062571525574\n",
      "Test Loss:0.6880051493644714\n",
      "Accuracy:0.5058091878890991\n",
      "___________________\n",
      "Epoch:459\n",
      "Train Loss:0.6838729977607727\n",
      "Test Loss:0.6879842877388\n",
      "Accuracy:0.5057950615882874\n",
      "___________________\n",
      "Epoch:460\n",
      "Train Loss:0.6838395595550537\n",
      "Test Loss:0.6879631280899048\n",
      "Accuracy:0.5057697892189026\n",
      "___________________\n",
      "Epoch:461\n",
      "Train Loss:0.6838060617446899\n",
      "Test Loss:0.6879422068595886\n",
      "Accuracy:0.5057640671730042\n",
      "___________________\n",
      "Epoch:462\n",
      "Train Loss:0.6837724447250366\n",
      "Test Loss:0.6879211664199829\n",
      "Accuracy:0.5057528018951416\n",
      "___________________\n",
      "Epoch:463\n",
      "Train Loss:0.6837387084960938\n",
      "Test Loss:0.6879000663757324\n",
      "Accuracy:0.5057330131530762\n",
      "___________________\n",
      "Epoch:464\n",
      "Train Loss:0.6837049126625061\n",
      "Test Loss:0.6878789663314819\n",
      "Accuracy:0.5057189464569092\n",
      "___________________\n",
      "Epoch:465\n",
      "Train Loss:0.6836710572242737\n",
      "Test Loss:0.6878578066825867\n",
      "Accuracy:0.505702018737793\n",
      "___________________\n",
      "Epoch:466\n",
      "Train Loss:0.6836370825767517\n",
      "Test Loss:0.6878366470336914\n",
      "Accuracy:0.5056878924369812\n",
      "___________________\n",
      "Epoch:467\n",
      "Train Loss:0.6836029291152954\n",
      "Test Loss:0.6878154873847961\n",
      "Accuracy:0.5056794285774231\n",
      "___________________\n",
      "Epoch:468\n",
      "Train Loss:0.6835687756538391\n",
      "Test Loss:0.6877942085266113\n",
      "Accuracy:0.5056484937667847\n",
      "___________________\n",
      "Epoch:469\n",
      "Train Loss:0.6835344433784485\n",
      "Test Loss:0.6877729296684265\n",
      "Accuracy:0.5056315064430237\n",
      "___________________\n",
      "Epoch:470\n",
      "Train Loss:0.6835001111030579\n",
      "Test Loss:0.6877515912055969\n",
      "Accuracy:0.5056174397468567\n",
      "___________________\n",
      "Epoch:471\n",
      "Train Loss:0.6834656000137329\n",
      "Test Loss:0.6877302527427673\n",
      "Accuracy:0.5056061744689941\n",
      "___________________\n",
      "Epoch:472\n",
      "Train Loss:0.6834310293197632\n",
      "Test Loss:0.6877087950706482\n",
      "Accuracy:0.5055949091911316\n",
      "___________________\n",
      "Epoch:473\n",
      "Train Loss:0.6833963990211487\n",
      "Test Loss:0.6876872777938843\n",
      "Accuracy:0.5055751800537109\n",
      "___________________\n",
      "Epoch:474\n",
      "Train Loss:0.6833616495132446\n",
      "Test Loss:0.6876657009124756\n",
      "Accuracy:0.5055582523345947\n",
      "___________________\n",
      "Epoch:475\n",
      "Train Loss:0.6833266615867615\n",
      "Test Loss:0.6876439452171326\n",
      "Accuracy:0.505544126033783\n",
      "___________________\n",
      "Epoch:476\n",
      "Train Loss:0.6832916736602783\n",
      "Test Loss:0.6876222491264343\n",
      "Accuracy:0.5055243968963623\n",
      "___________________\n",
      "Epoch:477\n",
      "Train Loss:0.6832565665245056\n",
      "Test Loss:0.6876005530357361\n",
      "Accuracy:0.5055074691772461\n",
      "___________________\n",
      "Epoch:478\n",
      "Train Loss:0.6832214593887329\n",
      "Test Loss:0.6875789165496826\n",
      "Accuracy:0.5054933428764343\n",
      "___________________\n",
      "Epoch:479\n",
      "Train Loss:0.6831862330436707\n",
      "Test Loss:0.6875571012496948\n",
      "Accuracy:0.5054764151573181\n",
      "___________________\n",
      "Epoch:480\n",
      "Train Loss:0.6831509470939636\n",
      "Test Loss:0.6875353455543518\n",
      "Accuracy:0.5054708123207092\n",
      "___________________\n",
      "Epoch:481\n",
      "Train Loss:0.6831156015396118\n",
      "Test Loss:0.6875134110450745\n",
      "Accuracy:0.5054623484611511\n",
      "___________________\n",
      "Epoch:482\n",
      "Train Loss:0.6830801963806152\n",
      "Test Loss:0.6874914765357971\n",
      "Accuracy:0.5054510235786438\n",
      "___________________\n",
      "Epoch:483\n",
      "Train Loss:0.6830445528030396\n",
      "Test Loss:0.6874695420265198\n",
      "Accuracy:0.5054341554641724\n",
      "___________________\n",
      "Epoch:484\n",
      "Train Loss:0.6830087900161743\n",
      "Test Loss:0.6874476671218872\n",
      "Accuracy:0.5054228901863098\n",
      "___________________\n",
      "Epoch:485\n",
      "Train Loss:0.6829730272293091\n",
      "Test Loss:0.6874256134033203\n",
      "Accuracy:0.5054144263267517\n",
      "___________________\n",
      "Epoch:486\n",
      "Train Loss:0.6829372048377991\n",
      "Test Loss:0.6874036192893982\n",
      "Accuracy:0.5054059028625488\n",
      "___________________\n",
      "Epoch:487\n",
      "Train Loss:0.6829013228416443\n",
      "Test Loss:0.6873816251754761\n",
      "Accuracy:0.5053974986076355\n",
      "___________________\n",
      "Epoch:488\n",
      "Train Loss:0.6828655004501343\n",
      "Test Loss:0.6873594522476196\n",
      "Accuracy:0.5053946375846863\n",
      "___________________\n",
      "Epoch:489\n",
      "Train Loss:0.6828294396400452\n",
      "Test Loss:0.6873372793197632\n",
      "Accuracy:0.505386233329773\n",
      "___________________\n",
      "Epoch:490\n",
      "Train Loss:0.682793378829956\n",
      "Test Loss:0.6873151659965515\n",
      "Accuracy:0.5053749084472656\n",
      "___________________\n",
      "Epoch:491\n",
      "Train Loss:0.6827571988105774\n",
      "Test Loss:0.6872929334640503\n",
      "Accuracy:0.5053636431694031\n",
      "___________________\n",
      "Epoch:492\n",
      "Train Loss:0.6827210187911987\n",
      "Test Loss:0.6872708201408386\n",
      "Accuracy:0.5053607821464539\n",
      "___________________\n",
      "Epoch:493\n",
      "Train Loss:0.6826846599578857\n",
      "Test Loss:0.6872484683990479\n",
      "Accuracy:0.505355179309845\n",
      "___________________\n",
      "Epoch:494\n",
      "Train Loss:0.682648241519928\n",
      "Test Loss:0.6872261762619019\n",
      "Accuracy:0.5053495168685913\n",
      "___________________\n",
      "Epoch:495\n",
      "Train Loss:0.6826117634773254\n",
      "Test Loss:0.6872038841247559\n",
      "Accuracy:0.5053382515907288\n",
      "___________________\n",
      "Epoch:496\n",
      "Train Loss:0.6825752854347229\n",
      "Test Loss:0.6871814727783203\n",
      "Accuracy:0.5053185224533081\n",
      "___________________\n",
      "Epoch:497\n",
      "Train Loss:0.682538628578186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.68715900182724\n",
      "Accuracy:0.5053043961524963\n",
      "___________________\n",
      "Epoch:498\n",
      "Train Loss:0.6825018525123596\n",
      "Test Loss:0.6871366500854492\n",
      "Accuracy:0.5052847266197205\n",
      "___________________\n",
      "Epoch:499\n",
      "Train Loss:0.6824652552604675\n",
      "Test Loss:0.6871142387390137\n",
      "Accuracy:0.5052734613418579\n",
      "___________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = modelNN(torch.tensor(X_train_num))\n",
    "    losstrain = loss(outputs.squeeze(), torch.tensor(y_train, dtype=torch.float))\n",
    "    losstrain.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"Epoch:{epoch}\")\n",
    "    print(f\"Train Loss:{losstrain.item()}\")\n",
    "    \n",
    "    modelNN.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        outputs=modelNN(torch.tensor(X_test_num))\n",
    "        losstest=loss(outputs.squeeze(),torch.tensor(y_test.to_numpy(),dtype=torch.float))\n",
    "        acc = (outputs.round() == torch.tensor(y_test.to_numpy(),dtype=torch.float)).float().mean()\n",
    "    print(f\"Test Loss:{losstest.item()}\")    \n",
    "    print(f\"Accuracy:{acc}\")\n",
    "    print(\"___________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9dfe548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.6871142387390137\n",
      "Accuracy:0.5052734613418579\n",
      "Train Loss:0.6824284791946411\n",
      "Accuracy:0.5078516006469727\n"
     ]
    }
   ],
   "source": [
    "modelNN.eval()\n",
    "    \n",
    "with torch.inference_mode():\n",
    "    outputs=modelNN(torch.tensor(X_test_num))\n",
    "    losstest=loss(outputs.squeeze(),torch.tensor(y_test.to_numpy(),dtype=torch.float))\n",
    "    acc = (outputs.round() == torch.tensor(y_test.to_numpy(),dtype=torch.float)).float().mean()\n",
    "print(f\"Test Loss:{losstest.item()}\")    \n",
    "print(f\"Accuracy:{acc}\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs=modelNN(torch.tensor(X_train_num))\n",
    "    losstest=loss(outputs.squeeze(),torch.tensor(y_train.to_numpy(),dtype=torch.float))\n",
    "    acc = (outputs.round() == torch.tensor(y_train.to_numpy(),dtype=torch.float)).float().mean()\n",
    "print(f\"Train Loss:{losstest.item()}\")    \n",
    "print(f\"Accuracy:{acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb097e9",
   "metadata": {},
   "source": [
    "Linear Regression performed the best ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3c389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
